# FinSight æŠ€æœ¯å®ç°æ·±åº¦é—®ç­” (Technical Q&A)

> ğŸ“… **åˆ›å»ºæ—¥æœŸ**: 2026-01-09
> ğŸ“… **æ›´æ–°æ—¥æœŸ**: 2026-01-13
> ğŸ¯ **ç”¨é€”**: é¡¹ç›®æŠ€æœ¯éš¾ç‚¹è‡ªæŸ¥ã€æ¶æ„è®¾è®¡é¢è¯•é¢˜åº“ã€æ ¸å¿ƒåŠŸèƒ½å®ç°åŸç†è®°å½•ã€‚

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½å®ç°ç¯‡

### Q1: FinSight çš„æµå¼è¾“å‡º (SSE) æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ

**A**: SSE çš„å®ç°éå¸¸ç»å…¸ï¼Œæ˜¯é€šè¿‡ **FastAPI + LangGraph + SSE æ ‡å‡†** ç»„åˆå®Œæˆçš„ã€‚å®ƒæ„å»ºäº†ä¸€æ¡ä» LLM åˆ°å‰ç«¯æµè§ˆå™¨çš„â€œå³æ—¶é€šè®¯æµæ°´çº¿â€ã€‚

ç³»ç»Ÿç”± 3 ä¸ªæ ¸å¿ƒä»£ç æ®µç»„æˆï¼š

#### 1. æºå¤´ï¼šLangChain é€å­—ç”Ÿæˆ token
**åŸç†**: ä½¿ç”¨ LangGraph çš„ `astream_events` ç›‘å¬ LLM çš„æ¯ä¸€ä¸ª chunkã€‚
**ä»£ç ä½ç½®**: `backend/langchain_agent.py`

```python
# ç›‘å¬ LLM çš„æ¯ä¸€ä¸ªå°åŠ¨ä½œ
async for event in self.graph.astream_events(initial_state, ...):
    # ç›‘å¬åˆ° LLM æ­£åœ¨è¯´è¯ (on_chat_model_stream)
    if kind == "on_chat_model_stream":
        chunk = event.get("data", {}).get("chunk")
        # æ‹¿åˆ°ä¸€ä¸ªå­—ï¼Œç«‹åˆ» yield å‡ºå»
        yield json.dumps({"type": "token", "content": chunk.content}) + "\n"
```

#### 2. ç®¡é“ï¼šSSE æ ¼å¼å°è£…
**åŸç†**: å°†åº•å±‚çš„ raw token åŒ…è£…æˆç¬¦åˆ **SSE åè®®** çš„æ ¼å¼ï¼ˆ`data: ...\n\n`ï¼‰ã€‚
**ä»£ç ä½ç½®**: `backend/api/streaming.py`

```python
async for raw in report_agent.analyze_stream(query):
    # ... è§£æ JSON ...
    if event_type == "token":
        # åŒ…è£…æˆ SSE æ ¼å¼ï¼šdata: {...}\n\n
        # è¿™å°±å¥½æ¯”æŠŠæ•£è£…çš„è´§ç‰©è£…è¿›æ ‡å‡†çš„é›†è£…ç®±ï¼Œæµè§ˆå™¨æ‰èƒ½è®¤å¾—
        yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
```

#### 3. å‡ºå£ï¼šFastAPI æµå¼å“åº”
**åŸç†**: ä½¿ç”¨ `StreamingResponse` ä¿æŒé•¿è¿æ¥ï¼ŒæŒç»­æ¨é€æ•°æ®ã€‚
**ä»£ç ä½ç½®**: `backend/api/main.py`

```python
return StreamingResponse(
    generate_report(), # è¿™ä¸ªç”Ÿæˆå™¨ä¼šä¸æ–­ yield æ•°æ®
    media_type="text/event-stream", # å‘Šè¯‰æµè§ˆå™¨è¿™æ˜¯ SSE æµ
    # headers ç¦ç”¨ç¼“å­˜ï¼Œç¡®ä¿å®æ—¶æ€§
    headers={"Cache-Control": "no-cache", "Connection": "keep-alive"}
)
```

---

### Q2: ä¸ºä»€ä¹ˆé€‰æ‹© LangGraph è€Œä¸æ˜¯åŸç”Ÿ LangChain Agentï¼Ÿ

**A**: è™½ç„¶ LangChain Agent é€‚åˆçº¿æ€§ä»»åŠ¡ï¼Œä½†åœ¨å¤æ‚çš„**å¤š Agent åä½œ**åœºæ™¯ä¸‹ï¼ŒLangGraph ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼š

1.  **å¾ªç¯èƒ½åŠ› (Cyclic Graphs)**:
    *   **LangChain**: ä¸»è¦æ˜¯ DAGï¼ˆæœ‰å‘æ— ç¯å›¾ï¼‰ï¼Œå¾ˆéš¾å®ç°â€œAgent A åšå®Œ -> Agent B æ£€æŸ¥ ->å¦‚æœä¸åˆæ ¼ -> é€€å›ç»™ Agent Aâ€è¿™æ ·çš„å¾ªç¯ã€‚
    *   **LangGraph**: åŸç”Ÿæ”¯æŒå¾ªç¯ç”±äº `StateGraph` çš„è®¾è®¡ï¼Œè¿™å¯¹äºå®ç° `NewsAgent` çš„**åæ€å¾ªç¯ (Reflection Loop)** è‡³å…³é‡è¦ã€‚

2.  **çŠ¶æ€ç®¡ç† (State Management)**:
    *   LangGraph æ˜¾å¼å®šä¹‰äº† `MessagesState`ï¼Œè®©å¤šä¸ª Agentï¼ˆå¦‚ Supervisorã€PriceAgentã€NewsAgentï¼‰å¯ä»¥å…±äº«åŒä¸€ä¸ªä¸Šä¸‹æ–‡å†å²ï¼Œæ•°æ®æµè½¬æ›´æ¸…æ™°ã€‚

3.  **ç»†ç²’åº¦æ§åˆ¶**:
    *   é€šè¿‡ `astream_events` å¯ä»¥ç²¾ç¡®æ§åˆ¶æµå¼è¾“å‡ºçš„æ¯ä¸€ä¸ªç¯èŠ‚ï¼ˆå¦‚åªè¾“å‡º tokenï¼Œéšè—å·¥å…·è°ƒç”¨çš„ä¸­é—´æ­¥éª¤ï¼‰ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚

---

### Q3: Supervisor æ¶æ„æ˜¯å¦‚ä½•è§£å†³ API ä¸å…¼å®¹é—®é¢˜çš„ï¼Ÿ

**A**: åœ¨ Phase 1 å®ç°ä¸­ï¼Œæˆ‘ä»¬é‡åˆ°äº† FastAPI çš„ `asyncio` äº‹ä»¶å¾ªç¯ä¸ LangChain `asyncio.run()` çš„å†²çªã€‚

**é—®é¢˜èƒŒæ™¯**:
FastAPI æœ¬èº«è¿è¡Œåœ¨ä¸€ä¸ª Event Loop ä¸­ã€‚å¦‚æœæˆ‘ä»¬åœ¨è¯·æ±‚å¤„ç†å‡½æ•°ä¸­ç›´æ¥è°ƒç”¨ `asyncio.run(supervisor.analyze())`ï¼Œä¼šæŠ›å‡º *"RuntimeError: asyncio.run() cannot be called from a running event loop"*ã€‚

**è§£å†³æ–¹æ¡ˆ**:
1.  **å…¨é“¾è·¯å¼‚æ­¥åŒ–**: å½»åº•ç§»é™¤åŒæ­¥çš„ `asyncio.run()` è°ƒç”¨ã€‚
2.  **Await Rewrite**: å°†æ‰€æœ‰é˜»å¡è°ƒç”¨æ”¹ä¸º `await`ã€‚
    *   `Supervisor.analyze` -> `await Supervisor.analyze`
    *   `ReportHandler.handle` -> `await ReportHandler.handle`
3.  **æµå¼é‡æ„**: å¯¹äº `analyize_stream`ï¼Œç›´æ¥ä½¿ç”¨ `async for` è¿­ä»£ç”Ÿæˆå™¨ï¼Œåˆ©ç”¨ FastAPI è‡ªèº«çš„å¼‚æ­¥ç‰¹æ€§è¿›è¡Œæµå¼ä¼ è¾“ï¼Œé¿å…äº†åˆ›å»ºæ–°çš„ Event Loopã€‚

---

### Q4: ç³»ç»Ÿçš„â€œå¤šæºæ•°æ®å›é€€â€æœºåˆ¶æ˜¯å¦‚ä½•è®¾è®¡çš„ï¼Ÿ

**A**: ä¸ºäº†ä¿è¯é‡‘èæ•°æ®çš„å¯é æ€§ï¼Œæˆ‘ä»¬åœ¨ `backend/tools.py` ä¸­å®ç°äº†ä¸¥æ ¼çš„é™çº§ç­–ç•¥ã€‚

ä»¥ `get_stock_price` ä¸ºä¾‹ï¼Œå…¶è°ƒç”¨é“¾è·¯å¦‚ä¸‹ï¼š

```mermaid
flowchart LR
    A[Yahoo Finance] -->|å¤±è´¥/é™æµ| B[Google Finance (Scraper)]
    B -->|å¤±è´¥| C[Stooq API]
    C -->|å¤±è´¥| D[CNBC/Finnhub]
    D -->|å…¨éƒ¨å¤±è´¥| E[æŠ›å‡ºå¼‚å¸¸/è¿”å›ç©º]
```

**è®¾è®¡è¦ç‚¹**:
1.  **ä¼˜å…ˆçº§**: ä¼˜å…ˆä½¿ç”¨å®˜æ–¹ API (Yahoo/Finnhub)ï¼Œå…¶æ¬¡æ˜¯ç¨³å®šçš„ HTML è§£æ (Google)ï¼Œæœ€åæ˜¯å¤‡ç”¨æºã€‚
2.  **ç†”æ–­å™¨ (Circuit Breaker)**: å¦‚æœæŸä¸ªæºè¿ç»­å¤±è´¥ï¼ˆå¦‚ Yahoo æ¥å£å˜åŠ¨ï¼‰ï¼Œ`CircuitBreaker` ä¼šè‡ªåŠ¨â€œè·³é—¸â€ï¼Œæš‚æ—¶å±è”½è¯¥æºï¼Œç›´æ¥è¯·æ±‚ä¸‹ä¸€ä¸ªå¤‡ç”¨æºï¼Œé¿å…æµªè´¹æ—¶é—´åœ¨æ— æ•ˆè¯·æ±‚ä¸Šã€‚

---

## ğŸ”® æ¶æ„æ¼”è¿›ç¯‡

### Q5: RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ

**A**: RAG åŸºç¡€è®¾æ–½å·²åœ¨ 2026-01-12 å®Œæˆï¼Œé‡‡ç”¨ **ChromaDB + Sentence Transformers** æ–¹æ¡ˆï¼š

**1. å‘é‡å­˜å‚¨å±‚ (`backend/knowledge/vector_store.py`)**:
```python
class VectorStore:
    """ChromaDB å•ä¾‹å°è£…"""
    # å»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨æ—¶é˜»å¡
    def _get_embedding_fn(self):
        # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±æ–‡
        self._embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

    def add_documents(self, collection_name, documents, metadatas, ids):
        # å‘é‡åŒ–å¹¶å­˜å…¥ ChromaDB
        embeddings = self._embed_texts(documents)
        collection.add(documents=documents, embeddings=embeddings, ...)

    def query(self, collection_name, query_text, n_results=5):
        # ç›¸ä¼¼åº¦æ£€ç´¢ï¼Œè¿”å› Top-K ç»“æœ
        return collection.query(query_embeddings=query_embedding, n_results=n_results)
```

**2. RAG å¼•æ“å±‚ (`backend/knowledge/rag_engine.py`)**:
```python
class RAGEngine:
    def chunk_text(self, text, chunk_size=512, chunk_overlap=50):
        # æ™ºèƒ½åˆ‡ç‰‡ï¼šå¥å­è¾¹ç•Œæ£€æµ‹ + é‡å çª—å£
        # æ”¯æŒä¸­è‹±æ–‡å¥å­ç»“æŸç¬¦ï¼ˆã€‚ï¼ï¼Ÿ.ï¼‰

    def ingest_document(self, collection_name, content, metadata):
        # åˆ‡ç‰‡ -> å‘é‡åŒ– -> å…¥åº“

    def query_with_context(self, collection_name, query, top_k=5):
        # æ£€ç´¢ -> æ ¼å¼åŒ–ä¸º LLM å¯ç”¨çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
```

**3. åº”ç”¨åœºæ™¯**:
- **DeepSearch ä¸´æ—¶å·¥ä½œå°**: é•¿æ–‡ç ”æŠ¥åˆ‡ç‰‡å…¥åº“ï¼Œä»»åŠ¡ç»“æŸåé”€æ¯
- **ç”¨æˆ·é•¿æœŸè®°å¿†**: æŒä¹…åŒ–å­˜å‚¨ç”¨æˆ·åå¥½ï¼ˆè®¡åˆ’ä¸­ï¼‰

---

### Q6: æ„å›¾è¯†åˆ« (Intent Classification) æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

**A**: FinSight é‡‡ç”¨ **Supervisor Agent æ¶æ„**ï¼Œå®ç°äº†ä¸šç•Œæ ‡å‡†çš„"ä¸‰å±‚æ··åˆ"æ„å›¾åˆ†ç±»æœºåˆ¶ã€‚

**æ¶æ„æµç¨‹**:
```
ç”¨æˆ·è¾“å…¥
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬ä¸€å±‚ï¼šè§„åˆ™åŒ¹é…ï¼ˆå¿«é€Ÿé€šé“ï¼‰          â”‚
â”‚ - "ä½ å¥½/å¸®åŠ©/é€€å‡º" â†’ ç›´æ¥å¤„ç†         â”‚
â”‚ - å¤š ticker â†’ è‡ªåŠ¨è¯†åˆ«ä¸ºå¯¹æ¯”         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ æ²¡åŒ¹é…åˆ°
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬äºŒå±‚ï¼šEmbeddingç›¸ä¼¼åº¦ + å…³é”®è¯åŠ æƒ  â”‚
â”‚ - è®¡ç®—ä¸å„æ„å›¾ä¾‹å¥çš„ç›¸ä¼¼åº¦            â”‚
â”‚ - å…³é”®è¯å‘½ä¸­ â†’ åŠ æƒ +0.12           â”‚
â”‚ - ç›¸ä¼¼åº¦ >= 0.75 â†’ ç›´æ¥åˆ†ç±»          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“ ç½®ä¿¡åº¦ä¸å¤Ÿ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ç¬¬ä¸‰å±‚ï¼šLLM Routerï¼ˆå…œåº•ï¼‰           â”‚
â”‚ - æŠŠå€™é€‰æ„å›¾å‘Šè¯‰LLM                  â”‚
â”‚ - LLMåšæœ€ç»ˆå†³ç­–                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®è®¾è®¡åŸåˆ™**ï¼šå…³é”®è¯ä¸æ˜¯ç”¨æ¥"åŒ¹é…"çš„ï¼Œè€Œæ˜¯ç”¨æ¥**åŠ æƒ/æå‡ç½®ä¿¡åº¦**ï¼š

```python
def _embedding_classify(self, query, query_lower, tickers):
    # 1. å…ˆç”¨ embedding ç®—è¯­ä¹‰ç›¸ä¼¼åº¦
    scores = self._embedding_classifier.compute_similarity(query)

    # 2. å…³é”®è¯å‘½ä¸­åˆ™åŠ åˆ†ï¼ˆä¸æ˜¯ç›´æ¥å†³å®šï¼‰
    for intent, keywords in KEYWORD_BOOST.items():
        if any(kw in query_lower for kw in keywords):
            scores[intent] += 0.12  # åŠ æƒï¼Œä¸æ˜¯ç›´æ¥é€‰æ‹©

    # 3. é€‰æœ€é«˜åˆ†ï¼Œç½®ä¿¡åº¦ä¸å¤Ÿåˆ™è°ƒç”¨ LLM
    ...
```

**æ–¹æ¡ˆå¯¹æ¯”**:

| æ–¹æ¡ˆ | é€‚ç”¨åœºæ™¯ | å‡†ç¡®ç‡ | æˆæœ¬ |
|------|---------|--------|------|
| å…³é”®è¯åŒ¹é… | å¿«é€Ÿé€šé“ã€è¾…åŠ©åŠ æƒ | 60-70% | å…è´¹ |
| Embeddingç›¸ä¼¼åº¦ | ä¸»åŠ›æ–¹æ¡ˆ | 80-90% | ä½ |
| å¾®è°ƒåˆ†ç±»æ¨¡å‹ | å¤§è§„æ¨¡ç”Ÿäº§ | 95%+ | è®­ç»ƒæˆæœ¬é«˜ |
| LLM Router | å…œåº•ã€å¤æ‚åœºæ™¯ | 90%+ | é«˜ |

**FinSight é‡‡ç”¨**: Embeddingä¸ºä¸» + å…³é”®è¯åŠ æƒ + LLMå…œåº•

**Embedding æ¨¡å‹**: `paraphrase-multilingual-MiniLM-L12-v2` (æ”¯æŒä¸­è‹±æ–‡ï¼Œå»¶è¿ŸåŠ è½½)

**API ç«¯ç‚¹**:
- `/chat/supervisor` - åè°ƒè€…æ¨¡å¼å¯¹è¯
- `/chat/supervisor/stream` - åè°ƒè€…æ¨¡å¼æµå¼å¯¹è¯

---

### Q7: NEWS å­æ„å›¾åˆ†ç±» (Sub-intent Classification) æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ

**A**: NEWS æ„å›¾é‡‡ç”¨ **å­æ„å›¾åˆ†ç±» (Sub-intent Classification)** æœºåˆ¶ï¼ŒåŒºåˆ†"è·å–æ–°é—»"ä¸"åˆ†ææ–°é—»å½±å“"ã€‚

**èƒŒæ™¯é—®é¢˜**:
ç”¨æˆ·é—®"è‹¹æœæ–°é—»"å’Œ"åˆ†æè‹¹æœæ–°é—»å½±å“"æ˜¯ä¸¤ç§ä¸åŒéœ€æ±‚ï¼š
- å‰è€…åªéœ€è¿”å›æ–°é—»åˆ—è¡¨
- åè€…éœ€è¦ LLM è¿›è¡Œæ·±åº¦åˆ†æ

**è§£å†³æ–¹æ¡ˆ**:

**æ–‡ä»¶ä½ç½®**: `backend/orchestration/supervisor_agent.py`

```python
def _classify_news_subintent(self, query: str) -> str:
    """
    NEWS æ„å›¾çš„å­åˆ†ç±»ï¼šåŒºåˆ†"æŸ¥è¯¢æ–°é—»"å’Œ"åˆ†ææ–°é—»"
    """
    query_lower = query.lower()

    # åˆ†æç±»å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
    analyze_keywords = [
        # ä¸­æ–‡åˆ†æè¯
        "åˆ†æ", "å½±å“", "è§£è¯»", "æ„å‘³", "è¯„ä¼°", "çœ‹æ³•", "è§‚ç‚¹",
        "èµ°åŠ¿", "é¢„æµ‹", "è§£æ", "æ·±åº¦", "è¯¦ç»†", "æ€ä¹ˆçœ‹", "ä¼šæ€æ ·",
        "å¸¦æ¥", "å¯¼è‡´", "é€ æˆ", "å¼•å‘", "è¯´æ˜", "åæ˜ ", "è¡¨æ˜",
        "åˆ©å¥½", "åˆ©ç©º", "æœºä¼š", "é£é™©", "è¶‹åŠ¿", "å‰æ™¯", "å±•æœ›",
        # è‹±æ–‡åˆ†æè¯
        "analyze", "analysis", "impact", "effect", "implication",
        "interpret", "predict", "forecast", "outlook", "assess"
    ]

    # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†æç±»å…³é”®è¯
    for keyword in analyze_keywords:
        if keyword in query_lower:
            return "analyze"

    return "fetch"  # é»˜è®¤è¿”å›æŸ¥è¯¢ç±»
```

**å¤„ç†ç­–ç•¥**:

| å­æ„å›¾ | å¤„ç†æ–¹å¼ | è¾“å‡ºæ ¼å¼ |
|--------|---------|---------|
| `fetch` | `_handle_news()` - è¿”å›åŸå§‹æ–°é—»åˆ—è¡¨ | æ–°é—»æ ‡é¢˜ + é“¾æ¥ |
| `analyze` | `_handle_news_analysis()` - LLM æ·±åº¦åˆ†æ | æ–°é—»æ‘˜è¦ + å¸‚åœºå½±å“ + æŠ•èµ„å¯ç¤º + é£é™©æç¤º |

**åˆ†æç±»è¾“å‡ºç»“æ„** (`_handle_news_analysis()`):
```markdown
## ğŸ“° ç›¸å…³æ–°é—»
[åŸå§‹æ–°é—»åˆ—è¡¨]

---

## ğŸ” æ·±åº¦åˆ†æ

### ğŸ“° æ–°é—»æ‘˜è¦
ç®€è¦æ€»ç»“ä¸»è¦æ–°é—»äº‹ä»¶

### ğŸ“Š å¸‚åœºå½±å“åˆ†æ
- **çŸ­æœŸå½±å“**ï¼šå¯¹è‚¡ä»·/å¸‚åœºçš„å³æ—¶å½±å“é¢„åˆ¤
- **ä¸­é•¿æœŸå½±å“**ï¼šæ½œåœ¨çš„æŒç»­æ€§å½±å“

### ğŸ¯ æŠ•èµ„å¯ç¤º
- è¿™äº›æ–°é—»å¯¹æŠ•èµ„è€…æ„å‘³ç€ä»€ä¹ˆï¼Ÿ

### âš ï¸ é£é™©æç¤º
- æ–°é—»ä¸­éšå«çš„é£é™©å› ç´ 
```

---

### Q8: ReportIR æ„å»ºä¸ Forum åˆ†æè§£ææ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ

**A**: ReportIR æ„å»ºé‡‡ç”¨ **ä¼˜å…ˆè§£æ Forum å®Œæ•´åˆ†æ** çš„ç­–ç•¥ï¼Œç¡®ä¿å‰ç«¯å¡ç‰‡èƒ½å±•ç¤ºç»“æ„åŒ–çš„ 8 èŠ‚æŠ¥å‘Šã€‚

**æ ¸å¿ƒæ–¹æ³•**: `_build_report_ir()` å’Œ `_parse_forum_sections()`

**æ–‡ä»¶ä½ç½®**: `backend/orchestration/supervisor_agent.py`

```python
def _parse_forum_sections(self, forum_text: str) -> list:
    """
    è§£æ Forum çš„ 8 èŠ‚åˆ†ææ–‡æœ¬ä¸ºç»“æ„åŒ–ç« èŠ‚

    åŒ¹é…æ¨¡å¼: ### 1. ğŸ“Š æ‰§è¡Œæ‘˜è¦ æˆ– ### 1. æ‰§è¡Œæ‘˜è¦
    """
    section_pattern = r'###\s*(\d+)\.\s*([^\n]+)\n([\s\S]*?)(?=###\s*\d+\.|$)'
    matches = re.findall(section_pattern, forum_text)

    sections = []
    for match in matches:
        order, title, content = match
        # æ¸…ç†æ ‡é¢˜ä¸­çš„ emoji
        clean_title = re.sub(r'[ğŸ“ŠğŸ“ˆğŸ’°ğŸŒâš ï¸ğŸ¯ğŸ“ğŸ“…]\s*', '', title).strip()
        sections.append({"title": clean_title, "content": content.strip()})

    return sections


def _extract_executive_summary(self, forum_text: str) -> str:
    """ä» Forum åˆ†æä¸­æå–æ‰§è¡Œæ‘˜è¦ä½œä¸ºå¡ç‰‡æ‘˜è¦"""
    patterns = [
        r'###\s*1\.\s*[ğŸ“Š]?\s*æ‰§è¡Œæ‘˜è¦[^\n]*\n([\s\S]*?)(?=###\s*2\.|$)',
        r'\*\*æŠ•èµ„è¯„çº§\*\*[ï¼š:]\s*([^\n]+)',
        r'\*\*æ ¸å¿ƒè§‚ç‚¹\*\*[ï¼š:]\s*([^\n]+)',
    ]
    for pattern in patterns:
        match = re.search(pattern, forum_text, re.IGNORECASE)
        if match:
            return match.group(1).strip()[:500]
    return forum_text[:500]
```

**æ„å»ºä¼˜å…ˆçº§**:
1. **ä¼˜å…ˆ**: è§£æ Forum çš„ 8 èŠ‚åˆ†æ (`_parse_forum_sections()`)
2. **Fallback**: ä»å„ Agent è¾“å‡ºæ„å»ºç« èŠ‚ (å½“ Forum è§£æå¤±è´¥æ—¶)

**ReportIR æ•°æ®ç»“æ„**:
```json
{
  "report_id": "report_abc12345",
  "ticker": "AAPL",
  "title": "AAPL æ·±åº¦åˆ†ææŠ¥å‘Š",
  "summary": "æ‰§è¡Œæ‘˜è¦å†…å®¹...",
  "sentiment": "bullish",
  "confidence_score": 0.85,
  "sections": [
    {
      "title": "æ‰§è¡Œæ‘˜è¦",
      "order": 1,
      "agent_name": "ForumHost",
      "confidence": 0.85,
      "contents": [{"type": "text", "content": "..."}]
    }
  ],
  "citations": [...],
  "risks": [...],
  "agent_status": {"price": {"status": "success"}, ...}
}
```

---

### Q9: å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†æ˜¯å¦‚ä½•å®ç°çš„ï¼Ÿ

**A**: ç³»ç»Ÿå®ç°äº† **å‰ç«¯ä¼ é€’ + åç«¯æå–** çš„ä¸Šä¸‹æ–‡ç®¡ç†æœºåˆ¶ã€‚

**å‰ç«¯** (`ChatInput.tsx`):
```typescript
// å‘é€æœ€è¿‘ 6 æ¡æ¶ˆæ¯ä½œä¸ºå¯¹è¯å†å²
const history = messages.slice(-6).map(msg => ({
  role: msg.type === 'user' ? 'user' : 'assistant',
  content: msg.content
}));

await sendMessageStream(input, { history });
```

**åç«¯æå–** (`SupervisorAgent._extract_context_info()`):
```python
def _extract_context_info(self, conversation_context: List[Dict]) -> tuple:
    """ä»å¯¹è¯å†å²ä¸­æå–è‚¡ç¥¨ä»£ç å’Œæ‘˜è¦"""
    ticker_pattern = r'\b([A-Z]{1,5})\b'
    url_pattern = r'https?://[^\s\)\]<>"\']+'

    found_tickers = []
    context_parts = []

    for msg in conversation_context[-4:]:  # æœ€è¿‘ 4 æ¡
        content = msg.get("content", "")
        # æå–è‚¡ç¥¨ä»£ç ï¼ˆè¿‡æ»¤åœç”¨è¯ï¼‰
        matches = re.findall(ticker_pattern, content)
        stopwords = {'A', 'I', 'AM', 'PM', 'AI', 'CEO', 'IPO', ...}
        found_tickers.extend([m for m in matches if m not in stopwords])
        # æ„å»ºæ‘˜è¦
        preview = content[:150] + "..." if len(content) > 150 else content
        context_parts.append(f"{role}: {preview}")

    return "\n".join(context_parts), found_tickers[-1] if found_tickers else None
```

**ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç‰¹æ€§**:
- **æŒ‡ä»£æ¶ˆè§£**: "å®ƒçš„æ–°é—»" â†’ ä»ä¸Šä¸‹æ–‡æå–ä¹‹å‰è®¨è®ºçš„è‚¡ç¥¨
- **æ™ºèƒ½å¿½ç•¥**: REPORT æ„å›¾ä¼šæ£€æµ‹ä¸Šä¸‹æ–‡ä¸­çš„ ticker æ˜¯å¦ä¸å½“å‰ç›¸å…³
- **LLM å¢å¼º**: ç®€å•æ„å›¾ï¼ˆå¦‚ PRICEï¼‰ä¼šç»“åˆä¸Šä¸‹æ–‡ç”Ÿæˆæ›´ç›¸å…³çš„å›å¤

---

### Q10: å­ Agent (Sub-agents) ç›®å‰å­˜åœ¨å“ªäº›ç¼ºé™·ï¼Ÿ

**A**: æ¶æ„è®¾è®¡äº† 6 å¤§ä¸“å®¶ Agentï¼Œç›®å‰å¤§éƒ¨åˆ†å·²å®ç°ï¼š

| Agent | çŠ¶æ€ | æ ¸å¿ƒèƒ½åŠ› | æ”¹è¿›è®¡åˆ’ |
|-------|------|----------|----------|
| **PriceAgent** | âœ… å¯ç”¨ | å¤šæºå›é€€è¡Œæƒ…æŸ¥è¯¢ | æ¥å…¥ WebSocket å®æ—¶æ•°æ®æµ |
| **NewsAgent** | âœ… å¯ç”¨ | åæ€å¾ªç¯ + RSS + Finnhub | å¢åŠ  Cross-Validation (å¤šæºäº¤å‰éªŒè¯) |
| **TechnicalAgent** | âœ… å¯ç”¨ | MA/RSI/MACD æŠ€æœ¯æŒ‡æ ‡ | å¢åŠ æ›´å¤šå½¢æ€è¯†åˆ« |
| **FundamentalAgent** | âœ… å¯ç”¨ | PE/PB/ç°é‡‘æµ/æ æ†åˆ†æ | å¢åŠ  DCF ä¼°å€¼æ¨¡å‹ |
| **DeepSearchAgent** | âœ… å¯ç”¨ | çœŸå®æ£€ç´¢ + PDF + Self-RAG | é›†æˆ RAGEngine å‘é‡åŒ– |
| **MacroAgent** | âœ… å¯ç”¨ | FRED API å®è§‚ç»æµæ•°æ® | å¢åŠ æ›´å¤šç»æµæŒ‡æ ‡ |
| **RiskAgent** | âŒ **å¾…å®ç°** | VaR è®¡ç®—ã€ä»“ä½è¯Šæ–­ | Phase 3 è®¡åˆ’ |

**æ¶æ„é£é™©**:
*   **Supervisor ç“¶é¢ˆ**: ç›®å‰æ‰€æœ‰å­ Agent éƒ½é€šè¿‡ Supervisor ä¸²è¡Œ/å¹¶è¡Œè°ƒåº¦ï¼Œå¦‚æœ Supervisor é€»è¾‘å‡ºé”™ (å¦‚ JSON è§£æå¤±è´¥)ï¼Œæ•´ä¸ªåˆ†æé“¾ä¼šæ–­è£‚ã€‚
*   **Context ä¸¢å¤±**: å­ Agent ä¹‹é—´å°šæœªå®ç°é«˜æ•ˆçš„ Memory å…±äº«ï¼ˆå¦‚ TechnicalAgent åº”è¯¥èƒ½çœ‹åˆ° MacroAgent çš„é€šèƒ€ç»“è®ºï¼‰ã€‚

---

### Q8: MacroAgent å¦‚ä½•è·å–å®è§‚ç»æµæ•°æ®ï¼Ÿ

**A**: MacroAgent åœ¨ 2026-01-12 å‡çº§ä¸ºçœŸå® FRED API æ•°æ®é©±åŠ¨ï¼š

**æ•°æ®æº**: ç¾è”å‚¨ç»æµæ•°æ®åº“ (FRED - Federal Reserve Economic Data)

**æ”¯æŒçš„æŒ‡æ ‡**:
| æŒ‡æ ‡ | Series ID | è¯´æ˜ |
|------|-----------|------|
| CPI é€šèƒ€ç‡ | CPIAUCSL | æ¶ˆè´¹è€…ä»·æ ¼æŒ‡æ•° |
| è”é‚¦åŸºé‡‘åˆ©ç‡ | FEDFUNDS | ç¾è”å‚¨åŸºå‡†åˆ©ç‡ |
| GDP å¢é•¿ç‡ | GDP | å›½å†…ç”Ÿäº§æ€»å€¼ |
| å¤±ä¸šç‡ | UNRATE | åŠ³åŠ¨åŠ›å¸‚åœºæŒ‡æ ‡ |
| 10å¹´æœŸå›½å€º | GS10 | é•¿æœŸåˆ©ç‡åŸºå‡† |
| æ”¶ç›Šç‡æ›²çº¿ | T10Y2Y | 10Y-2Y åˆ©å·® |

**ç‰¹æ€§**:
- è‡ªåŠ¨æ£€æµ‹æ”¶ç›Šç‡å€’æŒ‚ï¼ˆrecession_warningï¼‰
- ç»“æ„åŒ–è¾“å‡ºå¤šæ¡ evidence é¡¹
- æ”¯æŒ `FRED_API_KEY` ç¯å¢ƒå˜é‡é…ç½®

```python
# backend/tools.py
def get_fred_data(series_id: str = None) -> Dict[str, Any]:
    """è·å– FRED å®è§‚ç»æµæ•°æ®"""
    # æ”¯æŒå•æŒ‡æ ‡æˆ–å…¨é‡è·å–
    # è¿”å›æ ¼å¼åŒ–æ•°æ® + recession_warning æ ‡å¿—
```
