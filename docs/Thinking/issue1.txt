FinSight é¡¹ç›®é—®é¢˜åˆ†æä¸ä¼˜åŒ– TODO List
ğŸ” æ ¸å¿ƒé—®é¢˜è¯Šæ–­
é—®é¢˜ 1ï¼šNewsAgent æ•°æ®æºå•è–„ï¼Œè¯´æœåŠ›ä¸è¶³
ç°çŠ¶åˆ†æï¼ˆä» news_agent.py ä»£ç ï¼‰ï¼š

<TEXT>
å½“å‰æ•°æ®æºé“¾ï¼š
1. get_company_news (yfinance â†’ finnhub â†’ alpha_vantage â†’ search)
2. æœç´¢å›é€€ (Tavily/Exa)
é—®é¢˜ï¼š

âŒ åªä¾èµ– 1-2 ä¸ª APIï¼Œç»å¸¸è¿”å›ç›¸åŒçš„æ–°é—»
âŒ æ²¡æœ‰æƒå¨è´¢ç»åª’ä½“çš„ç›´æ¥æ¥å…¥ï¼ˆå¦‚ Bloombergã€Reuters å…¨æ–‡ï¼‰
âŒ ç¼ºä¹æ–°é—»æƒ…æ„Ÿåˆ†æå’Œå½±å“åŠ›è¯„ä¼°
âŒ æ²¡æœ‰æ–°é—»å»é‡å’Œç›¸å…³æ€§æ’åº
é—®é¢˜ 2ï¼šMacroAgent è¿‡äºç®€å•
ç°çŠ¶åˆ†æï¼ˆä» macro_agent.py ä»£ç ï¼‰ï¼š

<PYTHON>
# å½“å‰åªæ”¯æŒ FRED API çš„ 5 ä¸ªæŒ‡æ ‡
- fed_rate (è”é‚¦åŸºé‡‘åˆ©ç‡)
- cpi (CPIæŒ‡æ•°)
- unemployment (å¤±ä¸šç‡)
- gdp_growth (GDPå¢é•¿ç‡)
- treasury_10y (10å¹´æœŸå›½å€º)
é—®é¢˜ï¼š

âŒ FRED API å¦‚æœå¤±è´¥ï¼Œç›´æ¥å›é€€åˆ°æœç´¢ï¼ˆè´¨é‡å¾ˆå·®ï¼‰
âŒ ç¼ºä¹å®è§‚ç»æµäº‹ä»¶æ—¥å†ï¼ˆFOMC ä¼šè®®ã€éå†œç­‰ï¼‰
âŒ æ²¡æœ‰è¡Œä¸š/æ¿å—å®è§‚æ•°æ®
âŒ ç¼ºå°‘å…¨çƒå®è§‚ï¼ˆä¸­å›½ PMIã€æ¬§æ´²å¤®è¡Œç­‰ï¼‰
é—®é¢˜ 3ï¼šDeepSearchAgent åŠŸèƒ½å•ä¸€
ç°çŠ¶åˆ†æï¼š

åªæ˜¯ç®€å•çš„æœç´¢ + LLM æ€»ç»“
æ²¡æœ‰å¤šè½®è¿­ä»£æœç´¢
ç¼ºä¹ä¿¡æ¯å¯ä¿¡åº¦éªŒè¯
é—®é¢˜ 4ï¼šAgent è¾“å‡ºè´¨é‡é—®é¢˜
é—®é¢˜è¡¨ç°ï¼š

âœ… èƒ½æ­£ç¡®è·¯ç”±åˆ°å¯¹åº” Agent
âŒ ä½† Agent è¿”å›çš„å†…å®¹"æ°´åˆ†å¤§"ï¼Œç¼ºä¹æ·±åº¦
âŒ ForumHost åˆæˆæ—¶ç¼ºä¹æœ‰æ•ˆçš„ä¿¡æ¯ç­›é€‰
ğŸ“‹ ä¼˜åŒ– TODO List
P0 - ç´§æ€¥ï¼ˆ1-2 å‘¨å†…ï¼‰
ä»»åŠ¡	æè¿°	é¢„æœŸæ•ˆæœ
P0-1: å¢å¼º NewsAgent æ•°æ®æº	æ¥å…¥ NewsAPI.org (å…è´¹å±‚ 100 req/day) + Google News RSS	æ–°é—»æ¥æºä» 2 ä¸ªå¢åŠ åˆ° 5+ ä¸ª
P0-2: æ–°é—»å»é‡å’Œæ’åº	åŸºäºæ ‡é¢˜ç›¸ä¼¼åº¦å»é‡ + æ—¶é—´/æ¥æºæƒé‡æ’åº	é¿å…é‡å¤æ–°é—»ï¼Œæå‡è´¨é‡
P0-3: MacroAgent å¢åŠ ç»æµæ—¥å†	æ¥å…¥ Investing.com ç»æµæ—¥å† API æˆ–çˆ¬è™«	èƒ½å›ç­”"è¿™å‘¨æœ‰ä»€ä¹ˆé‡è¦ç»æµæ•°æ®"
P0-4: Agent è¾“å‡ºç»“æ„åŒ–è¯„åˆ†	æ¯ä¸ª Agent è¾“å‡ºå¿…é¡»åŒ…å« confidence_score + evidence_quality	ForumHost å¯ä»¥ç­›é€‰ä½è´¨é‡è¾“å‡º
P1 - é‡è¦ï¼ˆ2-4 å‘¨å†…ï¼‰
ä»»åŠ¡	æè¿°	é¢„æœŸæ•ˆæœ
P1-1: æ–°é—»æƒ…æ„Ÿåˆ†æ	ä½¿ç”¨ FinBERT æˆ– GPT å¯¹æ–°é—»æ ‡é¢˜/æ‘˜è¦æ‰“åˆ†	æŠ¥å‘Šä¸­æ˜¾ç¤º"åˆ©å¤š/åˆ©ç©º"æ ‡ç­¾
P1-2: MacroAgent å¤šæ•°æ®æº	å¢åŠ  World Bank APIã€OECD Statsã€ä¸­å›½å›½å®¶ç»Ÿè®¡å±€	æ”¯æŒå…¨çƒå®è§‚åˆ†æ
P1-3: DeepSearch è¿­ä»£æœç´¢	æœç´¢ â†’ åˆ†æç¼ºå£ â†’ å†æœç´¢ï¼ˆæœ€å¤š 3 è½®ï¼‰	æ·±åº¦ç ”ç©¶è´¨é‡æå‡ 50%+
P1-4: ä¿¡æ¯æºå¯ä¿¡åº¦ç³»ç»Ÿ	ç»™æ¯ä¸ªæ¥æºæ‰“åˆ†ï¼ˆBloomberg=1.0, å°ç½‘ç«™=0.3ï¼‰	æŠ¥å‘Šä¸­æ ‡æ³¨æ¥æºå¯ä¿¡åº¦
P1-5: è¡Œä¸šæ–°é—»åˆ†ç±»	è‡ªåŠ¨è¯†åˆ«æ–°é—»å±äºå“ªä¸ªè¡Œä¸š/ä¸»é¢˜	æ”¯æŒè¡Œä¸šèšç„¦åˆ†æ
P2 - æ”¹è¿›ï¼ˆ1-2 æœˆå†…ï¼‰
ä»»åŠ¡	æè¿°	é¢„æœŸæ•ˆæœ
P2-1: RAG é›†æˆ	ç”¨ ChromaDB/Pinecone å­˜å‚¨å†å²ç ”ç©¶æŠ¥å‘Š	æ”¯æŒ"ä¹‹å‰åˆ†æè¿‡ NVDA å—"ç±»æŸ¥è¯¢
P2-2: å¤šè¯­è¨€æ–°é—»	æ”¯æŒä¸­æ–‡è´¢ç»æ–°é—»ï¼ˆä¸œæ–¹è´¢å¯Œã€åŒèŠ±é¡ºï¼‰	ä¸­å›½è‚¡ç¥¨åˆ†æè´¨é‡æå‡
P2-3: äº‹ä»¶é©±åŠ¨åˆ†æ	æ£€æµ‹è´¢æŠ¥æ—¥ã€åˆ†çº¢æ—¥ã€é‡å¤§äº‹ä»¶	è‡ªåŠ¨è§¦å‘æ·±åº¦åˆ†æ
P2-4: ç«å“å¯¹æ¯”åˆ†æ	è‡ªåŠ¨è¯†åˆ«ç«äº‰å¯¹æ‰‹å¹¶å¯¹æ¯”	æŠ¥å‘Šä¸­åŒ…å«ç«äº‰æ ¼å±€
P2-5: ç¤¾äº¤åª’ä½“æƒ…ç»ª	æ¥å…¥ Twitter/Reddit æƒ…ç»ªåˆ†æ	å¢åŠ æ•£æˆ·æƒ…ç»ªç»´åº¦
ğŸ”§ å…·ä½“å®ç°å»ºè®®
P0-1: å¢å¼º NewsAgent æ•°æ®æº
<PYTHON>
# backend/agents/news_agent.py ä¿®æ”¹
NEWS_SOURCES = [
    {"name": "newsapi", "priority": 1, "free_tier": 100},
    {"name": "finnhub", "priority": 2, "free_tier": 60},
    {"name": "google_news_rss", "priority": 3, "free_tier": "unlimited"},
    {"name": "yahoo_finance_rss", "priority": 4, "free_tier": "unlimited"},
    {"name": "seeking_alpha_rss", "priority": 5, "free_tier": "unlimited"},
]
async def _initial_search(self, query: str, ticker: str):
    all_news = []
    
    # å¹¶è¡Œè°ƒç”¨å¤šä¸ªæ•°æ®æº
    tasks = [
        self._fetch_newsapi(ticker),
        self._fetch_finnhub(ticker),
        self._fetch_google_rss(ticker),
        self._fetch_yahoo_rss(ticker),
    ]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for result in results:
        if isinstance(result, list):
            all_news.extend(result)
    
    # å»é‡ + æ’åº
    unique_news = self._deduplicate(all_news)
    ranked_news = self._rank_by_relevance(unique_news, ticker)
    
    return ranked_news[:10]  # è¿”å› top 10
P0-3: MacroAgent å¢åŠ ç»æµæ—¥å†
<PYTHON>
# backend/tools.py æ–°å¢
def get_economic_calendar(days_ahead: int = 7) -> List[Dict]:
    """
    è·å–æœªæ¥ N å¤©çš„é‡è¦ç»æµäº‹ä»¶
    æ•°æ®æºï¼šinvesting.com æˆ– tradingeconomics.com
    """
    events = []
    
    # æ–¹æ¡ˆ A: ä½¿ç”¨ investing.com éå®˜æ–¹ API
    # æ–¹æ¡ˆ B: çˆ¬å– tradingeconomics.com
    # æ–¹æ¡ˆ C: ä½¿ç”¨ Exa æœç´¢ "economic calendar this week"
    
    important_events = [
        "FOMC Meeting",
        "Non-Farm Payrolls",
        "CPI Release",
        "GDP Report",
        "Fed Chair Speech",
    ]
    
    return events
P1-1: æ–°é—»æƒ…æ„Ÿåˆ†æ
<PYTHON>
# backend/services/sentiment.py æ–°å¢
from transformers import pipeline
class NewsSentimentAnalyzer:
    def __init__(self):
        # ä½¿ç”¨ FinBERTï¼ˆé‡‘èé¢†åŸŸå¾®è°ƒçš„ BERTï¼‰
        self.model = pipeline(
            "sentiment-analysis",
            model="ProsusAI/finbert"
        )
    
    def analyze(self, text: str) -> Dict:
        result = self.model(text[:512])[0]
        return {
            "sentiment": result["label"],  # positive/negative/neutral
            "confidence": result["score"],
            "impact": self._estimate_impact(result)
        }
    
    def _estimate_impact(self, result):
        # æ ¹æ®æƒ…æ„Ÿå¼ºåº¦ä¼°è®¡å¯¹è‚¡ä»·çš„æ½œåœ¨å½±å“
        if result["label"] == "positive" and result["score"] > 0.9:
            return "strong_bullish"
        elif result["label"] == "negative" and result["score"] > 0.9:
            return "strong_bearish"
        return "neutral"
ğŸ“Š ä¼˜åŒ–æ•ˆæœé¢„æœŸ
æŒ‡æ ‡	å½“å‰	ä¼˜åŒ–å
æ–°é—»æ¥æºæ•°é‡	2-3 ä¸ª	6-8 ä¸ª
æ–°é—»å¹³å‡è´¨é‡è¯„åˆ†	0.5	0.8
å®è§‚æ•°æ®è¦†ç›–	5 ä¸ªæŒ‡æ ‡	20+ ä¸ªæŒ‡æ ‡
åˆ†ææŠ¥å‘Šæ·±åº¦	æµ…å±‚æ±‡æ€»	å¤šç»´åº¦åˆ†æ
ç”¨æˆ·æ»¡æ„åº¦	60%	85%+
ğŸ—ï¸ æ¶æ„ä¼˜åŒ–å»ºè®®
å…³äº DeepSearchAgent æ‹†åˆ†é—®é¢˜
æˆ‘çš„å»ºè®®ï¼šæš‚æ—¶ä¸æ‹†åˆ†æˆ 3 ä¸ªå­ Agent

ç†ç”±ï¼š

å½“å‰é—®é¢˜æ˜¯æ•°æ®æºä¸å¤Ÿï¼Œä¸æ˜¯æ¶æ„é—®é¢˜
æ‹†åˆ†ä¼šå¢åŠ å¤æ‚åº¦ï¼Œä½†ä¸ä¼šæå‡è´¨é‡
å…ˆæŠŠ P0/P1 åšå®Œï¼Œå†è€ƒè™‘æ¶æ„ä¼˜åŒ–
æ›¿ä»£æ–¹æ¡ˆï¼šåœ¨ DeepSearchAgent å†…éƒ¨ä½¿ç”¨ Workflow

<PYTHON>
class DeepSearchAgent:
    async def run(self, query: str):
        # Step 1: Plan (ä¸æ˜¯ç‹¬ç«‹ Agentï¼Œæ˜¯å‡½æ•°)
        search_plan = await self._plan_search(query)
        
        # Step 2: Execute (å¹¶è¡Œæœç´¢)
        results = await asyncio.gather(*[
            self._search(q) for q in search_plan.queries
        ])
        
        # Step 3: Synthesize (LLM æ€»ç»“)
        report = await self._synthesize(results)
        
        return report
ğŸ“ æ€»ç»“
æœ€æ ¸å¿ƒçš„é—®é¢˜æ˜¯ï¼šæ•°æ®æºå¤ªå°‘ + ç¼ºä¹è´¨é‡æ§åˆ¶

ä¼˜å…ˆçº§æ’åºï¼š

P0 ä»»åŠ¡ä¼˜å…ˆï¼šå¢åŠ æ•°æ®æºã€å»é‡ã€è¯„åˆ†
P1 ä»»åŠ¡æ¬¡ä¹‹ï¼šæƒ…æ„Ÿåˆ†æã€è¿­ä»£æœç´¢
P2 å¯ä»¥æ…¢æ…¢åšï¼šRAGã€å¤šè¯­è¨€
ä¸å»ºè®®ç°åœ¨æ‹†åˆ† Agentï¼Œå…ˆæŠŠæ•°æ®è´¨é‡åšä¸Šå»ã€‚