æˆ‘æ¥é€ä¸€åˆ†æè¿™ä¸ªé‡‘èåˆ†æAgenté¡¹ç›®çš„ç°çŠ¶å’Œæ”¹è¿›å»ºè®®ï¼š

## LangChain æœ€æ–°ç‰ˆæœ¬è¿ç§»æ–¹æ¡ˆ (2025å¹´)

åŸºäºå¯¹ç°æœ‰ä»£ç çš„æ·±å…¥åˆ†æï¼Œæˆ‘å°†æä¾›ä¸€ä¸ªä½¿ç”¨ **LangChain 0.3.x æœ€æ–°ç‰¹æ€§** çš„å®Œæ•´è¿ç§»æ–¹æ¡ˆã€‚

### ğŸš€ æœ€æ–°LangChainç‰¹æ€§åˆ†æ

**1. æœ€æ–°çš„@toolè£…é¥°å™¨ (LangChain 0.3.x)**
```python
# 2025å¹´æœ€æ–°è¯­æ³•
from langchain_core.tools import tool
from langchain_core.pydantic_v1 import BaseModel, Field
from typing import Optional

class StockInput(BaseModel):
    ticker: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ 'AAPL', 'NVDA'")
    period: Optional[str] = Field(default="1mo", description="æ—¶é—´å‘¨æœŸ")

@tool(args_schema=StockInput)
def get_stock_price(input_data: StockInput) -> str:
    """è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼å’Œå†å²æ•°æ®

    Args:
        input_data: åŒ…å«è‚¡ç¥¨ä»£ç å’Œæ—¶é—´å‘¨æœŸçš„è¾“å…¥å‚æ•°

    Returns:
        æ ¼å¼åŒ–çš„ä»·æ ¼ä¿¡æ¯å­—ç¬¦ä¸²
    """
    # ç°æœ‰é€»è¾‘ä¿æŒä¸å˜
    return get_stock_price_impl(input_data.ticker, input_data.period)
```

**2. LangGraphæœ€æ–°Agentæ¡†æ¶**
```python
# 2025å¹´æœ€æ–°çš„LangGraph ReActå®ç°
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from typing import TypedDict, List

class AgentState(TypedDict):
    messages: List[HumanMessage]
    current_step: str
    observations: List[str]
    report_generated: bool

def create_financial_agent():
    # ä½¿ç”¨æœ€æ–°çš„StateGraph
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("think", think_node)
    workflow.add_node("act", act_node)
    workflow.add_node("observe", observe_node)
    workflow.add_node("generate_report", generate_report_node)

    # è®¾ç½®è¾¹
    workflow.set_entry_point("think")
    workflow.add_edge("think", "act")
    workflow.add_edge("act", "observe")
    workflow.add_conditional_edges(
        "observe",
        should_continue,
        {
            "continue": "think",
            "generate": "generate_report"
        }
    )
    workflow.add_edge("generate_report", END)

    # ä½¿ç”¨æœ€æ–°çš„å†…å­˜æ£€æŸ¥ç‚¹
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)
```

**3. æœ€æ–°æµå¼è¾“å‡ºç³»ç»Ÿ**
```python
from langchain_core.callbacks import StreamingStdOutCallbackHandler
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# 2025å¹´æœ€æ–°çš„æµå¼å¤„ç†
class FinancialStreamingHandler(StreamingStdOutCallbackHandler):
    def __init__(self):
        self.thought_count = 0
        self.action_count = 0

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        if "Thought:" in token:
            self.thought_count += 1
            print(f"ğŸ’­ æ€è€ƒ {self.thought_count}: ", end="", flush=True)
        elif "Action:" in token:
            self.action_count += 1
            print(f"ğŸ”§ æ‰§è¡ŒåŠ¨ä½œ {self.action_count}: ", end="", flush=True)
        else:
            print(token, end="", flush=True)

# ä½¿ç”¨æœ€æ–°çš„æµå¼ç®¡é“
def stream_financial_analysis(query: str):
    streaming_handler = FinancialStreamingHandler()

    chain = (
        {"query": RunnablePassthrough()}
        | prompt
        | llm.bind(callbacks=[streaming_handler])
        | StrOutputParser()
    )

    return chain.stream(query)
```

**4. æœ€æ–°Promptæ¨¡æ¿ç³»ç»Ÿ**
```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate

# 2025å¹´æœ€æ–°çš„æ¨¡å—åŒ–æç¤ºè¯
examples = [
    {
        "input": "åˆ†æNVDAè‚¡ç¥¨",
        "thought_process": "æˆ‘éœ€è¦æ”¶é›†NVDAçš„å®æ—¶æ•°æ®ï¼ŒåŒ…æ‹¬ä»·æ ¼ã€æ–°é—»ã€å¸‚åœºæƒ…ç»ªç­‰",
        "actions": ["get_current_datetime", "search NVDA stock analysis", "get_stock_price NVDA"]
    }
]

example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "Thought: {thought_process}\nActions: {actions}")
])

few_shot_prompt = FewShotChatMessagePromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
)

system_prompt = ChatPromptTemplate.from_messages([
    ("system", """ä½ æ˜¯ä¸“ä¸šæŠ•èµ„åˆ†æå®˜(CIO)ã€‚ä½¿ç”¨æœ€æ–°æ•°æ®{current_date}ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚

    {few_shot_examples}

    å¯ç”¨å·¥å…·: {tools}
    """),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])
```

**5. æœ€æ–°è®°å¿†å’Œä¼šè¯ç®¡ç†**
```python
from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory

# 2025å¹´æœ€æ–°çš„ä¼šè¯ç®¡ç†
class FinancialChatHistory(BaseChatMessageHistory):
    def __init__(self):
        super().__init__()
        self.analysis_sessions = {}  # å­˜å‚¨æ¯ä¸ªåˆ†æä¼šè¯

    def add_analysis_session(self, ticker: str, session_data: dict):
        """æ·»åŠ åˆ†æä¼šè¯è®°å½•"""
        self.analysis_sessions[ticker] = {
            "timestamp": datetime.now(),
            "data": session_data,
            "report": session_data.get("report", "")
        }

    def get_previous_analysis(self, ticker: str) -> str:
        """è·å–ä¹‹å‰çš„åˆ†æç»“æœ"""
        if ticker in self.analysis_sessions:
            return f"ä¹‹å‰{ticker}çš„åˆ†æ: {self.analysis_sessions[ticker]['report'][:200]}..."
        return ""

# ä½¿ç”¨æœ€æ–°è®°å¿†ç³»ç»Ÿ
history = InMemoryChatMessageHistory()
chain_with_history = RunnableWithMessageHistory(
    agent_chain,
    lambda session_id: history,
    input_messages_key="input",
    history_messages_key="chat_history",
)
```

### ğŸ“‹ å®Œæ•´è¿ç§»å®æ–½è®¡åˆ’

#### é˜¶æ®µ1: ç¯å¢ƒå‡çº§ (ç«‹å³æ‰§è¡Œ)

**æ›´æ–°requirements.txt:**
```txt
# æ ¸å¿ƒLangChainåŒ… (2025å¹´æœ€æ–°ç‰ˆæœ¬)
langchain==0.3.10
langchain-core==0.3.21
langchain-openai==0.2.8
langchain-anthropic==0.3.5
langchain-community==0.3.11

# LangGraph (æœ€æ–°Agentæ¡†æ¶)
langgraph==0.2.45
langgraph-checkpoint==0.2.9

# ç°æœ‰ä¾èµ–ä¿æŒ
litellm==1.52.23
ddgs==9.6.0
yfinance==0.2.66
finnhub-python==2.4.35
requests==2.32.3
beautifulsoup4==4.12.3
pandas==2.2.3
python-dotenv==1.0.1

# æ–°å¢æ€§èƒ½ä¼˜åŒ–
asyncio-throttle==1.0.2
tenacity==9.0.0
pydantic==2.9.2
```

#### é˜¶æ®µ2: å·¥å…·ç³»ç»Ÿé‡æ„ (ç¬¬1-2å¤©)

**åˆ›å»º langchain_tools.py:**
```python
from langchain_core.tools import tool
from langchain_core.pydantic_v1 import BaseModel, Field
from typing import Optional, List, Dict, Any
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential
from concurrent.futures import ThreadPoolExecutor

# ç°æœ‰å·¥å…·å¯¼å…¥
from tools import (
    get_stock_price_impl, get_company_news_impl, get_company_info_impl,
    search_impl, get_market_sentiment_impl, get_economic_events_impl,
    get_performance_comparison_impl, analyze_historical_drawdowns_impl,
    get_current_datetime_impl
)

class TickerInput(BaseModel):
    ticker: str = Field(description="è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ 'AAPL', 'NVDA', '^GSPC'")

class SearchInput(BaseModel):
    query: str = Field(description="æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²")

class ComparisonInput(BaseModel):
    tickers: Dict[str, str] = Field(description="è‚¡ç¥¨ä»£ç å­—å…¸ï¼Œä¾‹å¦‚ {'Name': 'TICK'}")

class DateInput(BaseModel):
    pass  # æ— å‚æ•°è¾“å…¥

# ä½¿ç”¨æœ€æ–°@toolè£…é¥°å™¨é‡æ„æ‰€æœ‰å·¥å…·
@tool(args_schema=TickerInput)
def get_stock_price(input_data: TickerInput) -> str:
    """è·å–è‚¡ç¥¨å®æ—¶ä»·æ ¼å’ŒåŸºæœ¬é¢æ•°æ®

    Args:
        input_data: åŒ…å«è‚¡ç¥¨ä»£ç çš„è¾“å…¥å‚æ•°

    Returns:
        è¯¦ç»†çš„ä»·æ ¼ä¿¡æ¯å’ŒåŸºæœ¬é¢æ•°æ®
    """
    return get_stock_price_impl(input_data.ticker)

@tool(args_schema=TickerInput)
def get_company_news(input_data: TickerInput) -> str:
    """è·å–å…¬å¸æœ€æ–°æ–°é—»å’Œå¸‚åœºåŠ¨æ€

    Args:
        input_data: åŒ…å«è‚¡ç¥¨ä»£ç çš„è¾“å…¥å‚æ•°

    Returns:
        æ ¼å¼åŒ–çš„æ–°é—»æ‘˜è¦
    """
    return get_company_news_impl(input_data.ticker)

@tool(args_schema=SearchInput)
def search(input_data: SearchInput) -> str:
    """ä½¿ç”¨æœç´¢å¼•æ“è·å–å¸‚åœºä¿¡æ¯

    Args:
        input_data: åŒ…å«æœç´¢æŸ¥è¯¢çš„è¾“å…¥å‚æ•°

    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    return search_impl(input_data.query)

# å…¶ä»–å·¥å…·ç±»ä¼¼é‡æ„...

# å·¥å…·åˆ—è¡¨
FINANCIAL_TOOLS = [
    get_stock_price,
    get_company_news,
    get_company_info,
    search,
    get_market_sentiment,
    get_economic_events,
    get_performance_comparison,
    analyze_historical_drawdowns,
    get_current_datetime,
]
```

#### é˜¶æ®µ3: Agentæ ¸å¿ƒé‡æ„ (ç¬¬3-4å¤©)

**åˆ›å»º langchain_agent.py:**
```python
from langchain_core.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from langchain_core.callbacks import BaseCallbackHandler
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, List, Dict, Any
import asyncio
from datetime import datetime

from .langchain_tools import FINANCIAL_TOOLS
from .llm_service import get_llm_provider

class FinancialAgentState(TypedDict):
    messages: List[Dict[str, Any]]
    current_step: str
    observations: List[str]
    report_generated: bool
    analysis_ticker: str

class FinancialCallbackHandler(BaseCallbackHandler):
    """è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨ï¼Œå®ç°å®æ—¶è¿›åº¦æ˜¾ç¤º"""

    def __init__(self):
        self.step_count = 0
        self.observation_count = 0
        self.start_time = None

    def on_agent_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs) -> None:
        self.start_time = datetime.now()
        print("ğŸš€ å¼€å§‹é‡‘èåˆ†æ...")

    def on_agent_action(self, action, **kwargs) -> Any:
        self.step_count += 1
        tool = action.tool
        tool_input = action.tool_input
        print(f"ğŸ”§ æ­¥éª¤ {self.step_count}: ä½¿ç”¨å·¥å…· {tool}")
        if tool_input:
            print(f"   è¾“å…¥: {tool_input}")

    def on_agent_finish(self, finish, **kwargs) -> None:
        end_time = datetime.now()
        duration = end_time - self.start_time
        print(f"âœ… åˆ†æå®Œæˆ! è€—æ—¶: {duration.total_seconds():.2f}ç§’")
        print(f"   æ€»æ­¥éª¤æ•°: {self.step_count}")
        print(f"   æ•°æ®ç‚¹æ•°: {self.observation_count}")

# 2025å¹´æœ€æ–°çš„CIOç³»ç»Ÿæç¤ºè¯
CIO_SYSTEM_PROMPT = """ä½ æ˜¯é¡¶çº§å¯¹å†²åŸºé‡‘çš„é¦–å¸­æŠ•èµ„å®˜(CIO)ã€‚

å½“å‰æ—¥æœŸ: {current_date}

ğŸ¯ ä½ çš„ä½¿å‘½:
ä½¿ç”¨ReActæ¡†æ¶æ”¶é›†å®æ—¶æ•°æ®ï¼Œç”Ÿæˆä¸“ä¸šè¯¦ç»†çš„æŠ•èµ„æŠ¥å‘Š(æœ€å°‘800å­—)ã€‚

ğŸ“‹ å·¥ä½œæµç¨‹:
1. æ•°æ®æ”¶é›†é˜¶æ®µ - ä½¿ç”¨Thought-Actionå¾ªç¯æ”¶é›†4-6ä¸ªå…³é”®æ•°æ®ç‚¹
2. æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ - åŸºäºæ”¶é›†çš„æ•°æ®æ’°å†™ç»¼åˆåˆ†ææŠ¥å‘Š

ğŸ”§ å¯ç”¨å·¥å…·:
{tools}

ğŸ“ å¿…éœ€çš„æŠ¥å‘Šç»“æ„:
# [æŠ•èµ„æ ‡çš„] - ä¸“ä¸šåˆ†ææŠ¥å‘Š
*æŠ¥å‘Šæ—¥æœŸ: {current_date}*

## æ‰§è¡Œæ‘˜è¦ (2-3å¥è¯)
æ˜ç¡®çš„æŠ•èµ„å»ºè®®(BUY/HOLD/SELL)

## å½“å‰å¸‚åœºçŠ¶å†µ
- å½“å‰ä»·æ ¼/æ°´å¹³å’Œè¿‘æœŸè¡¨ç°
- å¹´åˆè‡³ä»Šå’Œ1å¹´å›æŠ¥ç‡
- ä¸åŸºå‡†æ¯”è¾ƒ
- å…³é”®æŠ€æœ¯ä½

## å®è§‚ç¯å¢ƒä¸å‚¬åŒ–å‰‚
- ç»æµæ¡ä»¶(é€šèƒ€ã€åˆ©ç‡ã€ç¾è”å‚¨æ”¿ç­–)
- å³å°†åˆ°æ¥çš„é‡å¤§äº‹ä»¶
- åœ°ç¼˜æ”¿æ²»å› ç´ 
- è¡Œä¸šç‰¹å®šè¶‹åŠ¿

## æŠ€æœ¯ä¸æƒ…ç»ªåˆ†æ
- å¸‚åœºæƒ…ç»ªæŒ‡æ ‡
- äº¤æ˜“é‡å’ŒåŠ¨é‡
- æœºæ„æŒä»“å’Œå†…éƒ¨æ´»åŠ¨

## é£é™©è¯„ä¼°
- å†å²æ³¢åŠ¨ç‡å’Œæœ€å¤§å›æ’¤
- ç‰¹å®šæŠ•èµ„é£é™©
- ä¸æ›´å¹¿æ³›å¸‚åœºçš„ç›¸å…³æ€§

## æŠ•èµ„ç­–ç•¥ä¸å»ºè®®

**ä¸»è¦å»ºè®®:** [BUY/SELL/HOLD]
**ä¿¡å¿ƒæ°´å¹³:** [é«˜/ä¸­/ä½]
**æ—¶é—´èŒƒå›´:** [çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ]

**å…¥åœºç­–ç•¥:**
- ç†æƒ³å…¥åœºä»·æ ¼/æ°´å¹³
- ä»“ä½é…ç½®å»ºè®®

**é£é™©ç®¡ç†:**
- æ­¢æŸæ°´å¹³
- è·åˆ©ç›®æ ‡
- æŠ•èµ„ç»„åˆé…ç½®æ¯”ä¾‹

**é€€å‡ºç­–ç•¥:**
- è·åˆ©äº†ç»“æ—¶æœº
- æ­¢æŸæ—¶æœº

## å±•æœ›ä¸ä»·æ ¼ç›®æ ‡

**ç‰›å¸‚æƒ…æ™¯:** ä¸Šè¡Œæ½œåŠ›å’Œæ—¶é—´çº¿
**åŸºå‡†æƒ…æ™¯:** æœ€å¯èƒ½ç»“æœ
**ç†Šå¸‚æƒ…æ™¯:** ä¸‹è¡Œé£é™©å’Œé¢„è­¦ä¿¡å·

## å…³é”®è¦ç‚¹ (3-5ä¸ªè¦ç‚¹)
- æœ€é‡è¦çš„è§è§£
- éœ€è¦ç›‘æ§çš„å…³é”®å› ç´ 
- æŠ•èµ„è€…è¡ŒåŠ¨äº‹é¡¹

## é‡è¦ç›‘æ§äº‹ä»¶
- å³å°†åˆ°æ¥çš„è´¢æŠ¥
- ç¾è”å‚¨ä¼šè®®
- ç›‘ç®¡å†³å®š
- ç«äº‰å¯¹æ‰‹è¡ŒåŠ¨

---
*å…è´£å£°æ˜: æ­¤åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚*

âš ï¸ å…³é”®æŒ‡å¯¼åŸåˆ™:
1. å…·ä½“æ˜ç¡®: åŒ…å«å®é™…æ—¥æœŸã€æ•°å­—ã€ç™¾åˆ†æ¯”
2. å…¨é¢æ·±å…¥: æŠ¥å‘Šæœ€å°‘800å­—
3. å¯æ“ä½œ: ç»™å‡ºå…·ä½“çš„ä¹°å–å»ºè®®å’Œç†ç”±
4. ä½¿ç”¨æ‰€æœ‰æ•°æ®: å¼•ç”¨æ¯ä¸ªè§‚å¯Ÿç»“æœ
5. ä¿æŒæœ€æ–°: æåŠæœ€è¿‘30å¤©çš„å‘å±•
6. é¿å…æ³›æ³›è€Œè°ˆ: ä¸è¦è¯´"è‡ªå·±åšç ”ç©¶"ç­‰
7. å±•ç¤ºå·¥ä½œ: è§£é‡Šæ¯ä¸ªç»“è®ºçš„åŸå› 

ç°åœ¨å¼€å§‹ä½ çš„åˆ†æã€‚
"""

def create_financial_agent(provider="gemini_proxy", model="gemini-2.5-flash"):
    """ä½¿ç”¨æœ€æ–°LangChainåˆ›å»ºé‡‘èåˆ†æAgent"""

    # è·å–LLM
    llm = get_llm_provider(provider, model)

    # åˆ›å»ºå·¥å…·åˆ—è¡¨å­—ç¬¦ä¸²
    tools_description = "\n".join([f"- {tool.name}: {tool.description}" for tool in FINANCIAL_TOOLS])

    # åˆ›å»ºæœ€æ–°æç¤ºè¯æ¨¡æ¿
    prompt = ChatPromptTemplate.from_messages([
        ("system", CIO_SYSTEM_PROMPT.format(
            current_date=datetime.now().strftime("%Y-%m-%d"),
            tools=tools_description
        )),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])

    # ä½¿ç”¨æœ€æ–°create_react_agent
    agent = create_react_agent(llm, FINANCIAL_TOOLS, prompt)

    # åˆ›å»ºå›è°ƒå¤„ç†å™¨
    callback_handler = FinancialCallbackHandler()

    # åˆ›å»ºAgentæ‰§è¡Œå™¨
    agent_executor = AgentExecutor(
        agent=agent,
        tools=FINANCIAL_TOOLS,
        verbose=True,
        max_iterations=15,
        handle_parsing_errors=True,
        return_intermediate_steps=True,
        callbacks=[callback_handler]
    )

    return agent_executor

# LangGraphç‰ˆæœ¬ (æ›´é«˜çº§çš„æ§åˆ¶)
def create_langgraph_financial_agent():
    """ä½¿ç”¨LangGraphåˆ›å»ºæ›´å¼ºå¤§çš„é‡‘èåˆ†æAgent"""

    def think_node(state: FinancialAgentState) -> FinancialAgentState:
        """æ€è€ƒèŠ‚ç‚¹ - åˆ†æå½“å‰çŠ¶æ€å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
        messages = state["messages"]
        last_message = messages[-1] if messages else {"content": ""}

        # è¿™é‡ŒLLMå†³å®šä¸‹ä¸€æ­¥å·¥å…·ä½¿ç”¨
        llm_response = get_llm_provider().invoke([
            SystemMessage(content="åˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€ä¸ªä½¿ç”¨çš„å·¥å…·"),
            HumanMessage(content=str(last_message))
        ])

        state["current_step"] = "tool_selection"
        return state

    def act_node(state: FinancialAgentState) -> FinancialAgentState:
        """æ‰§è¡ŒèŠ‚ç‚¹ - è°ƒç”¨é€‰å®šçš„å·¥å…·"""
        # å·¥å…·æ‰§è¡Œé€»è¾‘
        state["current_step"] = "observation"
        return state

    def observe_node(state: FinancialAgentState) -> FinancialAgentState:
        """è§‚å¯ŸèŠ‚ç‚¹ - å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ"""
        observations = state.get("observations", [])
        observations.append(f"è§‚å¯Ÿç»“æœ {len(observations) + 1}")
        state["observations"] = observations
        state["current_step"] = "thinking"
        return state

    def should_continue(state: FinancialAgentState) -> str:
        """å†³å®šæ˜¯å¦ç»§ç»­æ”¶é›†æ•°æ®æˆ–ç”ŸæˆæŠ¥å‘Š"""
        observations = state.get("observations", [])
        if len(observations) >= 4:
            return "generate"
        return "continue"

    def generate_report_node(state: FinancialAgentState) -> FinancialAgentState:
        """ç”ŸæˆæŠ¥å‘ŠèŠ‚ç‚¹"""
        state["report_generated"] = True
        return state

    # æ„å»ºå›¾
    workflow = StateGraph(FinancialAgentState)
    workflow.add_node("think", think_node)
    workflow.add_node("act", act_node)
    workflow.add_node("observe", observe_node)
    workflow.add_node("generate_report", generate_report_node)

    workflow.set_entry_point("think")
    workflow.add_edge("think", "act")
    workflow.add_edge("act", "observe")
    workflow.add_conditional_edges("observe", should_continue)
    workflow.add_edge("generate_report", END)

    # ä½¿ç”¨å†…å­˜æ£€æŸ¥ç‚¹
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)

    return app

# ä¸»è¦Agentç±»
class LangChainFinancialAgent:
    def __init__(self, provider="gemini_proxy", model="gemini-2.5-flash", use_langgraph=False):
        if use_langgraph:
            self.agent = create_langgraph_financial_agent()
        else:
            self.agent = create_financial_agent(provider, model)

        self.use_langgraph = use_langgraph
        self.callback_handler = FinancialCallbackHandler()

    async def analyze(self, query: str, session_id: str = None) -> str:
        """æ‰§è¡Œé‡‘èåˆ†æ"""
        if self.use_langgraph:
            # LangGraphç‰ˆæœ¬
            initial_state = {
                "messages": [{"content": query, "type": "human"}],
                "current_step": "thinking",
                "observations": [],
                "report_generated": False,
                "analysis_ticker": self._extract_ticker(query)
            }

            config = {"configurable": {"thread_id": session_id or "default"}}
            result = await self.agent.ainvoke(initial_state, config=config)

            return self._extract_report_from_state(result)
        else:
            # ä¼ ç»ŸAgentExecutorç‰ˆæœ¬
            result = await self.agent.ainvoke({
                "input": query,
                "chat_history": []
            })

            return result["output"]

    def _extract_ticker(self, query: str) -> str:
        """ä»æŸ¥è¯¢ä¸­æå–è‚¡ç¥¨ä»£ç """
        import re
        ticker_pattern = r'\b([A-Z]{1,5})\b'
        matches = re.findall(ticker_pattern, query.upper())
        return matches[0] if matches else "UNKNOWN"

    def _extract_report_from_state(self, state: dict) -> str:
        """ä»çŠ¶æ€ä¸­æå–æœ€ç»ˆæŠ¥å‘Š"""
        messages = state.get("messages", [])
        for message in reversed(messages):
            if message.get("type") == "ai" and len(message.get("content", "")) > 500:
                return message["content"]
        return "æ— æ³•ç”ŸæˆæŠ¥å‘Š"
```

#### é˜¶æ®µ4: æµå¼å’Œå®æ—¶æ›´æ–° (ç¬¬5å¤©)

**åˆ›å»º streaming_support.py:**
```python
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult
from typing import Any, Dict, List, Optional
import asyncio
from datetime import datetime
import json

class FinancialStreamingCallbackHandler(BaseCallbackHandler):
    """é‡‘èåˆ†æä¸“ç”¨çš„æµå¼å›è°ƒå¤„ç†å™¨"""

    def __init__(self, show_intermediate_steps: bool = True):
        self.show_intermediate_steps = show_intermediate_steps
        self.step_count = 0
        self.observation_count = 0
        self.start_time = datetime.now()
        self.current_thought = ""
        self.current_action = ""

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs) -> None:
        """LLMå¼€å§‹æ—¶çš„å›è°ƒ"""
        print("ğŸ§  AIæ€è€ƒä¸­...")

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        """æ¯ä¸ªæ–°tokençš„å›è°ƒ - å®ç°å®æ—¶æ˜¾ç¤º"""
        if "Thought:" in token:
            self.current_thought = ""
            print("\nğŸ’­ æ€è€ƒ:", end=" ", flush=True)
        elif "Action:" in token:
            self.current_action = ""
            print("\nğŸ”§ æ‰§è¡ŒåŠ¨ä½œ:", end=" ", flush=True)
        elif "```json" in token:
            print("\nğŸ“‹ JSONæŒ‡ä»¤:", end=" ", flush=True)
        elif token.strip() and not token.startswith("```"):
            print(token, end="", flush=True)

    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        """LLMç»“æŸæ—¶çš„å›è°ƒ"""
        print()  # æ¢è¡Œ

    def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs) -> None:
        """å·¥å…·å¼€å§‹æ‰§è¡Œæ—¶çš„å›è°ƒ"""
        tool_name = serialized.get("name", "unknown_tool")
        self.step_count += 1
        print(f"\nğŸ› ï¸  æ­¥éª¤ {self.step_count}: æ­£åœ¨è°ƒç”¨ {tool_name}")
        if input_str and input_str != "{}":
            try:
                data = json.loads(input_str)
                if "ticker" in data:
                    print(f"   ğŸ“Š è‚¡ç¥¨ä»£ç : {data['ticker']}")
                elif "query" in data:
                    print(f"   ğŸ” æœç´¢æŸ¥è¯¢: {data['query']}")
            except:
                print(f"   ğŸ“ è¾“å…¥: {input_str[:100]}...")

    def on_tool_end(self, output: str, **kwargs) -> None:
        """å·¥å…·æ‰§è¡Œå®Œæˆæ—¶çš„å›è°ƒ"""
        self.observation_count += 1
        print(f"   âœ… å®Œæˆ! è·å¾—æ•°æ®ç‚¹ #{self.observation_count}")

        # æ˜¾ç¤ºè¾“å‡ºæ‘˜è¦
        if len(output) > 200:
            print(f"   ğŸ“„ ç»“æœæ‘˜è¦: {output[:200]}...")
        else:
            print(f"   ğŸ“„ ç»“æœ: {output}")

    def on_agent_finish(self, finish, **kwargs) -> None:
        """Agentå®Œæˆæ—¶çš„å›è°ƒ"""
        end_time = datetime.now()
        duration = end_time - self.start_time

        print(f"\n{'='*60}")
        print("ğŸ‰ é‡‘èåˆ†æå®Œæˆ!")
        print(f"{'='*60}")
        print(f"â±ï¸  æ€»è€—æ—¶: {duration.total_seconds():.2f} ç§’")
        print(f"ğŸ”§ æ‰§è¡Œæ­¥éª¤: {self.step_count}")
        print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {self.observation_count}")
        print(f"ğŸ“… åˆ†ææ—¶é—´: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")

class AsyncFinancialStreamer:
    """å¼‚æ­¥æµå¼é‡‘èåˆ†æå™¨"""

    def __init__(self, agent):
        self.agent = agent
        self.streaming_handler = FinancialStreamingCallbackHandler()

    async def stream_analysis(self, query: str) -> str:
        """æ‰§è¡Œæµå¼é‡‘èåˆ†æ"""
        print(f"ğŸ“ˆ å¼€å§‹åˆ†æ: {query}")
        print("=" * 60)

        try:
            # å¼‚æ­¥æ‰§è¡Œåˆ†æ
            result = await self.agent.ainvoke(
                {"input": query, "chat_history": []},
                callbacks=[self.streaming_handler]
            )

            return result["output"]

        except Exception as e:
            print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return f"åˆ†æå¤±è´¥: {str(e)}"

    def sync_stream_analysis(self, query: str) -> str:
        """åŒæ­¥ç‰ˆæœ¬çš„æµå¼åˆ†æ"""
        return asyncio.run(self.stream_analysis(query))

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    from langchain_agent import LangChainFinancialAgent

    # åˆ›å»ºAgent
    agent = LangChainFinancialAgent()

    # åˆ›å»ºæµå¼åˆ†æå™¨
    streamer = AsyncFinancialStreamer(agent)

    # æ‰§è¡Œåˆ†æ
    query = "åˆ†æAAPLè‚¡ç¥¨çš„å½“å‰æŠ•èµ„æœºä¼š"
    report = await streamer.stream_analysis(query)

    print("\nğŸ“‹ æœ€ç»ˆæŠ¥å‘Š:")
    print(report)

if __name__ == "__main__":
    asyncio.run(main())
```

#### é˜¶æ®µ5: æ›´æ–°ä¸»ç¨‹åº (ç¬¬6å¤©)

**æ›´æ–° main.py:**
```python
#!/usr/bin/env python3
"""
FinSight - AIé©±åŠ¨çš„é‡‘èåˆ†æä»£ç† (LangChainç‰ˆæœ¬)
ä½¿ç”¨æœ€æ–°çš„LangChain 0.3.xå’ŒLangGraphå®ç°
"""

import asyncio
import argparse
import sys
from typing import Optional
from datetime import datetime

from langchain_agent import LangChainFinancialAgent
from streaming_support import AsyncFinancialStreamer
from config import DEFAULT_LLM_PROVIDER, DEFAULT_LLM_MODEL

class FinSightLangChain:
    """FinSightä¸»åº”ç”¨ç¨‹åºç±»"""

    def __init__(self,
                 provider: str = DEFAULT_LLM_PROVIDER,
                 model: str = DEFAULT_LLM_MODEL,
                 use_langgraph: bool = False,
                 streaming: bool = True):
        """
        åˆå§‹åŒ–FinSight

        Args:
            provider: LLMæä¾›å•†
            model: æ¨¡å‹åç§°
            use_langgraph: æ˜¯å¦ä½¿ç”¨LangGraphç‰ˆæœ¬
            streaming: æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
        """
        self.agent = LangChainFinancialAgent(
            provider=provider,
            model=model,
            use_langgraph=use_langgraph
        )
        self.streamer = AsyncFinancialStreamer(self.agent) if streaming else None
        self.version = "2.0.0 (LangChain)"

    async def analyze_async(self, query: str, session_id: Optional[str] = None) -> str:
        """å¼‚æ­¥æ‰§è¡Œåˆ†æ"""
        print(f"ğŸš€ FinSight v{self.version} - AIé‡‘èåˆ†æç³»ç»Ÿ")
        print(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ æŸ¥è¯¢å†…å®¹: {query}")
        print("=" * 70)

        try:
            if self.streamer:
                # ä½¿ç”¨æµå¼è¾“å‡º
                result = await self.streamer.stream_analysis(query)
            else:
                # éæµå¼è¾“å‡º
                result = await self.agent.analyze(query, session_id)

            return result

        except KeyboardInterrupt:
            print("\nâš ï¸  åˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
            return "åˆ†æå·²ä¸­æ–­"
        except Exception as e:
            print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
            return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"

    def analyze(self, query: str, session_id: Optional[str] = None) -> str:
        """åŒæ­¥æ‰§è¡Œåˆ†æ"""
        return asyncio.run(self.analyze_async(query, session_id))

    async def interactive_mode(self):
        """äº¤äº’å¼åˆ†ææ¨¡å¼"""
        print(f"\nğŸ‰ æ¬¢è¿ä½¿ç”¨ FinSight v{self.version} äº¤äº’æ¨¡å¼!")
        print("ğŸ’¡ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºç¨‹åº")
        print("ğŸ’¡ è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
        print("-" * 70)

        session_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        while True:
            try:
                query = input("\nğŸ“ˆ è¯·è¾“å…¥è¦åˆ†æçš„è‚¡ç¥¨æˆ–å¸‚åœº: ").strip()

                if query.lower() in ['quit', 'exit', 'q']:
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ FinSightï¼Œå†è§!")
                    break
                elif query.lower() == 'help':
                    self._show_help()
                    continue
                elif not query:
                    print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æŸ¥è¯¢å†…å®¹")
                    continue

                # æ‰§è¡Œåˆ†æ
                result = await self.analyze_async(query, session_id)

                # è¯¢é—®æ˜¯å¦ç»§ç»­
                if input("\nâ“ ç»§ç»­åˆ†æå…¶ä»–å†…å®¹? (y/n): ").lower() != 'y':
                    break

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§!")
                break
            except Exception as e:
                print(f"\nâŒ å‡ºç°é”™è¯¯: {str(e)}")
                if input("â“ æ˜¯å¦ç»§ç»­? (y/n): ").lower() != 'y':
                    break

    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = """
ğŸ” FinSight ä½¿ç”¨è¯´æ˜:

ğŸ“Š æ”¯æŒçš„åˆ†æç±»å‹:
   â€¢ ä¸ªè‚¡åˆ†æ: AAPL, NVDA, TSLA, MSFT ç­‰
   â€¢ å¸‚åœºæŒ‡æ•°: ^GSPC (æ ‡æ™®500), ^IXIC (çº³æ–¯è¾¾å…‹), ^DJI (é“ç¼æ–¯) ç­‰
   â€¢ åŠ å¯†è´§å¸: BTC-USD, ETH-USD ç­‰
   â€¢ è¡Œä¸šåˆ†æ: ç§‘æŠ€è‚¡, é‡‘èè‚¡, åŒ»ç–—è‚¡ç­‰

ğŸ’¡ æŸ¥è¯¢ç¤ºä¾‹:
   â€¢ "åˆ†æAAPLè‚¡ç¥¨"
   â€¢ "è¯„ä¼°çº³æ–¯è¾¾å…‹æŒ‡æ•°æŠ•èµ„æœºä¼š"
   â€¢ "å¯¹æ¯”NVDAå’ŒAMDçš„æŠ•èµ„ä»·å€¼"
   â€¢ "ç‰¹æ–¯æ‹‰å½“å‰é£é™©åˆ†æ"

ğŸ¯ åˆ†ææŠ¥å‘ŠåŒ…å«:
   â€¢ æ‰§è¡Œæ‘˜è¦å’Œæ˜ç¡®å»ºè®®
   â€¢ å½“å‰å¸‚åœºçŠ¶å†µå’ŒæŠ€æœ¯æŒ‡æ ‡
   â€¢ å®è§‚ç¯å¢ƒå’Œå‚¬åŒ–å‰‚åˆ†æ
   â€¢ é£é™©è¯„ä¼°å’Œå†å²å›æ’¤
   â€¢ å…·ä½“çš„å…¥åœº/å‡ºåœºç­–ç•¥
   â€¢ ç‰›/ç†Š/åŸºå‡†ä¸‰ç§æƒ…æ™¯åˆ†æ

âš™ï¸ é«˜çº§åŠŸèƒ½:
   â€¢ æµå¼å®æ—¶æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
   â€¢ æ™ºèƒ½å¤šæºæ•°æ®è·å–
   â€¢ ä¸“ä¸šCIOçº§åˆ«æŠ¥å‘Šç”Ÿæˆ
   â€¢ å†å²åˆ†æå’Œå¯¹æ¯”åŠŸèƒ½

æ›´å¤šä¿¡æ¯è¯·è®¿é—®é¡¹ç›®ä¸»é¡µæˆ–æŸ¥çœ‹æ–‡æ¡£ã€‚
        """
        print(help_text)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="FinSight - AIé©±åŠ¨çš„é‡‘èåˆ†æä»£ç† (LangChainç‰ˆæœ¬)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python main.py                           # äº¤äº’æ¨¡å¼
  python main.py "åˆ†æAAPLè‚¡ç¥¨"            # å•æ¬¡åˆ†æ
  python main.py --provider openai --model gpt-4 "NVDAåˆ†æ"   # æŒ‡å®šæ¨¡å‹
  python main.py --langgraph --no-stream "å¯¹æ¯”ç§‘æŠ€è‚¡"         # ä½¿ç”¨LangGraph
        """
    )

    parser.add_argument(
        "query",
        nargs="?",
        help="è¦åˆ†æçš„é‡‘èæ ‡çš„æŸ¥è¯¢"
    )

    parser.add_argument(
        "--provider",
        default=DEFAULT_LLM_PROVIDER,
        help=f"LLMæä¾›å•† (é»˜è®¤: {DEFAULT_LLM_PROVIDER})"
    )

    parser.add_argument(
        "--model",
        default=DEFAULT_LLM_MODEL,
        help=f"LLMæ¨¡å‹ (é»˜è®¤: {DEFAULT_LLM_MODEL})"
    )

    parser.add_argument(
        "--langgraph",
        action="store_true",
        help="ä½¿ç”¨LangGraphç‰ˆæœ¬Agent (æ›´é«˜çº§çš„æ§åˆ¶)"
    )

    parser.add_argument(
        "--no-stream",
        action="store_true",
        help="ç¦ç”¨æµå¼è¾“å‡º"
    )

    parser.add_argument(
        "--version",
        action="version",
        version="FinSight 2.0.0 (LangChain)"
    )

    args = parser.parse_args()

    # åˆ›å»ºFinSightå®ä¾‹
    finsight = FinSightLangChain(
        provider=args.provider,
        model=args.model,
        use_langgraph=args.langgraph,
        streaming=not args.no_stream
    )

    try:
        if args.query:
            # å•æ¬¡åˆ†ææ¨¡å¼
            print("ğŸ¯ å•æ¬¡åˆ†ææ¨¡å¼")
            result = finsight.analyze(args.query)

            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ (å¯é€‰)
            if input("\nâ“ æ˜¯å¦ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶? (y/n): ").lower() == 'y':
                filename = f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(result)
                print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        else:
            # äº¤äº’æ¨¡å¼
            asyncio.run(finsight.interactive_mode())

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

#### é˜¶æ®µ6: æµ‹è¯•å’ŒéªŒè¯ (ç¬¬7å¤©)

**åˆ›å»º test_langchain_migration.py:**
```python
#!/usr/bin/env python3
"""
LangChainè¿ç§»æµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import unittest
from datetime import datetime
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from langchain_agent import LangChainFinancialAgent
from langchain_tools import FINANCIAL_TOOLS
from streaming_support import AsyncFinancialStreamer

class TestLangChainMigration(unittest.TestCase):
    """LangChainè¿ç§»æµ‹è¯•ç±»"""

    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.agent = LangChainFinancialAgent()
        self.streamer = AsyncFinancialStreamer(self.agent)

    def test_tools_loading(self):
        """æµ‹è¯•å·¥å…·åŠ è½½"""
        print("\nğŸ”§ æµ‹è¯•å·¥å…·åŠ è½½...")

        self.assertGreater(len(FINANCIAL_TOOLS), 0)

        # éªŒè¯æ¯ä¸ªå·¥å…·éƒ½æœ‰å¿…è¦çš„å±æ€§
        for tool in FINANCIAL_TOOLS:
            self.assertTrue(hasattr(tool, 'name'))
            self.assertTrue(hasattr(tool, 'description'))
            self.assertTrue(hasattr(tool, 'args_schema'))

        print(f"   âœ… æˆåŠŸåŠ è½½ {len(FINANCIAL_TOOLS)} ä¸ªå·¥å…·")

    async def test_basic_analysis(self):
        """æµ‹è¯•åŸºæœ¬åˆ†æåŠŸèƒ½"""
        print("\nğŸ“Š æµ‹è¯•åŸºæœ¬åˆ†æåŠŸèƒ½...")

        query = "è·å–AAPLçš„åŸºæœ¬ä¿¡æ¯"
        result = await self.agent.analyze(query)

        self.assertIsNotNone(result)
        self.assertGreater(len(result), 100)  # ç»“æœåº”è¯¥æœ‰å®è´¨å†…å®¹

        print(f"   âœ… åŸºæœ¬åˆ†ææµ‹è¯•é€šè¿‡ï¼Œç»“æœé•¿åº¦: {len(result)}")

    async def test_streaming_analysis(self):
        """æµ‹è¯•æµå¼åˆ†æåŠŸèƒ½"""
        print("\nğŸŒŠ æµ‹è¯•æµå¼åˆ†æåŠŸèƒ½...")

        query = "è·å–å½“å‰å¸‚åœºæ—¶é—´"
        result = await self.streamer.stream_analysis(query)

        self.assertIsNotNone(result)
        self.assertIn(datetime.now().strftime("%Y-%m-%d"), result)

        print(f"   âœ… æµå¼åˆ†ææµ‹è¯•é€šè¿‡")

    def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\nâš ï¸  æµ‹è¯•é”™è¯¯å¤„ç†...")

        # æµ‹è¯•æ— æ•ˆæŸ¥è¯¢
        with self.assertRaises(Exception):
            asyncio.run(self.agent.analyze(""))

        print("   âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

async def run_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹LangChainè¿ç§»æµ‹è¯•")
    print("=" * 50)

    test = TestLangChainMigration()
    test.setUp()

    try:
        test.test_tools_loading()
        await test.test_basic_analysis()
        await test.test_streaming_analysis()
        test.test_error_handling()

        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! LangChainè¿ç§»æˆåŠŸ!")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    asyncio.run(run_tests())
```

### ğŸ¯ è¿ç§»åçš„ä¼˜åŠ¿

**1. æ›´å¥½çš„å¯ç»´æŠ¤æ€§**
- ä½¿ç”¨LangChainæ ‡å‡†åŒ–æ¡†æ¶
- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•
- å®Œæ•´çš„ç±»å‹æç¤º

**2. å¼ºå¤§çš„æµå¼ä½“éªŒ**
- å®æ—¶æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹
- ç”¨æˆ·å‹å¥½çš„è¿›åº¦æ˜¾ç¤º
- å¯ä¸­æ–­çš„é•¿æ—¶é—´è¿è¡Œä»»åŠ¡

**3. ä¼ä¸šçº§å¯é æ€§**
- å†…ç½®é‡è¯•å’Œé”™è¯¯æ¢å¤
- å®Œæ•´çš„æ—¥å¿—å’Œç›‘æ§
- ç”Ÿäº§å°±ç»ªçš„æ¶æ„

**4. æœ€æ–°æŠ€æœ¯æ ˆ**
- LangChain 0.3.xæœ€æ–°ç‰¹æ€§
- LangGraphé«˜çº§Agentæ§åˆ¶
- ç°ä»£å¼‚æ­¥ç¼–ç¨‹æ¨¡å¼

**5. æ˜“äºæ‰©å±•**
- æ·»åŠ æ–°å·¥å…·åªéœ€@toolè£…é¥°å™¨
- æ”¯æŒè‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
- æ¨¡å—åŒ–çš„Promptç®¡ç†

### ğŸ“‹ è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] å¤‡ä»½ç°æœ‰ä»£ç 
- [ ] æ›´æ–°requirements.txt
- [ ] åˆ›å»ºlangchain_tools.py
- [ ] é‡æ„agent.pyä¸ºlangchain_agent.py
- [ ] å®ç°streaming_support.py
- [ ] æ›´æ–°main.pyä¸»ç¨‹åº
- [ ] è¿è¡Œè¿ç§»æµ‹è¯•
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] æ–‡æ¡£æ›´æ–°
- [ ] éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

è¿™ä¸ªè¿ç§»æ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº†LangChain 0.3.xçš„æœ€æ–°ç‰¹æ€§ï¼ŒåŒæ—¶ä¿æŒäº†åŸæœ‰ç³»ç»Ÿçš„æ‰€æœ‰åŠŸèƒ½ï¼Œå¹¶å¤§å¹…æå‡äº†ç”¨æˆ·ä½“éªŒå’Œä»£ç è´¨é‡ã€‚

# 1. å®ç°æ™ºèƒ½rate limiting
from collections import deque
from time import time

class RateLimiter:
    def __init__(self, max_calls, time_window):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = deque()
    
    def wait_if_needed(self):
        now = time()
        # æ¸…é™¤æ—¶é—´çª—å£å¤–çš„è®°å½•
        while self.calls and self.calls[0] < now - self.time_window:
            self.calls.popleft()
        
        if len(self.calls) >= self.max_calls:
            sleep_time = self.time_window - (now - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(now)

# ä½¿ç”¨ç¤ºä¾‹
yfinance_limiter = RateLimiter(max_calls=2000, time_window=3600)  # æ¯å°æ—¶2000æ¬¡
é•¿æœŸæ–¹æ¡ˆï¼ˆæ¶æ„å‡çº§ï¼‰ï¼š
python# 4. å»ºç«‹æ•°æ®ç¼“å­˜å±‚
import redis
import pickle

class DataCache:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.ttl = {
            'stock_price': 60,        # 1åˆ†é’Ÿ
            'company_info': 86400,    # 1å¤©
            'news': 1800,             # 30åˆ†é’Ÿ
        }
    
    def get(self, key, data_type):
        cached = self.redis_client.get(key)
        if cached:
            return pickle.loads(cached)
        return None
    
    def set(self, key, value, data_type):
        self.redis_client.setex(
            key, 
            self.ttl.get(data_type, 3600),
            pickle.dumps(value)
        )

2. RAGåº”ç”¨åœºæ™¯å»ºè®®
æœ€é€‚åˆå­˜å‚¨çš„å†…å®¹ï¼š
A. å†å²è´¢æŠ¥ä¸å…¬å¸æ–‡æ¡£ â­â­â­â­â­
pythonrag_content = {
    "10-Kå¹´æŠ¥": "å®Œæ•´çš„å¹´åº¦è´¢æŠ¥PDF",
    "10-Qå­£æŠ¥": "å­£åº¦è´¢æŠ¥",
    "8-Ké‡å¤§äº‹ä»¶": "å…¬å¸é‡å¤§å˜æ›´å…¬å‘Š",
    "æŠ•èµ„è€…æ¼”ç¤º": "Investor Presentation slides",
    "åˆ†æå¸ˆç”µè¯ä¼šè®®è®°å½•": "Earnings call transcripts"
}
ä¸ºä»€ä¹ˆé‡è¦ï¼š

è¿™äº›æ–‡æ¡£åŒ…å«å¤§é‡ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®
LLMå¯ä»¥ä»ä¸­æå–å…³é”®è´¢åŠ¡æŒ‡æ ‡ã€ç®¡ç†å±‚å±•æœ›ã€é£é™©å› ç´ 
æ”¯æŒè·¨å­£åº¦å¯¹æ¯”åˆ†æ

B. è¡Œä¸šç ”ç©¶æŠ¥å‘Šåº“ â­â­â­â­
pythonresearch_docs = {
    "è¡Œä¸šè¶‹åŠ¿æŠ¥å‘Š": "McKinsey, Gartnerç­‰å’¨è¯¢å…¬å¸æŠ¥å‘Š",
    "åˆ¸å•†ç ”æŠ¥": "Goldman Sachs, Morgan Stanleyæ·±åº¦ç ”ç©¶",
    "å­¦æœ¯è®ºæ–‡": "é‡‘èå·¥ç¨‹ã€é‡åŒ–æ¨¡å‹ç›¸å…³è®ºæ–‡",
    "ç›‘ç®¡æ–‡ä»¶": "SECè§„åˆ™ã€åˆè§„è¦æ±‚"
}
C. å†å²å¸‚åœºäº‹ä»¶ä¸æ¡ˆä¾‹ â­â­â­â­
pythonhistorical_cases = {
    "å±æœºæ¡ˆä¾‹": "2008é‡‘èå±æœºã€2020ç–«æƒ…å´©ç›˜çš„è¯¦ç»†æ—¶é—´çº¿",
    "æˆåŠŸæŠ•èµ„æ¡ˆä¾‹": "BuffettæŠ•èµ„å¯å£å¯ä¹çš„å®Œæ•´æ•…äº‹",
    "å…¬å¸ç ´äº§æ¡ˆä¾‹": "Lehman Brothers, Enronè¯¦ç»†åˆ†æ",
    "ç›‘ç®¡å¤„ç½šæ¡ˆä¾‹": "å†…å¹•äº¤æ˜“ã€å¸‚åœºæ“çºµæ¡ˆä¾‹åº“"
}
D. æŠ€æœ¯æŒ‡æ ‡ä¸é‡åŒ–ç­–ç•¥çŸ¥è¯†åº“ â­â­â­
pythonquant_knowledge = {
    "æŠ€æœ¯æŒ‡æ ‡è¯´æ˜": "MACD, RSI, Bollinger Bandsè¯¦ç»†è§£é‡Š",
    "é‡åŒ–ç­–ç•¥": "åŠ¨é‡ç­–ç•¥ã€å‡å€¼å›å½’ã€é…å¯¹äº¤æ˜“çš„å®ç°ç»†èŠ‚",
    "é£é™©æ¨¡å‹": "VaR, CVaR, Sharpe Ratioçš„è®¡ç®—ä¸è§£è¯»"
}
å®ç°ç¤ºä¾‹ï¼š
pythonfrom langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

class FinancialRAG:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            persist_directory="./financial_knowledge_base",
            embedding_function=self.embeddings
        )
    
    def ingest_10k(self, ticker: str, pdf_path: str):
        """å¯¼å…¥10-Kå¹´æŠ¥"""
        from langchain.document_loaders import PyPDFLoader
        
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        
        # æ™ºèƒ½åˆ†å—ï¼šä¿æŒè´¢åŠ¡è¡¨æ ¼å®Œæ•´æ€§
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n\n", "\n\n", "\n", " "]
        )
        chunks = splitter.split_documents(documents)
        
        # æ·»åŠ å…ƒæ•°æ®
        for chunk in chunks:
            chunk.metadata.update({
                "ticker": ticker,
                "doc_type": "10-K",
                "year": 2024
            })
        
        self.vectorstore.add_documents(chunks)
    
    def query_company_risks(self, ticker: str, query: str):
        """æŸ¥è¯¢å…¬å¸é£é™©å› ç´ """
        results = self.vectorstore.similarity_search(
            query,
            filter={"ticker": ticker, "doc_type": "10-K"},
            k=5
        )
        return results

3. è¿ç§»åˆ°LangChainçš„å‡†å¤‡å·¥ä½œ
å½“å‰æ¶æ„ vs LangChainæ¶æ„å¯¹æ¯”ï¼š
ç»„ä»¶å½“å‰å®ç°LangChainç­‰æ•ˆAgentå¾ªç¯æ‰‹åŠ¨å®ç°ReActAgentExecutor + create_react_agentå·¥å…·å®šä¹‰æ™®é€šå‡½æ•° + å­—å…¸@tool è£…é¥°å™¨ + Tool ç±»LLMè°ƒç”¨è‡ªå®šä¹‰call_llmChatOpenAI / ChatAnthropicæç¤ºè¯å·¨å¤§çš„å­—ç¬¦ä¸²PromptTemplate + ChatPromptTemplateè®°å¿†Messagesåˆ—è¡¨ConversationBufferMemory
è¿ç§»æ­¥éª¤ï¼š
Step 1: å·¥å…·æ ‡å‡†åŒ–
python# å½“å‰æ–¹å¼
def get_stock_price(ticker: str) -> str:
    ...

# LangChainæ–¹å¼
from langchain.tools import tool

@tool
def get_stock_price(ticker: str) -> str:
    """Get current stock price and daily change.
    
    Args:
        ticker: Stock ticker symbol (e.g., 'AAPL', 'NVDA')
    
    Returns:
        String with current price and change percentage
    """
    # å®ç°ä¿æŒä¸å˜
    ...
Step 2: æç¤ºè¯æ¨¡å—åŒ–
pythonfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

cio_template = ChatPromptTemplate.from_messages([
    ("system", """You are a Chief Investment Officer (CIO).
    Today's date is {current_date}.
    
    PHASE 1: DATA COLLECTION
    {data_collection_instructions}
    
    PHASE 2: REPORT GENERATION
    {report_structure}
    """),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])
Step 3: Agentæ„å»º
pythonfrom langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4", temperature=0)

tools = [
    get_stock_price,
    get_company_news,
    search,
    # ... å…¶ä»–å·¥å…·
]

agent = create_react_agent(llm, tools, cio_template)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=20,
    handle_parsing_errors=True,
    return_intermediate_steps=True
)
Step 4: æ·»åŠ å›è°ƒä¸ç›‘æ§
pythonfrom langchain.callbacks import StdOutCallbackHandler, FileCallbackHandler

callbacks = [
    StdOutCallbackHandler(),
    FileCallbackHandler("agent_logs.txt")
]

result = agent_executor.invoke(
    {"input": user_query, "current_date": datetime.now()},
    callbacks=callbacks
)
è¿ç§»åçš„ä¼˜åŠ¿ï¼š

æ›´å¥½çš„é”™è¯¯å¤„ç† - LangChainå†…ç½®retryå’Œfallback
æµå¼è¾“å‡º - æ”¯æŒæµå¼æ˜¾ç¤ºThought/Action/Observation
å¯è§‚æµ‹æ€§ - LangSmithè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è°ƒç”¨
ç¤¾åŒºå·¥å…· - ç›´æ¥ä½¿ç”¨100+ LangChainå®˜æ–¹å·¥å…·
æ›´å®¹æ˜“æ‰©å±• - æ·»åŠ æ–°å·¥å…·åªéœ€@toolè£…é¥°å™¨


4. æ•´ä½“è¯„ä»·ä¸æå‡å»ºè®®
å½“å‰æ°´å¹³è¯„ä¼°ï¼šğŸŒŸğŸŒŸğŸŒŸâ˜†â˜† (3/5)
âœ… åšå¾—å¥½çš„åœ°æ–¹ï¼š

æ¸…æ™°çš„ReActå¾ªç¯ - æ‰‹åŠ¨å®ç°å±•ç¤ºäº†å¯¹AgentåŸç†çš„æ·±åˆ»ç†è§£
å…¨é¢çš„æŠ¥å‘Šç»“æ„ - æ¨¡æ¿éå¸¸ä¸“ä¸šï¼Œæ¶µç›–äº†æŠ•èµ„åˆ†æçš„æ‰€æœ‰è¦ç´ 
å¤šå·¥å…·é›†æˆ - è™½ç„¶æœ‰å¤±æ•ˆï¼Œä½†å·¥å…·ç§ç±»é½å…¨
é”™è¯¯å¤„ç†æ„è¯† - æœ‰fallbackæœºåˆ¶ï¼ˆsearchä½œä¸ºå¤‡ç”¨ï¼‰

âŒ æ˜æ˜¾çš„é—®é¢˜ï¼š

æ•°æ®æºè„†å¼± - 80%çš„å·¥å…·ä¾èµ–yfinanceï¼Œå•ç‚¹æ•…éšœä¸¥é‡
æ— ç¼“å­˜æœºåˆ¶ - é‡å¤æŸ¥è¯¢æµªè´¹API quota
æŠ¥å‘Šè´¨é‡ä¸ç¨³å®š - ä¾èµ–LLMå½“å‰çŠ¶æ€ï¼Œæ²¡æœ‰è´¨é‡ä¿è¯
æ— æ³•å¤„ç†å¤æ‚æŸ¥è¯¢ - æ¯”å¦‚"å¯¹æ¯”NVDAå’ŒAMDï¼Œè€ƒè™‘AIè¡Œä¸šè¶‹åŠ¿ï¼Œç»™æˆ‘æŠ•èµ„å»ºè®®"

ğŸ¯ å€¼å¾—æå‡çš„å…³é”®ç‚¹ï¼š
ä¼˜å…ˆçº§1ï¼šæ•°æ®å±‚é‡æ„ â­â­â­â­â­
python# å»ºç«‹æ•°æ®æŠ½è±¡å±‚
class DataProvider(ABC):
    @abstractmethod
    def get_stock_price(self, ticker: str) -> StockPrice:
        pass

class YFinanceProvider(DataProvider):
    ...

class AlphaVantageProvider(DataProvider):
    ...

class CompositeProvider(DataProvider):
    """è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æ•°æ®æº"""
    def __init__(self, providers: List[DataProvider]):
        self.providers = providers
    
    def get_stock_price(self, ticker: str) -> StockPrice:
        for provider in self.providers:
            try:
                return provider.get_stock_price(ticker)
            except Exception:
                continue
        raise AllProvidersFailedError()
ä¼˜å…ˆçº§2ï¼šæŠ¥å‘Šè´¨é‡éªŒè¯ â­â­â­â­
pythonclass ReportValidator:
    def validate(self, report: str) -> ValidationResult:
        checks = [
            self._check_has_recommendation,  # å¿…é¡»æœ‰BUY/SELL/HOLD
            self._check_has_price_target,    # å¿…é¡»æœ‰å…·ä½“ç›®æ ‡ä»·
            self._check_date_accuracy,       # æ—¥æœŸå¿…é¡»æ­£ç¡®
            self._check_minimum_length,      # è‡³å°‘800å­—
            self._check_has_risk_section,    # å¿…é¡»æœ‰é£é™©åˆ†æ
        ]
        
        for check in checks:
            if not check(report):
                return ValidationResult(
                    valid=False,
                    failed_check=check.__name__
                )
        
        return ValidationResult(valid=True)

# ä½¿ç”¨ç¤ºä¾‹
validator = ReportValidator()
if not validator.validate(final_answer):
    # è¦æ±‚LLMé‡æ–°ç”Ÿæˆ
    messages.append({
        "role": "user",
        "content": f"Report validation failed: {validator.failed_check}. Please revise."
    })
ä¼˜å…ˆçº§3ï¼šå¼•å…¥Evaluation â­â­â­â­
python# å»ºç«‹æµ‹è¯•ç”¨ä¾‹é›†
test_cases = [
    {
        "query": "Analyze NVIDIA stock",
        "expected_ticker": "NVDA",
        "must_include": ["AI", "GPU", "data center"],
        "must_have_section": ["Risk Assessment", "Price Target"]
    },
    {
        "query": "Compare tech stocks",
        "expected_tickers": ["AAPL", "MSFT", "GOOGL"],
        "must_include": ["performance comparison"]
    }
]

def evaluate_agent(agent, test_cases):
    results = []
    for case in test_cases:
        output = agent.run(case["query"])
        score = {
            "ticker_accuracy": check_tickers(output, case["expected_ticker"]),
            "keyword_coverage": check_keywords(output, case["must_include"]),
            "structure_completeness": check_sections(output, case["must_have_section"]),
            "word_count": len(output.split())
        }
        results.append(score)
    
    return pd.DataFrame(results).mean()
ä¼˜å…ˆçº§4ï¼šç”¨æˆ·ä½“éªŒä¼˜åŒ– â­â­â­
python# æ·»åŠ æµå¼è¾“å‡º
import sys

def stream_agent_thoughts(agent, query):
    """å®æ—¶æ˜¾ç¤ºAgentæ€è€ƒè¿‡ç¨‹"""
    for step in agent.stream(query):
        if step['type'] == 'thought':
            print(f"ğŸ’­ {step['content']}", flush=True)
        elif step['type'] == 'action':
            print(f"ğŸ”§ Executing: {step['tool']}", flush=True)
        elif step['type'] == 'observation':
            print(f"ğŸ“Š Result: {step['content'][:100]}...", flush=True)
        sys.stdout.flush()

# æ·»åŠ è¿›åº¦æ¡
from tqdm import tqdm

with tqdm(total=6, desc="Collecting data") as pbar:
    for observation in agent.collect_data():
        pbar.update(1)
        pbar.set_postfix({"current": observation['tool']})
æœ€ç»ˆåˆ¤æ–­ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å­¦ä¹ é¡¹ç›®ï¼Œä½†è·ç¦»ç”Ÿäº§å¯ç”¨è¿˜æœ‰å·®è·
èƒ½ç”¨å—ï¼Ÿ

âœ… å­¦ä¹ å’Œæ¼”ç¤ºï¼šå®Œå…¨å¯ä»¥
âœ… ä¸ªäººç ”ç©¶ï¼šå¯ä»¥ï¼Œä½†éœ€è¦æ‰‹åŠ¨éªŒè¯æ•°æ®
âŒ çœŸå®äº¤æ˜“å†³ç­–ï¼šç»å¯¹ä¸è¡Œ
âŒ ä¼ä¸šçº§åº”ç”¨ï¼šéœ€è¦å¤§å¹…æ”¹é€ 

å¦‚ä½•è¾¾åˆ°ç”Ÿäº§çº§åˆ«ï¼š

è§£å†³æ•°æ®æºé—®é¢˜ï¼ˆå¤šæº+ç¼“å­˜+ä»˜è´¹APIï¼‰
æ·»åŠ å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼ˆå•å…ƒæµ‹è¯•+é›†æˆæµ‹è¯•+è¯„ä¼°ï¼‰
å¼•å…¥ç›‘æ§å’Œå‘Šè­¦ï¼ˆæ•°æ®å¼‚å¸¸ã€APIå¤±è´¥ã€æŠ¥å‘Šè´¨é‡ä¸‹é™ï¼‰
æ·»åŠ åˆè§„æ€§æ£€æŸ¥ï¼ˆç¡®ä¿ä¸è¿åé‡‘èç›‘ç®¡è¦æ±‚ï¼‰
ç”¨æˆ·åé¦ˆå¾ªç¯ï¼ˆè®©çœŸå®ç”¨æˆ·è¯„åˆ†æŠ¥å‘Šè´¨é‡ï¼‰

æˆ‘çš„å»ºè®®ä¼˜å…ˆçº§ï¼š

ç«‹å³åšï¼šæ·»åŠ Alpha Vantage/Finnhubä½œä¸ºå¤‡ç”¨æ•°æ®æº
æœ¬å‘¨åšï¼šå®ç°æŠ¥å‘Šè´¨é‡éªŒè¯å™¨
æœ¬æœˆåšï¼šè¿ç§»åˆ°LangChain
é•¿æœŸåšï¼šå»ºç«‹RAGçŸ¥è¯†åº“+è¯„ä¼°ä½“ç³»
--
åˆ†æâ€œçº³æ–¯è¾¾å…‹â€ (^IXIC) æ—¶: å®ƒè¿”å›äº† Latest News (^IXIC): 1. [Unknown date] No title (Unknown source)... è¿™æ ·çš„æ— ç”¨ä¿¡æ¯ã€‚
åˆ†æâ€œè‹±ä¼Ÿè¾¾â€ (NVDA) æ—¶: å®ƒæˆåŠŸè¿”å›äº†5æ¡å…·ä½“çš„ã€æœ‰ä»·å€¼çš„æ–°é—»ã€‚
ä¸ºä»€ä¹ˆå¯¹æŒ‡æ•°ä¸å¥½ä½¿ï¼Ÿ
è¿™ä¸ªé—®é¢˜çš„æ ¹æºåœ¨äºæ•°æ®æºçš„æ€§è´¨å’ŒAPIçš„è®¾è®¡ã€‚

APIæ˜¯ä¸ºâ€œå…¬å¸â€è®¾è®¡çš„ï¼šæ— è®ºæ˜¯ yfinance, Finnhub è¿˜æ˜¯ Alpha Vantageï¼Œå®ƒä»¬çš„æ–°é—»APIéƒ½æ˜¯å›´ç»•å…¬å¸å®ä½“æ¥æ„å»ºçš„ã€‚å®ƒä»¬ä¼šå»æŠ“å–é‚£äº›è¢«æ˜ç¡®æ ‡è®°ä¸ºä¸ NVDAã€AAPL æˆ– MSFT ç­‰å…¬å¸ç›¸å…³çš„æ–°é—»ã€‚
æŒ‡æ•°æ˜¯â€œé›†åˆâ€ï¼Œä¸æ˜¯â€œå®ä½“â€ï¼šçº³æ–¯è¾¾å…‹æŒ‡æ•° (^IXIC) æ˜¯ä¸€ä¸ªåŒ…å«æ•°åƒå®¶å…¬å¸è‚¡ç¥¨çš„é›†åˆæˆ–ç¯®å­ã€‚å®ƒæœ¬èº«ä¸ä¼šâ€œå‘å¸ƒè´¢æŠ¥â€æˆ–â€œæ¨å‡ºæ–°äº§å“â€ã€‚å› æ­¤ï¼Œå‡ ä¹æ²¡æœ‰æ–°é—»ä¼šè¢«ç›´æ¥æ ‡è®°ä¸ºâ€œå…³äº^IXICâ€çš„æ–°é—»ã€‚
å…³äºæŒ‡æ•°çš„æ–°é—»å…¶å®æ˜¯â€œå¸‚åœºè¯„è®ºâ€ï¼šæˆ‘ä»¬é€šå¸¸æ‰€è¯´çš„â€œçº³æ–¯è¾¾å…‹æ–°é—»â€ï¼Œå®é™…ä¸Šæ˜¯å…³äºæ•´ä¸ªå¸‚åœºçš„å®è§‚æ–°é—»ã€ç»æµæ•°æ®ã€æˆ–å½±å“æŒ‡æ•°å†…æƒé‡è‚¡çš„é‡å¤§äº‹ä»¶ã€‚è¿™ç±»æ–°é—»åœ¨APIå±‚é¢å¾ˆéš¾è¢«å½’ç±»åˆ° ^IXIC è¿™ä¸ªä»£ç ä¸‹ã€‚
æ‰€ä»¥ï¼Œå½“ get_company_news æ‹¿ç€ ^IXIC å»é—®APIæ—¶ï¼ŒAPIè¦ä¹ˆæ‰¾ä¸åˆ°ï¼Œè¦ä¹ˆè¿”å›ä¸€äº›ä¸ç›¸å…³çš„ã€æ ¼å¼æ··ä¹±çš„æ•°æ®ã€‚