import yfinance as yf
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, date
import time
import re
import finnhub
import pandas as pd
import os
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# æœç´¢ç›¸å…³å¯¼å…¥ï¼ˆå·²æµ‹è¯•å¯ç”¨ï¼‰
try:
    from ddgs import DDGS  # æ–°ç‰ˆæœ¬åŒ…åï¼ˆæ¨èï¼‰
    DDGS_AVAILABLE = True
except ImportError:
    try:
        from duckduckgo_search import DDGS  # æ—§ç‰ˆæœ¬åŒ…åï¼ˆå…¼å®¹ï¼Œä½†ä¼šæ˜¾ç¤ºè­¦å‘Šï¼‰
        DDGS_AVAILABLE = True
        print("[Warning] å»ºè®®ä½¿ç”¨ 'pip install ddgs' æ›¿ä»£ 'duckduckgo_search'")
    except ImportError:
        DDGS = None
        DDGS_AVAILABLE = False
        print("[Warning] æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼šæœªå®‰è£… ddgs æˆ– duckduckgo_search")

try:
    from tavily import TavilyClient
    TAVILY_AVAILABLE = True
except ImportError:
    TavilyClient = None
    TAVILY_AVAILABLE = False
    print("[Warning] Tavily æœç´¢ä¸å¯ç”¨ï¼šæœªå®‰è£… tavily-python")

# ç»´åŸºç™¾ç§‘æ”¯æŒï¼ˆå…è´¹ï¼Œä¸éœ€è¦API keyï¼‰
try:
    import wikipedia
    wikipedia.set_lang("zh")  # è®¾ç½®ä¸­æ–‡
    WIKIPEDIA_AVAILABLE = True
except ImportError:
    wikipedia = None
    WIKIPEDIA_AVAILABLE = False
    print("[Warning] ç»´åŸºç™¾ç§‘ä¸å¯ç”¨ï¼šæœªå®‰è£… wikipediaï¼Œè¿è¡Œ: pip install wikipedia")

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================
# APIé…ç½®
# ============================================
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY", "").strip('"')  # ç§»é™¤å¯èƒ½çš„å¼•å·
FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY", "").strip('"')
MASSIVE_API_KEY = os.getenv("MASSIVE_API_KEY", "").strip('"')  # Massive.com (åŸ Polygon.io) - è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®
IEX_CLOUD_API_KEY = os.getenv("IEX_CLOUD_API_KEY", "").strip('"')  # IEX Cloud (å…è´¹é¢åº¦: 50ä¸‡æ¬¡/æœˆ)
TIINGO_API_KEY = os.getenv("TIINGO_API_KEY", "").strip('"')  # Tiingo (å…è´¹é¢åº¦: æ¯æ—¥500æ¬¡)
TWELVE_DATA_API_KEY = os.getenv("TWELVE_DATA_API_KEY", "").strip('"')  # Twelve Data (å…è´¹é¢åº¦)
MARKETSTACK_API_KEY = os.getenv("MARKETSTACK_API_KEY", "").strip('"')  # Marketstack (å…è´¹é¢åº¦: 1000æ¬¡/æœˆ)
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "").strip('"')  # Tavily Search API (AIæœç´¢ï¼Œå…è´¹é¢åº¦: 1000æ¬¡/æœˆ)

# ============================================
# API å®¢æˆ·ç«¯åˆå§‹åŒ–
# ============================================
# åœ¨è„šæœ¬é¡¶éƒ¨åˆå§‹åŒ–ä¸€æ¬¡ï¼Œä»¥æé«˜æ•ˆç‡
try:
    finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)
except Exception as e:
    print(f"Failed to initialize Finnhub client: {e}")
    finnhub_client = None

# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def search(query: str) -> str:
    """
    ä½¿ç”¨å¤šæ•°æ®æºç­–ç•¥æ‰§è¡Œç½‘é¡µæœç´¢å¹¶åˆå¹¶ç»“æœã€‚
    åŒæ—¶ä½¿ç”¨ï¼šç»´åŸºç™¾ç§‘ + Tavily Search + DuckDuckGoï¼Œç„¶ååˆå¹¶æ€»ç»“
    
    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²
        
    Returns:
        æ ¼å¼åŒ–çš„åˆå¹¶æœç´¢ç»“æœ
    """
    all_results = []
    sources_used = []
    
    # 1. å°è¯•ç»´åŸºç™¾ç§‘ï¼ˆæœ€å‡†ç¡®ï¼Œå…è´¹ï¼‰
    if WIKIPEDIA_AVAILABLE:
        try:
            wiki_result = _search_with_wikipedia(query)
            if wiki_result and len(wiki_result) > 100:
                all_results.append({
                    'source': 'Wikipedia',
                    'content': wiki_result
                })
                sources_used.append('Wikipedia')
                print(f"[Search] âœ… ç»´åŸºç™¾ç§‘è·å–ä¿¡æ¯æˆåŠŸ: {query[:50]}...")
        except Exception as e:
            print(f"[Search] ç»´åŸºç™¾ç§‘æœç´¢å¤±è´¥: {e}")
    
    # 2. å°è¯• Tavily Search (AIæœç´¢)
    if TAVILY_API_KEY and TAVILY_AVAILABLE:
        try:
            tavily_result = _search_with_tavily(query)
            if tavily_result and len(tavily_result) > 50:
                all_results.append({
                    'source': 'Tavily',
                    'content': tavily_result
                })
                sources_used.append('Tavily')
                print(f"[Search] âœ… Tavily æœç´¢æˆåŠŸ: {query[:50]}...")
        except Exception as e:
            error_msg = str(e) if e else "æœªçŸ¥é”™è¯¯"
            error_type = type(e).__name__
            if "Forbidden" in error_type or "403" in error_msg or "401" in error_msg:
                print(f"[Search] Tavily API è®¤è¯å¤±è´¥ ({error_type}): è¯·æ£€æŸ¥ TAVILY_API_KEY æ˜¯å¦æ­£ç¡®")
            else:
                print(f"[Search] Tavily æœç´¢å¤±è´¥: {error_msg}")
    
    # 3. å°è¯• DuckDuckGo
    if DDGS_AVAILABLE and DDGS is not None:
        try:
            ddgs_result = _search_with_duckduckgo(query)
            if ddgs_result and len(ddgs_result) > 50:
                all_results.append({
                    'source': 'DuckDuckGo',
                    'content': ddgs_result
                })
                sources_used.append('DuckDuckGo')
                print(f"[Search] âœ… DuckDuckGo æœç´¢æˆåŠŸ: {query[:50]}...")
        except Exception as e:
            print(f"[Search] DuckDuckGo æœç´¢å¤±è´¥: {e}")
    
    # 4. åˆå¹¶æ‰€æœ‰ç»“æœ
    if not all_results:
        return "Search error: æ‰€æœ‰æœç´¢æºå‡å¤±è´¥ï¼Œæ— æ³•è·å–æœç´¢ç»“æœã€‚"
    
    # åˆå¹¶ç»“æœ
    combined_result = _merge_search_results(all_results, query)
    
    print(f"[Search] âœ… æˆåŠŸä½¿ç”¨ {len(sources_used)} ä¸ªæœç´¢æº: {', '.join(sources_used)}")
    return combined_result


def _search_with_duckduckgo(query: str) -> str:
    """ä½¿ç”¨ DuckDuckGo æœç´¢"""
    if not DDGS_AVAILABLE or DDGS is None:
        raise Exception("DuckDuckGo ä¸å¯ç”¨")
    
    for attempt in range(3):  # å¢åŠ é‡è¯•æ¬¡æ•°
        try:
            ddgs = DDGS()
            
            try:
                results = list(ddgs.text(query, max_results=10, safesearch='moderate'))
            except TypeError:
                results = list(ddgs.text(query, max_results=10))
            
            if not results:
                if attempt < 2:
                    time.sleep(2)
                    continue
                return None
            
            # éªŒè¯ç»“æœç›¸å…³æ€§
            query_lower = query.lower()
            relevant_results = []
            for res in results:
                title = res.get('title', '')
                body = res.get('body', '')
                title_lower = title.lower()
                body_lower = body.lower()
                
                query_words = [w for w in query_lower.split() if len(w) > 2 and w not in ['the', 'and', 'or', 'for', 'with', 'from']]
                is_relevant = any(word in title_lower or word in body_lower for word in query_words) if query_words else True
                
                if is_relevant or len(relevant_results) < 3:
                    relevant_results.append(res)
            
            if not relevant_results:
                if attempt < 2:
                    time.sleep(2)
                    continue
                relevant_results = results[:3]
            
            formatted = []
            for i, res in enumerate(relevant_results[:10], 1):
                title = res.get('title', 'No title')
                body = res.get('body', 'No summary')
                href = res.get('href', 'No link')
                
                title = title.encode('utf-8', 'ignore').decode('utf-8').strip()
                body = body.encode('utf-8', 'ignore').decode('utf-8').strip()
                
                if not title or not body:
                    continue
                    
                formatted.append(f"{i}. {title}\n   {body[:200]}...\n   {href}")
            
            if formatted:
                return "Search Results (DuckDuckGo):\n" + "\n\n".join(formatted)
            else:
                return None
                
        except Exception as e:
            if attempt < 2:
                time.sleep(2)
            else:
                raise e
    
    return None


def _merge_search_results(results: list, query: str) -> str:
    """
    åˆå¹¶å¤šä¸ªæœç´¢æºçš„ç»“æœ
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« 'source' å’Œ 'content'
        query: åŸå§‹æŸ¥è¯¢
        
    Returns:
        åˆå¹¶åçš„æœç´¢ç»“æœæ–‡æœ¬
    """
    if not results:
        return "No search results found."
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªç»“æœï¼Œç›´æ¥è¿”å›
    if len(results) == 1:
        return results[0]['content']
    
    # åˆå¹¶å¤šä¸ªç»“æœ
    merged_parts = []
    merged_parts.append(f"ğŸ” ç»¼åˆæœç´¢ç»“æœ (æ¥è‡ª {len(results)} ä¸ªæ•°æ®æº):\n")
    merged_parts.append("=" * 60 + "\n\n")
    
    # æŒ‰ä¼˜å…ˆçº§æ’åºï¼šWikipedia > Tavily > DuckDuckGo
    source_priority = {'Wikipedia': 1, 'Tavily': 2, 'DuckDuckGo': 3}
    results_sorted = sorted(results, key=lambda x: source_priority.get(x['source'], 99))
    
    for i, result in enumerate(results_sorted, 1):
        source = result['source']
        content = result['content']
        
        merged_parts.append(f"ã€æ•°æ®æº {i}: {source}ã€‘\n")
        merged_parts.append("-" * 60 + "\n")
        
        # æå–ä¸»è¦å†…å®¹ï¼ˆå»é™¤æ ‡é¢˜å’Œæ ¼å¼ï¼‰
        if source == 'Wikipedia':
            # ç»´åŸºç™¾ç§‘ç»“æœå·²ç»æ ¼å¼åŒ–å¥½äº†
            merged_parts.append(content)
        elif source == 'Tavily':
            # Tavily ç»“æœä¹Ÿæ ¼å¼åŒ–å¥½äº†
            merged_parts.append(content)
        else:
            # DuckDuckGo ç»“æœ
            merged_parts.append(content)
        
        merged_parts.append("\n\n")
    
    merged_parts.append("=" * 60 + "\n")
    merged_parts.append(f"ğŸ’¡ æç¤º: ä»¥ä¸Šç»“æœæ¥è‡ªå¤šä¸ªæœç´¢æºï¼Œè¯·ç»¼åˆå‚è€ƒä»¥è·å¾—æœ€å‡†ç¡®çš„ä¿¡æ¯ã€‚\n")
    
    return "".join(merged_parts)


def _search_with_wikipedia(query: str) -> str:
    """
    ä½¿ç”¨ç»´åŸºç™¾ç§‘æœç´¢ï¼ˆå…è´¹ï¼Œä¸éœ€è¦API keyï¼‰
    
    ä¼˜å…ˆä½¿ç”¨ç»´åŸºç™¾ç§‘ï¼Œå› ä¸ºï¼š
    - å†…å®¹å‡†ç¡®ã€æƒå¨
    - ç»“æ„åŒ–ä¿¡æ¯
    - å…è´¹ï¼Œæ— é™åˆ¶
    - ç‰¹åˆ«é€‚åˆæŸ¥è¯¢æŒ‡æ•°æˆåˆ†è‚¡ã€å…¬å¸ä¿¡æ¯ç­‰
    """
    if not WIKIPEDIA_AVAILABLE or wikipedia is None:
        raise Exception("ç»´åŸºç™¾ç§‘ä¸å¯ç”¨ï¼ˆæœªå®‰è£… wikipediaï¼‰")
    
    try:
        # å°è¯•æœç´¢é¡µé¢ï¼ˆå¢åŠ æœç´¢ç»“æœæ•°é‡ï¼‰
        search_results = wikipedia.search(query, results=5)
        
        if not search_results:
            return None
        
        # å°è¯•å¤šä¸ªæœç´¢ç»“æœï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„
        best_result = None
        for page_title in search_results:
            try:
                page = wikipedia.page(page_title, auto_suggest=False)
                
                # è·å–é¡µé¢æ‘˜è¦å’Œä¸»è¦å†…å®¹
                summary = page.summary
                content = page.content[:5000]  # å¢åŠ å†…å®¹é•¿åº¦
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦ç›¸å…³ï¼ˆåŒ…å«æŸ¥è¯¢å…³é”®è¯ï¼‰
                query_lower = query.lower()
                content_lower = (summary + content).lower()
                
                # å¦‚æœå†…å®¹åŒ…å«æŸ¥è¯¢å…³é”®è¯ï¼Œè®¤ä¸ºæ˜¯ç›¸å…³ç»“æœ
                if any(keyword in content_lower for keyword in query_lower.split() if len(keyword) > 2):
                    best_result = {
                        'title': page_title,
                        'summary': summary,
                        'content': content,
                        'url': page.url
                    }
                    break
                    
            except wikipedia.exceptions.DisambiguationError as e:
                # å¦‚æœæœ‰æ­§ä¹‰ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªé€‰é¡¹
                if e.options:
                    try:
                        page = wikipedia.page(e.options[0], auto_suggest=False)
                        summary = page.summary
                        content = page.content[:5000]
                        best_result = {
                            'title': e.options[0],
                            'summary': summary,
                            'content': content,
                            'url': page.url
                        }
                        break
                    except:
                        continue
                        
            except wikipedia.exceptions.PageError:
                continue
            except Exception as e:
                print(f"[Search] ç»´åŸºç™¾ç§‘è·å–é¡µé¢ {page_title} å¤±è´¥: {e}")
                continue
        
        # å¦‚æœæ²¡æ‰¾åˆ°ç›¸å…³ç»“æœï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœç´¢ç»“æœ
        if not best_result and search_results:
            try:
                page = wikipedia.page(search_results[0], auto_suggest=False)
                best_result = {
                    'title': search_results[0],
                    'summary': page.summary,
                    'content': page.content[:5000],
                    'url': page.url
                }
            except:
                return None
        
        if best_result:
            # æ ¼å¼åŒ–ç»“æœ
            result = f"""Wikipedia Results for "{best_result['title']}":

Summary:
{best_result['summary']}

Detailed Information:
{best_result['content']}

URL: {best_result['url']}"""
            return result
        
        return None
            
    except Exception as e:
        print(f"[Search] ç»´åŸºç™¾ç§‘æœç´¢å‡ºé”™: {e}")
        return None


def _search_with_tavily(query: str) -> str:
    """
    ä½¿ç”¨ Tavily Search API è¿›è¡ŒAIæœç´¢
    
    Tavily æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºAIåº”ç”¨è®¾è®¡çš„æœç´¢APIï¼Œæä¾›ï¼š
    - æ›´å‡†ç¡®çš„æœç´¢ç»“æœ
    - ç»“æ„åŒ–çš„æ•°æ®æ ¼å¼
    - æ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£
    """
    if not TAVILY_API_KEY:
        raise Exception("Tavily API key not configured")
    
    if not TAVILY_AVAILABLE or TavilyClient is None:
        raise Exception("Tavily å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼ˆæœªå®‰è£… tavily-pythonï¼‰")
    
    try:
        client = TavilyClient(api_key=TAVILY_API_KEY)
        
        # æ‰§è¡Œæœç´¢
        response = client.search(
            query=query,
            search_depth="advanced",  # basic æˆ– advanced
            max_results=10,
            include_answer=True,  # åŒ…å«AIç”Ÿæˆçš„ç­”æ¡ˆæ‘˜è¦
            include_raw_content=False,  # ä¸åŒ…å«åŸå§‹å†…å®¹ï¼ˆèŠ‚çœtokenï¼‰
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        formatted = []
        
        # å¦‚æœæœ‰AIç”Ÿæˆçš„ç­”æ¡ˆï¼Œä¼˜å…ˆæ˜¾ç¤º
        if response.get('answer'):
            formatted.append(f"ğŸ“Š AIæ‘˜è¦:\n{response['answer']}\n")
        
        # æ˜¾ç¤ºæœç´¢ç»“æœ
        results = response.get('results', [])
        if results:
            formatted.append("æœç´¢ç»“æœ:")
            for i, res in enumerate(results, 1):
                title = res.get('title', 'No title')
                content = res.get('content', 'No content')
                url = res.get('url', 'No link')
                score = res.get('score', 0)
                
                formatted.append(
                    f"{i}. {title} (ç›¸å…³æ€§: {score:.2f})\n"
                    f"   {content[:200]}...\n"
                    f"   {url}"
                )
        else:
            formatted.append("æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœã€‚")
        
        return "\n\n".join(formatted)
        
    except Exception as e:
        error_msg = str(e) if e else "æœªçŸ¥é”™è¯¯"
        error_type = type(e).__name__
        print(f"[Search] Tavily API é”™è¯¯ ({error_type}): {error_msg}")
        
        # å¦‚æœæ˜¯ API key ç›¸å…³é”™è¯¯ï¼Œç»™å‡ºæ›´æ˜ç¡®çš„æç¤º
        if "api" in error_msg.lower() or "key" in error_msg.lower() or "auth" in error_msg.lower():
            print(f"[Search] æç¤º: è¯·æ£€æŸ¥ TAVILY_API_KEY æ˜¯å¦æ­£ç¡®é…ç½®")
        
        raise Exception(f"Tavily API é”™è¯¯: {error_msg}")

# ============================================
# è‚¡ä»·è·å– - å¤šæ•°æ®æºç­–ç•¥
# ============================================

def _fetch_with_alpha_vantage(ticker: str):
    """ä¼˜å…ˆæ–¹æ¡ˆï¼šä½¿ç”¨ Alpha Vantage API è·å–å®æ—¶è‚¡ä»·"""
    print(f"  - Attempting Alpha Vantage API for {ticker}...")
    try:
        url = "https://www.alphavantage.co/query"
        params = {
            'function': 'GLOBAL_QUOTE',
            'symbol': ticker,
            'apikey': ALPHA_VANTAGE_API_KEY
        }
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if 'Global Quote' in data and data['Global Quote']:
            quote = data['Global Quote']
            price = float(quote.get('05. price', 0))
            change = float(quote.get('09. change', 0))
            change_percent_str = quote.get('10. change percent', '0%').replace('%', '')
            
            if price > 0 and change_percent_str:
                change_percent = float(change_percent_str)
                return f"{ticker} Current Price: ${price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
        
        if 'Note' in data or 'Information' in data:
            print(f"  - Alpha Vantage note: {data.get('Note') or data.get('Information')}")
        if 'Error Message' in data:
            print(f"  - Alpha Vantage error: {data['Error Message']}")
            
        return None
    except Exception as e:
        print(f"  - Alpha Vantage exception: {e}")
        return None

def _fetch_with_finnhub(ticker: str):
    """æ–°å¢ï¼šä½¿ç”¨ Finnhub API è·å–å®æ—¶è‚¡ä»·"""
    if not finnhub_client:
        return None
    print(f"  - Attempting Finnhub API for {ticker}...")
    try:
        quote = finnhub_client.quote(ticker)
        if quote and quote.get('c') is not None and quote.get('c') != 0:
            price = quote['c']
            change = quote.get('d', 0.0)
            change_percent = quote.get('dp', 0.0)
            return f"{ticker} Current Price: ${price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
        return None
    except Exception as e:
        print(f"  - Finnhub quote exception: {e}")
        return None

def _fetch_with_yfinance(ticker: str):
    """å°è¯•ä½¿ç”¨ yfinance è·å–ä»·æ ¼"""
    print(f"  - Attempting yfinance for {ticker}...")
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="5d")
        if hist.empty or len(hist) < 2:
            return None
        
        current_price = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2]
        change = current_price - prev_close
        change_percent = (change / prev_close) * 100
        
        return f"{ticker} Current Price: ${current_price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
    except Exception as e:
        print(f"  - yfinance exception: {e}")
        return None


def _fetch_with_twelve_data_price(ticker: str):
    """å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ Twelve Data è·å–å®æ—¶ä»·æ ¼"""
    if not TWELVE_DATA_API_KEY:
        return None
    print(f"  - Attempting Twelve Data for {ticker}...")
    try:
        params = {
            "symbol": ticker,
            "interval": "1day",
            "outputsize": 2,  # æœ€æ–°ä¸¤å¤©è®¡ç®—æ¶¨è·Œå¹…
            "apikey": TWELVE_DATA_API_KEY,
            "order": "desc",
        }
        response = requests.get("https://api.twelvedata.com/time_series", params=params, timeout=10)
        if response.status_code != 200:
            return None

        data = response.json()
        if data.get("status") != "ok" or not data.get("values"):
            # Twelve Data è¿”å› {"status": "error", "message": "..."} æ—¶ä¹Ÿèµ°å…œåº•
            return None

        values = data.get("values", [])
        latest = values[0] if values else None
        if not latest:
            return None

        price = float(latest.get("close", 0) or 0)
        if price <= 0:
            return None

        prev_close = None
        if len(values) > 1 and values[1].get("close"):
            prev_close = float(values[1]["close"])

        change = None
        change_percent = None
        if prev_close and prev_close != 0:
            change = price - prev_close
            change_percent = (change / prev_close) * 100.0

        msg = f"{ticker} Current Price: ${price:.2f}"
        if change is not None and change_percent is not None:
            msg += f" | Change: {change:+.2f} ({change_percent:+.2f}%)"
        return msg
    except Exception as e:
        print(f"  - Twelve Data price exception: {e}")
        return None

def _scrape_yahoo_finance(ticker: str):
    """å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥çˆ¬å– Yahoo Finance é¡µé¢"""
    print(f"  - Attempting to scrape Yahoo Finance for {ticker}...")
    try:
        url = f"https://finance.yahoo.com/quote/{ticker}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        price_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketPrice'})
        change_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketChange'})
        change_percent_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketChangePercent'})
        
        if price_elem and change_elem and change_percent_elem:
            price = price_elem.get('value')
            change = change_elem.get('value')
            change_percent = change_percent_elem.get('value')
            
            if price and change and change_percent:
                return f"{ticker} Current Price: ${float(price):.2f} | Change: ${float(change):.2f} ({float(change_percent)*100:+.2f}%)"
        
        return None
    except Exception as e:
        print(f"  - Yahoo scraping exception: {e}")
        return None


def _fetch_index_price(ticker: str):
    """
    æŒ‡æ•°ä¸“ç”¨ï¼šä¼˜å…ˆ yfinance.download è·å–æœ€è¿‘ä¸¤æ—¥æ”¶ç›˜ï¼Œå¤±è´¥å†ç”¨ Stooq/æœç´¢å…œåº•ã€‚
    """
    if not ticker.startswith('^'):
        return None
    print(f"  - Attempting index price via yfinance.download for {ticker}...")
    try:
        hist = yf.download(ticker, period="3d", interval="1d", progress=False, timeout=20)
        if not hist.empty and len(hist) > 0:
            closes = hist['Close'].dropna().tolist()
            if closes:
                current_price = closes[-1]
                prev_close = closes[-2] if len(closes) > 1 else None
                change = current_price - prev_close if prev_close else None
                change_pct = (change / prev_close) * 100 if prev_close else None
                msg = f"{ticker} Current Price: ${current_price:.2f}"
                if change is not None and change_pct is not None:
                    msg += f" | Change: {change:+.2f} ({change_pct:+.2f}%)"
                return msg
    except Exception as e:
        print(f"  - Index price via yfinance failed: {e}")
    # Fallback 1: Stooq å…è´¹æ¥å£
    stooq_result = _fetch_with_stooq_price(ticker)
    if stooq_result:
        return stooq_result
    # Fallback 2: æœç´¢å…œåº•
    try:
        price_val = _fallback_price_value(ticker)
        if price_val:
            return f"{ticker} Current Price: ${price_val:.2f}"
    except Exception:
        pass
    return None

def _search_for_price(ticker: str):
    """æœ€åæ‰‹æ®µï¼šä½¿ç”¨æœç´¢å¼•æ“å¹¶ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æä»·æ ¼"""
    print(f"  - Attempting to find price via search for {ticker}...")
    try:
        search_result = search(f"{ticker} stock price today")
        patterns = [
            r'\$(\d{1,5}(?:,\d{3})*\.\d{2})',
            r'(?:Price|price)[:\s]+\$?(\d{1,5}(?:,\d{3})*\.\d{2})',
            r'(\d{1,5}(?:,\d{3})*\.\d{2})\s*USD'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, search_result)
            if match:
                price = match.group(1).replace(',', '')
                return f"{ticker} Current Price (via search): ${price}"
        
        return None
    except Exception as e:
        print(f"  - Search price exception: {e}")
        return None

def _fetch_with_stooq_price(ticker: str):
    """
    ä½¿ç”¨ stooq å…è´¹æ¥å£è·å–æœ€æ–°æ”¶ç›˜ä»·ï¼ˆå… Keyï¼‰ï¼Œæ”¯æŒéƒ¨åˆ†æŒ‡æ•°å’Œç¾è‚¡ã€‚
    """
    try:
        symbol = _map_to_stooq_symbol(ticker)
        if not symbol:
            return None
        url = f"https://stooq.pl/q/l/?s={symbol}&f=sd2t2ohlcv&h&e=json"
        resp = requests.get(url, timeout=8)
        data = resp.json().get("symbols") if resp.status_code == 200 else None
        if not data:
            return None
        item = data[0]
        close = item.get("close")
        open_ = item.get("open")
        if close in (None, "N/D"):
            return None
        price = float(close)
        change = None
        change_percent = None
        if open_ not in (None, "N/D", 0):
            prev = float(open_)
            change = price - prev
            if prev:
                change_percent = (change / prev) * 100.0
        return f"{ticker} Current Price: ${price:.2f}" + (
            f" | Change: {change:+.2f} ({change_percent:+.2f}%)" if change is not None else ""
        )
    except Exception as e:
        print(f"  - Stooq price exception: {e}")
        return None

def get_stock_price(ticker: str) -> str:
    """
    ä½¿ç”¨å¤šæ•°æ®æºç­–ç•¥è·å–è‚¡ç¥¨ä»·æ ¼ï¼Œä»¥æé«˜ç¨³å®šæ€§ã€‚
    ç­–ç•¥é¡ºåº: Alpha Vantage -> Finnhub -> yfinance -> Twelve Data -> ç½‘é¡µæŠ“å– -> Stooq(å…Key) -> æœç´¢å¼•æ“è§£æ
    """
    print(f"Fetching price for {ticker} with multi-source strategy...")
    is_index = ticker.startswith('^')
    if is_index:
        sources = [
            _fetch_index_price,
            _fetch_with_stooq_price,
            _search_for_price
        ]
    else:
        sources = [
            _fetch_with_alpha_vantage,
            _fetch_with_finnhub,  # æ–°å¢ Finnhub ä½œä¸ºé«˜ä¼˜å…ˆçº§æº
            _fetch_with_yfinance,
            _fetch_with_twelve_data_price,
            _scrape_yahoo_finance,
            _fetch_with_stooq_price,
            _search_for_price
        ]
    
    for i, source_func in enumerate(sources, 1):
        try:
            result = source_func(ticker)
            if result:
                print(f"  OK source #{i} ({source_func.__name__})")
                # è¿½åŠ ä¸¤æ¡£åˆ†æ‰¹ä»·ï¼Œä¿è¯æœ‰å…·ä½“æ•°å­—
                price_num = None
                import re
                m = re.search(r"\$([0-9]+(?:\.[0-9]+)?)", result)
                if m:
                    try:
                        price_num = float(m.group(1))
                    except Exception:
                        price_num = None
                if price_num:
                    p1 = price_num * 0.99
                    p2 = price_num * 0.98
                result = f"{result} | Suggested ladder: ${p1:.2f} / ${p2:.2f} (+/-1% / +/-2% from current)"
                return result
            time.sleep(0.5)
        except Exception as e:
            print(f"  FAIL source #{i} ({source_func.__name__}) failed: {e}")
            continue
            
    return f"Error: All data sources failed to retrieve the price for {ticker}. Please try again later."

# ============================================
# å…¬å¸ä¿¡æ¯è·å–
# ============================================

def get_financial_statements(ticker: str) -> dict:
    """
    è·å–å…¬å¸çš„è´¢åŠ¡æŠ¥è¡¨æ•°æ®ï¼ˆè´¢æŠ¥ï¼‰
    åŒ…æ‹¬ï¼šæŸç›Šè¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        
    Returns:
        dict: åŒ…å« financials, balance_sheet, cashflow çš„å­—å…¸
    """
    try:
        stock = yf.Ticker(ticker)
        
        result = {
            'ticker': ticker,
            'timestamp': datetime.now().isoformat(),
            'financials': None,
            'balance_sheet': None,
            'cashflow': None,
            'error': None
        }
        
        # 1. è·å–æŸç›Šè¡¨ï¼ˆIncome Statementï¼‰
        try:
            financials = stock.financials
            if not financials.empty:
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äºJSONåºåˆ—åŒ–
                result['financials'] = {
                    'columns': financials.columns.tolist(),
                    'index': financials.index.tolist(),
                    'data': financials.to_dict('records')
                }
                print(f"[Financials] âœ… æˆåŠŸè·å– {ticker} æŸç›Šè¡¨æ•°æ®")
        except Exception as e:
            print(f"[Financials] è·å–æŸç›Šè¡¨å¤±è´¥: {e}")
            result['error'] = f"è·å–æŸç›Šè¡¨å¤±è´¥: {str(e)}"
        
        # 2. è·å–èµ„äº§è´Ÿå€ºè¡¨ï¼ˆBalance Sheetï¼‰
        try:
            balance_sheet = stock.balance_sheet
            if not balance_sheet.empty:
                result['balance_sheet'] = {
                    'columns': balance_sheet.columns.tolist(),
                    'index': balance_sheet.index.tolist(),
                    'data': balance_sheet.to_dict('records')
                }
                print(f"[Financials] âœ… æˆåŠŸè·å– {ticker} èµ„äº§è´Ÿå€ºè¡¨æ•°æ®")
        except Exception as e:
            print(f"[Financials] è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {e}")
            if not result['error']:
                result['error'] = f"è·å–èµ„äº§è´Ÿå€ºè¡¨å¤±è´¥: {str(e)}"
        
        # 3. è·å–ç°é‡‘æµé‡è¡¨ï¼ˆCash Flowï¼‰
        try:
            cashflow = stock.cashflow
            if not cashflow.empty:
                result['cashflow'] = {
                    'columns': cashflow.columns.tolist(),
                    'index': cashflow.index.tolist(),
                    'data': cashflow.to_dict('records')
                }
                print(f"[Financials] âœ… æˆåŠŸè·å– {ticker} ç°é‡‘æµé‡è¡¨æ•°æ®")
        except Exception as e:
            print(f"[Financials] è·å–ç°é‡‘æµé‡è¡¨å¤±è´¥: {e}")
            if not result['error']:
                result['error'] = f"è·å–ç°é‡‘æµé‡è¡¨å¤±è´¥: {str(e)}"
        
        # å¦‚æœæ‰€æœ‰æ•°æ®éƒ½è·å–å¤±è´¥ï¼Œè¿”å›é”™è¯¯
        if not result['financials'] and not result['balance_sheet'] and not result['cashflow']:
            result['error'] = "æ— æ³•è·å–ä»»ä½•è´¢æŠ¥æ•°æ®ï¼Œè¯·æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®"
        
        return result
        
    except Exception as e:
        print(f"[Financials] è·å–è´¢æŠ¥æ•°æ®å¤±è´¥: {e}")
        return {
            'ticker': ticker,
            'timestamp': datetime.now().isoformat(),
            'financials': None,
            'balance_sheet': None,
            'cashflow': None,
            'error': f"è·å–è´¢æŠ¥æ•°æ®å¤±è´¥: {str(e)}"
        }

def get_financial_statements_summary(ticker: str) -> str:
    """
    è·å–è´¢æŠ¥æ•°æ®å¹¶æ ¼å¼åŒ–ä¸ºå¯è¯»çš„æ–‡æœ¬æ‘˜è¦
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        
    Returns:
        str: æ ¼å¼åŒ–çš„è´¢æŠ¥æ‘˜è¦æ–‡æœ¬
    """
    data = get_financial_statements(ticker)
    
    if data.get('error'):
        return f"æ— æ³•è·å– {ticker} çš„è´¢æŠ¥æ•°æ®: {data['error']}"
    
    summary_parts = [f"ğŸ“Š {ticker} è´¢åŠ¡æŠ¥è¡¨æ‘˜è¦\n"]
    summary_parts.append("=" * 50 + "\n")
    
    # æŸç›Šè¡¨æ‘˜è¦
    if data.get('financials'):
        financials = data['financials']
        summary_parts.append("\nğŸ“ˆ æŸç›Šè¡¨ (Income Statement):\n")
        summary_parts.append("-" * 50 + "\n")
        
        # è·å–æœ€æ–°å¹´ä»½çš„æ•°æ®
        if financials.get('columns') and len(financials['columns']) > 0:
            latest_year = financials['columns'][0]
            summary_parts.append(f"æœ€æ–°è´¢æŠ¥æ—¥æœŸ: {latest_year}\n\n")
            
            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            key_metrics = ['Total Revenue', 'Net Income', 'Operating Income', 'EBIT', 'Gross Profit']
            for metric in key_metrics:
                # åœ¨ index ä¸­æŸ¥æ‰¾
                if financials.get('index'):
                    for idx, row_name in enumerate(financials['index']):
                        if metric.lower() in str(row_name).lower():
                            # ä» data ä¸­è·å–å€¼
                            if financials.get('data') and len(financials['data']) > idx:
                                value = financials['data'][idx].get(latest_year, 'N/A')
                                if value != 'N/A' and value is not None:
                                    formatted_value = f"${value/1e9:.2f}B" if abs(value) >= 1e9 else f"${value/1e6:.2f}M"
                                    summary_parts.append(f"  {row_name}: {formatted_value}\n")
    
    # èµ„äº§è´Ÿå€ºè¡¨æ‘˜è¦
    if data.get('balance_sheet'):
        balance_sheet = data['balance_sheet']
        summary_parts.append("\nğŸ’° èµ„äº§è´Ÿå€ºè¡¨ (Balance Sheet):\n")
        summary_parts.append("-" * 50 + "\n")
        
        if balance_sheet.get('columns') and len(balance_sheet['columns']) > 0:
            latest_year = balance_sheet['columns'][0]
            summary_parts.append(f"æœ€æ–°è´¢æŠ¥æ—¥æœŸ: {latest_year}\n\n")
            
            key_metrics = ['Total Assets', 'Total Liabilities', 'Total Stockholder Equity', 'Cash And Cash Equivalents']
            for metric in key_metrics:
                if balance_sheet.get('index'):
                    for idx, row_name in enumerate(balance_sheet['index']):
                        if metric.lower() in str(row_name).lower():
                            if balance_sheet.get('data') and len(balance_sheet['data']) > idx:
                                value = balance_sheet['data'][idx].get(latest_year, 'N/A')
                                if value != 'N/A' and value is not None:
                                    formatted_value = f"${value/1e9:.2f}B" if abs(value) >= 1e9 else f"${value/1e6:.2f}M"
                                    summary_parts.append(f"  {row_name}: {formatted_value}\n")
    
    # ç°é‡‘æµé‡è¡¨æ‘˜è¦
    if data.get('cashflow'):
        cashflow = data['cashflow']
        summary_parts.append("\nğŸ’µ ç°é‡‘æµé‡è¡¨ (Cash Flow):\n")
        summary_parts.append("-" * 50 + "\n")
        
        if cashflow.get('columns') and len(cashflow['columns']) > 0:
            latest_year = cashflow['columns'][0]
            summary_parts.append(f"æœ€æ–°è´¢æŠ¥æ—¥æœŸ: {latest_year}\n\n")
            
            key_metrics = ['Operating Cash Flow', 'Free Cash Flow', 'Capital Expenditure']
            for metric in key_metrics:
                if cashflow.get('index'):
                    for idx, row_name in enumerate(cashflow['index']):
                        if metric.lower() in str(row_name).lower():
                            if cashflow.get('data') and len(cashflow['data']) > idx:
                                value = cashflow['data'][idx].get(latest_year, 'N/A')
                                if value != 'N/A' and value is not None:
                                    formatted_value = f"${value/1e9:.2f}B" if abs(value) >= 1e9 else f"${value/1e6:.2f}M"
                                    summary_parts.append(f"  {row_name}: {formatted_value}\n")
    
    return "".join(summary_parts)

def get_company_info(ticker: str) -> str:
    """
    ä»å¤šä¸ªæ¥æºè·å–å…¬å¸èµ„æ–™ä¿¡æ¯ã€‚
    ä¼˜å…ˆä½¿ç”¨ yfinanceï¼Œå¤±è´¥æ—¶å›é€€åˆ° Finnhub, Alpha Vantage æˆ–ç½‘é¡µæœç´¢ã€‚
    """
    # æ–¹æ³•1: yfinance
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        if info and 'longName' in info:
            summary = info.get('longBusinessSummary', '')
            description = (summary[:200] + '...') if summary else 'No description available'
            return f"""Company Profile ({ticker}):
- Name: {info.get('longName', 'Unknown')}
- Sector: {info.get('sector', 'Unknown')}
- Industry: {info.get('industry', 'Unknown')}
- Market Cap: ${info.get('marketCap', 0):,.0f}
- Website: {info.get('website', 'N/A')}
- Description: {description}"""
    except Exception as e:
        print(f"yfinance info fetch for '{ticker}' failed: {e}")

    # æ–¹æ³•2: Finnhub (æ–°å¢)
    if finnhub_client:
        try:
            print(f"Trying Finnhub for company info: {ticker}")
            profile = finnhub_client.company_profile2(symbol=ticker)
            if profile and 'name' in profile:
                return f"""Company Profile ({ticker}):
- Name: {profile.get('name', 'Unknown')}
- Sector: {profile.get('finnhubIndustry', 'Unknown')}
- Market Cap: ${int(profile.get('marketCapitalization', 0) * 1_000_000):,}
- Website: {profile.get('weburl', 'N/A')}
- Description: Search online for more details.""" # Finnhub profile doesn't include a long description
        except Exception as e:
            print(f"Finnhub profile fetch failed: {e}")
    
    # æ–¹æ³•3: Alpha Vantage
    try:
        print(f"Trying Alpha Vantage for company info: {ticker}")
        url = "https://www.alphavantage.co/query"
        params = {'function': 'OVERVIEW', 'symbol': ticker, 'apikey': ALPHA_VANTAGE_API_KEY}
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        if 'Symbol' in data and data['Symbol']:
            description = data.get('Description', 'No description')[:200] + '...'
            return f"""Company Profile ({ticker}):
- Name: {data.get('Name', 'Unknown')}
- Sector: {data.get('Sector', 'Unknown')}
- Industry: {data.get('Industry', 'Unknown')}
- Market Cap: ${int(data.get('MarketCapitalization', 0)):,}
- Description: {description}"""
    except Exception as e:
        print(f"Alpha Vantage overview fetch failed: {e}")
    
    # æ–¹æ³•4: ç½‘é¡µæœç´¢
    print(f"Falling back to web search for '{ticker}' company info")
    return search(f"{ticker} company profile stock information")

# ============================================
# æ–°é—»è·å–
# ============================================

MARKET_INDICES = {
    "^GSPC": "S&P 500 index",
    "^IXIC": "Nasdaq Composite index", 
    "^DJI": "Dow Jones Industrial Average",
    "^RUT": "Russell 2000 index",
    "^VIX": "VIX volatility index",
    "^NYA": "NYSE Composite index",
    "^FTSE": "FTSE 100 index",
    "^N225": "Nikkei 225 index",
    "^HSI": "Hang Seng index"
}

def _is_market_index(ticker: str) -> bool:
    """åˆ¤æ–­tickeræ˜¯å¦ä¸ºå¸‚åœºæŒ‡æ•°"""
    # æ–¹æ³•1: æ£€æŸ¥æ˜¯å¦åœ¨å·²çŸ¥æŒ‡æ•°åˆ—è¡¨ä¸­
    if ticker in MARKET_INDICES:
        return True
    
    # æ–¹æ³•2: æ£€æŸ¥å¸¸è§æŒ‡æ•°å‘½åæ¨¡å¼
    index_patterns = [
        r'^\^',      # ä»¥ ^ å¼€å¤´ï¼ˆYahoo FinanceæŒ‡æ•°æ ‡è®°ï¼‰
        r'SPX$',     # S&P 500 çš„å¦ä¸€ç§å†™æ³•
        r'NDX$',     # Nasdaq 100
        r'DJI$',     # Dow Jones
    ]
    
    for pattern in index_patterns:
        if re.match(pattern, ticker):
            return True
    
    return False

def _get_index_news(ticker: str) -> str:
    """
    ä¸“é—¨ä¸ºå¸‚åœºæŒ‡æ•°è·å–æ–°é—»çš„æ–¹æ³•ã€‚
    ç­–ç•¥ï¼šé€šè¿‡æœç´¢è·å–å®è§‚å¸‚åœºæ–°é—»å’ŒæŒ‡æ•°åˆ†æã€‚
    """
    friendly_name = MARKET_INDICES.get(ticker, ticker.replace('^', ''))
    
    print(f"  â†’ Detected market index: {friendly_name}")
    print(f"  â†’ Using specialized search strategy for index news...")
    
    # ç­–ç•¥1: æœç´¢æŒ‡æ•°æœ€è¿‘è¡¨ç°å’Œåˆ†æ
    current_date = datetime.now().strftime('%B %Y')
    search_queries = [
        f"{friendly_name} recent performance analysis {current_date}",
        f"{friendly_name} market news today",
        f"What's driving {friendly_name} this week"
    ]
    
    all_results = []
    for query in search_queries[:2]:  # åªç”¨å‰2ä¸ªæŸ¥è¯¢ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
        try:
            results = search(query)
            if results and "No search results" not in results:
                all_results.append(results)
            time.sleep(1)
        except Exception as e:
            print(f"  â†’ Search failed for '{query}': {e}")
            continue
    
    if not all_results:
        return f"Unable to fetch recent news for {friendly_name}. Please check financial news sites manually."
    
    # è§£æå¹¶æ ¼å¼åŒ–æœç´¢ç»“æœ
    combined_results = "\n\n".join(all_results)
    
    # å°è¯•ä»æœç´¢ç»“æœä¸­æå–æ–°é—»æ ‡é¢˜å’Œæ—¥æœŸ
    news_items = []
    lines = combined_results.split('\n')
    
    for i, line in enumerate(lines):
        # å¯»æ‰¾æ ‡é¢˜æ¨¡å¼ï¼ˆé€šå¸¸ä»¥æ•°å­—å¼€å¤´ï¼‰
        if re.match(r'^\d+\.', line.strip()):
            title = line.strip()
            # å°è¯•æ‰¾åˆ°æ—¥æœŸä¿¡æ¯
            date_match = re.search(r'(\d{1,2}\s+\w+\s+ago|\d{4}-\d{2}-\d{2}|\w+\s+\d{1,2},?\s+\d{4})', 
                                  ' '.join(lines[i:i+3]), re.IGNORECASE)
            date_str = date_match.group(1) if date_match else 'Recent'
            news_items.append(f"[{date_str}] {title}")
            
            if len(news_items) >= 5:
                break
    
    if news_items:
        return f"Latest Market News & Analysis ({friendly_name}):\n" + "\n".join(news_items)
    else:
        # å¦‚æœæ— æ³•æå–ç»“æ„åŒ–æ–°é—»ï¼Œè¿”å›åŸå§‹æœç´¢æ‘˜è¦
        preview = combined_results[:800] + "..." if len(combined_results) > 800 else combined_results
        return f"Recent Market Context ({friendly_name}):\n{preview}"

def get_company_news(ticker: str) -> str:
    """
    æ™ºèƒ½è·å–æ–°é—»ï¼šè‡ªåŠ¨è¯†åˆ«æ˜¯å…¬å¸è‚¡ç¥¨è¿˜æ˜¯å¸‚åœºæŒ‡æ•°ã€‚
    - å…¬å¸è‚¡ç¥¨ï¼šä½¿ç”¨ API (yfinance, Finnhub, Alpha Vantage)
    - å¸‚åœºæŒ‡æ•°ï¼šä½¿ç”¨æœç´¢ç­–ç•¥è·å–å®è§‚å¸‚åœºæ–°é—»
    """
    # ğŸ” å…³é”®åˆ¤æ–­ï¼šè¿™æ˜¯æŒ‡æ•°è¿˜æ˜¯å…¬å¸è‚¡ç¥¨ï¼Ÿ
    if _is_market_index(ticker):
        return _get_index_news(ticker)
    
    # --- ä»¥ä¸‹æ˜¯åŸæœ‰çš„å…¬å¸æ–°é—»è·å–é€»è¾‘ ---
    
    # æ–¹æ³•1: yfinance
    try:
        stock = yf.Ticker(ticker)
        news = stock.news
        if news:
            news_list = []
            for i, article in enumerate(news[:5], 1):
                title = article.get('title', 'No title')
                publisher = article.get('publisher', 'Unknown source')
                pub_time = article.get('providerPublishTime', 0)
                date_str = datetime.fromtimestamp(pub_time).strftime('%Y-%m-%d') if pub_time else 'Unknown date'
                news_list.append(f"{i}. [{date_str}] {title} ({publisher})")
            return f"Latest News ({ticker}):\n" + "\n".join(news_list)
    except Exception as e:
        print(f"yfinance news error for {ticker}: {e}")

    # æ–¹æ³•2: Finnhub
    if finnhub_client:
        try:
            print(f"Trying Finnhub news for {ticker}")
            to_date = date.today().strftime("%Y-%m-%d")
            from_date = (date.today() - timedelta(days=7)).strftime("%Y-%m-%d")
            news = finnhub_client.company_news(ticker, _from=from_date, to=to_date)
            if news:
                news_list = []
                for i, article in enumerate(news[:5], 1):
                    title = article.get('headline', 'No title')
                    source = article.get('source', 'Unknown')
                    pub_time = article.get('datetime', 0)
                    date_str = datetime.fromtimestamp(pub_time).strftime('%Y-%m-%d') if pub_time else 'Unknown'
                    news_list.append(f"{i}. [{date_str}] {title} ({source})")
                return f"Latest News ({ticker}):\n" + "\n".join(news_list)
        except Exception as e:
            print(f"Finnhub news fetch failed: {e}")

    # æ–¹æ³•3: Alpha Vantage
    try:
        print(f"Trying Alpha Vantage news for {ticker}")
        url = "https://www.alphavantage.co/query"
        params = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'limit': 5, 'apikey': ALPHA_VANTAGE_API_KEY}
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        if 'feed' in data and data['feed']:
            news_list = []
            for i, article in enumerate(data['feed'][:5], 1):
                title = article.get('title', 'No title')
                source = article.get('source', 'Unknown')
                date_str = article.get('time_published', '')[:8]
                if date_str:
                    date_str = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                news_list.append(f"{i}. [{date_str}] {title} ({source})")
            return f"Latest News ({ticker}):\n" + "\n".join(news_list)
    except Exception as e:
        print(f"Alpha Vantage news fetch failed: {e}")
    
    # æ–¹æ³•4: å›é€€åˆ°å…¬å¸ç‰¹å®šæœç´¢
    print(f"Falling back to search for {ticker} news")
    return search(f"{ticker} company latest news stock")

# ============================================
# å…¶ä»–å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜æˆ–ç¨ä½œä¿®æ”¹ï¼‰
# ============================================

def get_market_sentiment() -> str:
    """
    è·å–å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ - CNN Fear & Greed Index
    ä½¿ç”¨æ›´å®Œæ•´çš„è¯·æ±‚å¤´æ¥æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œæé«˜æˆåŠŸç‡ã€‚
    """
    try:
        # ä¸»è¦APIåœ°å€
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        
        # ä¼ªè£…æˆä¸€ä¸ªä»CNNå®˜ç½‘é¡µé¢å‘å‡ºè¯·æ±‚çš„çœŸå®æµè§ˆå™¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            # 'Referer' æ˜¯æœ€å…³é”®çš„å¤´ä¿¡æ¯ï¼Œå‘Šè¯‰æœåŠ¡å™¨è¯·æ±‚çš„æ¥æºé¡µé¢
            'Referer': 'https://www.cnn.com/markets/fear-and-greed',
            'Origin': 'https://www.cnn.com',
        }
        
        print("Attempting to fetch from CNN API with full headers...")
        response = requests.get(url, headers=headers, timeout=10)
        
        # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™ä¼šå¼•å‘ HTTPError å¼‚å¸¸
        response.raise_for_status() 
        
        data = response.json()
        score = float(data['fear_and_greed']['score'])
        rating = data['fear_and_greed']['rating']
        
        print("CNN API fetch successful!")
        return f"CNN Fear & Greed Index: {score:.1f} ({rating})"
    
    except requests.exceptions.HTTPError as http_err:
        print(f"CNN API failed with HTTP error: {http_err}. Trying fallback search...")
    except Exception as e:
        # æ•è·å…¶ä»–æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼Œä¾‹å¦‚ç½‘ç»œé—®é¢˜ã€JSONè§£æé”™è¯¯ç­‰
        print(f"CNN API failed with other error: {e}. Trying fallback search...")
    # --- å¦‚æœä¸Šé¢çš„ try ä»£ç å—å‡ºç°ä»»ä½•å¼‚å¸¸ï¼Œåˆ™æ‰§è¡Œä¸‹é¢çš„å›é€€é€»è¾‘ ---
    try:
        search_result = search("CNN Fear and Greed Index current value today")
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æœç´¢ç»“æœä¸­æå–æ•°å€¼å’Œè¯„çº§
        match = re.search(r'(?:Index|Score)[:\s]*(\d+\.?\d*)\s*\((\w+\s?\w*)\)', search_result, re.IGNORECASE)
        if match:
            score = float(match.group(1))
            rating = match.group(2)
            print("Fallback search successful!")
            return f"CNN Fear & Greed Index (via search): {score:.1f} ({rating})"
    except Exception as search_e:
        print(f"Search fallback also failed: {search_e}")
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªé€šç”¨é”™è¯¯ä¿¡æ¯
    return "Fear & Greed Index: Unable to fetch. Please check manually."
def get_economic_events() -> str:
    """æœç´¢å½“å‰æœˆä»½çš„ä¸»è¦ç¾å›½ç»æµäº‹ä»¶"""
    now = datetime.now()
    query = f"major upcoming US economic events {now.strftime('%B %Y')} (FOMC, CPI, jobs report)"
    return search(query)

def get_performance_comparison(tickers: dict) -> str:
    """æ¯”è¾ƒå­—å…¸ä¸­è‚¡ç¥¨ä»£ç çš„å¹´åˆè‡³ä»Šå’Œ1å¹´æœŸè¡¨ç°"""
    data = {}
    for name, ticker in tickers.items():
        time.sleep(1) # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="2y")
            if hist.empty:
                print(f"Warning: No historical data for {ticker}")
                continue
            
            end_price = hist['Close'].iloc[-1]
            
            # YTD Performance
            start_of_year = datetime(datetime.now().year, 1, 1)
            ytd_hist = hist[hist.index.tz_localize(None) >= start_of_year]
            if ytd_hist.empty:
                perf_ytd = float('nan')
            else:
                start_price_ytd = ytd_hist['Close'].iloc[0]
                perf_ytd = ((end_price - start_price_ytd) / start_price_ytd) * 100
            
            # 1-Year Performance
            one_year_ago = datetime.now() - timedelta(days=365)
            one_year_hist = hist[hist.index.tz_localize(None) >= one_year_ago]
            if one_year_hist.empty:
                 perf_1y = float('nan')
            else:
                start_price_1y = one_year_hist['Close'].iloc[0]
                perf_1y = ((end_price - start_price_1y) / start_price_1y) * 100

            data[name] = {
                "Current": f"{end_price:,.2f}", 
                "YTD": f"{perf_ytd:+.2f}%" if not pd.isna(perf_ytd) else "N/A", 
                "1-Year": f"{perf_1y:+.2f}%" if not pd.isna(perf_1y) else "N/A"
            }
        except Exception as e:
            print(f"Error processing performance for '{ticker}': {e}")
            data[name] = {"Current": "N/A", "YTD": "N/A", "1-Year": "N/A"}
    
    if not data:
        return "Unable to fetch performance data for any ticker."
            
    header = f"{'Ticker':<25} {'Current Price':<15} {'YTD %':<12} {'1-Year %':<12}\n" + "-" * 67 + "\n"
    rows = [f"{name:<25} {metrics['Current']:<15} {metrics['YTD']:<12} {metrics['1-Year']:<12}" for name, metrics in data.items()]
    return "Performance Comparison:\n\n" + header + "\n".join(rows)

def analyze_historical_drawdowns(ticker: str = "^IXIC") -> str:
    """è®¡ç®—å¹¶æŠ¥å‘Šè¿‡å»20å¹´çš„å‰3å¤§å†å²å›æ’¤ï¼ˆå·²ä¿®å¤æ—¶åŒºé—®é¢˜ï¼‰"""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="20y") # å»¶é•¿è‡³20å¹´ä»¥æ•è·æ›´å¤šäº‹ä»¶
        if hist.empty:
            return f"No historical data available for {ticker}."
        
        # --- å…³é”®ä¿®å¤ï¼šç§»é™¤ç´¢å¼•çš„æ—¶åŒºä¿¡æ¯ ---
        hist.index = hist.index.tz_localize(None)
            
        hist['peak'] = hist['Close'].cummax()
        hist['drawdown'] = (hist['Close'] - hist['peak']) / hist['peak']
        
        # æ‰¾åˆ°æ‰€æœ‰å›æ’¤çš„è°·åº•
        # ä½¿ç”¨ä¸€ä¸ªæŠ€å·§æ¥åˆ†ç»„è¿ç»­çš„å›æ’¤æœŸ
        drawdown_groups = hist[hist['drawdown'] < 0]
        if drawdown_groups.empty:
            return f"No significant drawdowns found for {ticker} in the last 20 years."
        # æ‰¾åˆ°æ¯ä¸ªå›æ’¤æœŸå†…çš„æœ€ä½ç‚¹
        troughs = drawdown_groups.loc[drawdown_groups.groupby((drawdown_groups['drawdown'] == 0).cumsum())['drawdown'].idxmin()]
        top_3 = troughs.nsmallest(3, 'drawdown')
        if top_3.empty:
            return f"No significant drawdowns found for {ticker}."
        result = [f"Top 3 Historical Drawdowns for {ticker} (last 20y):\n"]
        for _, row in top_3.iterrows():
            trough_date = row.name
            # æ‰¾åˆ°è¿™ä¸ªè°·åº•å¯¹åº”çš„å³°å€¼æ—¥æœŸ
            peak_price = row['peak']
            
            # æ‰¾åˆ°å›æ’¤å¼€å§‹çš„æ—¥æœŸï¼ˆå³ç¬¬ä¸€æ¬¡è¾¾åˆ°å³°å€¼çš„æ—¥æœŸï¼‰
            peak_date = hist[(hist.index <= trough_date) & (hist['Close'] == peak_price)].index.max()
            
            # æŸ¥æ‰¾æ¢å¤æ—¥æœŸï¼ˆå³è°·åº•ä¹‹åç¬¬ä¸€æ¬¡å›åˆ°å³°å€¼ä»·æ ¼çš„æ—¥æœŸï¼‰
            recovery_df = hist[hist.index > trough_date]
            recovery_date_series = recovery_df[recovery_df['Close'] >= peak_price].index
            recovery_date = recovery_date_series[0] if not recovery_date_series.empty else None
            
            duration = (trough_date - peak_date).days
            recovery_days = (recovery_date - trough_date).days if recovery_date else "Ongoing"
            result.append(
                f"- Drawdown: {row['drawdown']:.2%} (from {peak_date.strftime('%Y-%m-%d')} to {trough_date.strftime('%Y-%m-%d')})\n"
                f"  Duration to trough: {duration} days. Recovery time: {recovery_days} days."
            )
        return "\n".join(result)
    except Exception as e:
        return f"Historical analysis error: {e}."
def get_current_datetime() -> str:
    """è¿”å›å½“å‰æ—¥æœŸå’Œæ—¶é—´"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def _fetch_with_yahoo_scrape_historical(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 4: æ”¹è¿›çš„ Yahoo Finance ç½‘é¡µæŠ“å–ï¼ˆ2024æœ€æ–°æ–¹æ³•ï¼‰
    ä½¿ç”¨å¤šä¸ªå¤‡ç”¨URLå’Œæ›´å®Œå–„çš„è¯·æ±‚å¤´
    """
    try:
        print(f"[get_stock_historical_data] å°è¯•ä» Yahoo Finance ç½‘é¡µæŠ“å– {ticker}...")
        
        # æ ¹æ® period è®¡ç®—éœ€è¦çš„å¤©æ•°
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        # æ”¹è¿›çš„è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼‰
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/csv,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Referer": f"https://finance.yahoo.com/quote/{ticker}/history",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "same-origin"
        }
        
        # å°è¯•å¤šä¸ª Yahoo Finance URLï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        urls = [
            f"https://query1.finance.yahoo.com/v7/finance/download/{ticker}",
            f"https://query2.finance.yahoo.com/v7/finance/download/{ticker}",
        ]
        
        for url in urls:
            try:
                params = {
                    "period1": int((datetime.now() - timedelta(days=days)).timestamp()),
                    "period2": int(datetime.now().timestamp()),
                    "interval": "1d",
                    "events": "history",
                    "includeAdjustedClose": "true"
                }
                
                response = requests.get(url, params=params, headers=headers, timeout=20, allow_redirects=True)
                
                if response.status_code == 200 and len(response.text) > 100:  # ç¡®ä¿æœ‰å®é™…æ•°æ®
                    # è§£æ CSV æ•°æ®
                    import io
                    import csv
                    csv_data = io.StringIO(response.text)
                    reader = csv.DictReader(csv_data)
                    
                    kline_data = []
                    for row in reader:
                        try:
                            # è·³è¿‡æ— æ•ˆè¡Œ
                            if not row.get('Date') or not row.get('Close'):
                                continue
                            kline_data.append({
                                "time": row['Date'],
                                "open": float(row['Open']),
                                "high": float(row['High']),
                                "low": float(row['Low']),
                                "close": float(row['Close']),
                                "volume": float(row.get('Volume', 0)) if row.get('Volume') else 0,
                            })
                        except (ValueError, KeyError) as e:
                            continue  # è·³è¿‡æ— æ•ˆè¡Œ
                    
                    if kline_data:
                        print(f"[get_stock_historical_data] Yahoo Finance ç½‘é¡µæŠ“å–æˆåŠŸï¼Œè·å– {len(kline_data)} æ¡æ•°æ®")
                        return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "yahoo_scrape"}
            except Exception as e:
                print(f"[get_stock_historical_data] Yahoo Finance URL {url} å¤±è´¥: {e}")
                continue
        
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Yahoo Finance ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def _fetch_with_iex_cloud(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 5a: ä½¿ç”¨ IEX Cloud API (å…è´¹é¢åº¦: 50ä¸‡æ¬¡/æœˆ)
    æ–‡æ¡£: https://iexcloud.io/docs/api/
    """
    try:
        if not IEX_CLOUD_API_KEY:
            return None
            
        print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ IEX Cloud {ticker}...")
        
        # IEX Cloud API ç«¯ç‚¹
        # æ ¹æ® period è®¡ç®—æ—¶é—´èŒƒå›´
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        # IEX Cloud ä½¿ç”¨ä¸åŒçš„æ—¶é—´èŒƒå›´å‚æ•°
        if days <= 5:
            range_param = "5d"
        elif days <= 30:
            range_param = "1m"
        elif days <= 90:
            range_param = "3m"
        elif days <= 365:
            range_param = "1y"
        elif days <= 730:
            range_param = "2y"
        elif days <= 1825:
            range_param = "5y"
        else:
            range_param = "max"
        
        # IEX Cloud ä¸æ”¯æŒæŒ‡æ•°ä»£ç ï¼ˆå¦‚ ^IXICï¼‰ï¼Œåªæ”¯æŒè‚¡ç¥¨ä»£ç 
        # å¦‚æœtickerä»¥^å¼€å¤´ï¼Œè·³è¿‡IEX Cloud
        if ticker.startswith('^'):
            return None
        
        url = f"https://cloud.iexapis.com/stable/stock/{ticker}/chart/{range_param}"
        params = {
            "token": IEX_CLOUD_API_KEY,
            "chartCloseOnly": "false"
        }
        
        response = requests.get(url, params=params, timeout=20)
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                kline_data = []
                for item in data:
                    kline_data.append({
                        "time": item.get('date', item.get('label', '')),
                        "open": float(item.get('open', 0)),
                        "high": float(item.get('high', 0)),
                        "low": float(item.get('low', 0)),
                        "close": float(item.get('close', 0)),
                        "volume": float(item.get('volume', 0)),
                    })
                
                if kline_data:
                    print(f"[get_stock_historical_data] IEX Cloud æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                    return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "iex_cloud"}
        
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] IEX Cloud å¤±è´¥: {e}")
        return None


def _fetch_with_tiingo(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 5b: ä½¿ç”¨ Tiingo API (å…è´¹é¢åº¦: æ¯æ—¥500æ¬¡)
    æ–‡æ¡£: https://api.tiingo.com/documentation/general/overview
    """
    try:
        if not TIINGO_API_KEY:
            return None
            
        print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ Tiingo {ticker}...")
        
        # Tiingo API ç«¯ç‚¹
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # Tiingo ä¸æ”¯æŒæŒ‡æ•°ä»£ç ï¼ˆå¦‚ ^IXICï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        # å¦‚æœtickerä»¥^å¼€å¤´ï¼Œè·³è¿‡Tiingoï¼ˆå› ä¸ºTiingoä¸æ”¯æŒæŒ‡æ•°ï¼‰
        if ticker.startswith('^'):
            return None
        
        url = f"https://api.tiingo.com/tiingo/daily/{ticker}/prices"
        params = {
            "startDate": start_date.strftime('%Y-%m-%d'),
            "endDate": end_date.strftime('%Y-%m-%d'),
            "format": "json"
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Token {TIINGO_API_KEY}"
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=20)
        
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                kline_data = []
                for item in data:
                    kline_data.append({
                        "time": item.get('date', '')[:10],  # åªå–æ—¥æœŸéƒ¨åˆ†
                        "open": float(item.get('open', 0)),
                        "high": float(item.get('high', 0)),
                        "low": float(item.get('low', 0)),
                        "close": float(item.get('close', 0)),
                        "volume": float(item.get('volume', 0)),
                    })
                
                if kline_data:
                    print(f"[get_stock_historical_data] Tiingo æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                    return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "tiingo"}
        elif response.status_code == 404:
            # Tiingo å¯èƒ½ä¸æ”¯æŒè¯¥tickerï¼ˆå¦‚æŒ‡æ•°ï¼‰ï¼Œè¿”å›Noneè®©å…¶ä»–æ•°æ®æºå¤„ç†
            print(f"[get_stock_historical_data] Tiingo ä¸æ”¯æŒ {ticker}ï¼Œè·³è¿‡")
            return None
        
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Tiingo å¤±è´¥: {e}")
        return None


def _fetch_with_twelve_data(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 5c: ä½¿ç”¨ Twelve Data API (å…è´¹é¢åº¦ï¼Œè½»é‡å›é€€)
    æ–‡æ¡£: https://twelvedata.com/docs#time-series
    """
    try:
        if not TWELVE_DATA_API_KEY:
            return None

        # Twelve Data å¯¹æŒ‡æ•°æ”¯æŒæœ‰é™ï¼Œé¿å… "^" å‰ç¼€çš„æŒ‡æ•°
        if ticker.startswith('^'):
            return None

        print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ Twelve Data {ticker}...")

        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        outputsize = max(2, min(5000, days + 2))  # è½»é‡æ§åˆ¶è¾“å‡ºï¼Œå…¼é¡¾å…è´¹é¢åº¦

        params = {
            "symbol": ticker,
            "interval": "1day",
            "outputsize": outputsize,
            "apikey": TWELVE_DATA_API_KEY,
            "order": "desc",
        }
        response = requests.get("https://api.twelvedata.com/time_series", params=params, timeout=20)

        if response.status_code != 200:
            return None

        data = response.json()
        if data.get("status") != "ok":
            # status != ok æ—¶é€šå¸¸è¿”å› message
            message = data.get("message") or data.get("error")
            if message:
                print(f"[get_stock_historical_data] Twelve Data çŠ¶æ€å¼‚å¸¸: {message}")
            return None

        values = data.get("values") or []
        if not values:
            return None

        kline_data = []
        for item in values:
            kline_data.append({
                "time": item.get("datetime", "")[:10],
                "open": float(item.get("open", 0)),
                "high": float(item.get("high", 0)),
                "low": float(item.get("low", 0)),
                "close": float(item.get("close", 0)),
                "volume": float(item.get("volume", 0)),
            })

        if kline_data:
            # Twelve Data é»˜è®¤å€’åºï¼Œç¿»è½¬ä¸ºæ—¶é—´æ­£åº
            kline_data = list(reversed(kline_data))
            as_of = values[0].get("datetime", "")[:19]
            print(f"[get_stock_historical_data] Twelve Data æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
            return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "twelve_data", "as_of": as_of}

        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Twelve Data å¤±è´¥: {e}")
        return None


def _fetch_with_marketstack(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 5d: ä½¿ç”¨ Marketstack API (å…è´¹é¢åº¦: 1000æ¬¡/æœˆ)
    æ–‡æ¡£: https://marketstack.com/documentation
    """
    try:
        if not MARKETSTACK_API_KEY:
            return None
            
        print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ Marketstack {ticker}...")
        
        # Marketstack API ç«¯ç‚¹
        url = "http://api.marketstack.com/v1/eod"
        
        # Marketstack ä¸æ”¯æŒæŒ‡æ•°ä»£ç ï¼ˆå¦‚ ^IXICï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        # å¦‚æœtickerä»¥^å¼€å¤´ï¼Œè·³è¿‡Marketstackï¼ˆå› ä¸ºMarketstackä¸æ”¯æŒæŒ‡æ•°ï¼‰
        if ticker.startswith('^'):
            return None
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        params = {
            "access_key": MARKETSTACK_API_KEY,
            "symbols": ticker,
            "date_from": start_date.strftime('%Y-%m-%d'),
            "date_to": end_date.strftime('%Y-%m-%d'),
            "limit": 10000  # æœ€å¤§é™åˆ¶
        }
        
        response = requests.get(url, params=params, timeout=20)
        
        if response.status_code == 200:
            data = response.json()
            if "error" in data:
                print(f"[get_stock_historical_data] Marketstack é”™è¯¯: {data['error']}")
                return None
            
            if "data" in data and isinstance(data["data"], list) and len(data["data"]) > 0:
                kline_data = []
                for item in data["data"]:
                    kline_data.append({
                        "time": item.get('date', '')[:10],  # åªå–æ—¥æœŸéƒ¨åˆ†
                        "open": float(item.get('open', 0)),
                        "high": float(item.get('high', 0)),
                        "low": float(item.get('low', 0)),
                        "close": float(item.get('close', 0)),
                        "volume": float(item.get('volume', 0)),
                    })
                
                if kline_data:
                    print(f"[get_stock_historical_data] Marketstack æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                    return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "marketstack"}
        
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Marketstack å¤±è´¥: {e}")
        return None


def _fetch_with_massive_io(ticker: str, period: str = "1y") -> dict:
    """
    ç­–ç•¥ 5e: ä½¿ç”¨ Massive.com (åŸ Polygon.io) API
    """
    try:
        if not MASSIVE_API_KEY:
            print(f"[get_stock_historical_data] Massive.com API key æœªé…ç½®")
            return None
            
        print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ Massive.com {ticker}...")
        
        # Massive.com (åŸ Polygon.io) API ç«¯ç‚¹
        # æ³¨æ„ï¼šPolygon.io å·²æ›´åä¸º Massive.comï¼Œä½† API ç«¯ç‚¹ä»ä¸º api.polygon.io
        # API æ ¼å¼: /v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from}/{to}
        # æ—¥æœŸå¿…é¡»ä½œä¸ºè·¯å¾„å‚æ•°ï¼Œä¸èƒ½ä½œä¸ºæŸ¥è¯¢å‚æ•°
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # æ—¥æœŸä½œä¸ºè·¯å¾„å‚æ•°
        url = f"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/{start_date.strftime('%Y-%m-%d')}/{end_date.strftime('%Y-%m-%d')}"
        
        params = {
            "adjusted": "true",
            "sort": "asc",
            "limit": 50000,
            "apikey": MASSIVE_API_KEY  # Massive.com API key ä½œä¸ºæŸ¥è¯¢å‚æ•°
        }
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=20)
        
        if response.status_code == 200:
            data = response.json()
            # Massive.com API å¯èƒ½è¿”å› 'OK' æˆ– 'DELAYED' çŠ¶æ€ï¼Œåªè¦ results æœ‰æ•°æ®å°±å¯ä»¥ä½¿ç”¨
            # DELAYED çŠ¶æ€è¡¨ç¤ºæ•°æ®æœ‰å»¶è¿Ÿï¼Œä½†ä»ç„¶å¯ä»¥ä½¿ç”¨
            if data.get('status') in ('OK', 'DELAYED') and 'results' in data:
                results = data.get('results', [])
                if len(results) > 0:
                    kline_data = []
                    for item in results:
                        timestamp = item['t'] / 1000  # è½¬æ¢ä¸ºç§’
                        date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                        kline_data.append({
                            "time": date_str,
                            "open": item['o'],
                            "high": item['h'],
                            "low": item['l'],
                            "close": item['c'],
                            "volume": item.get('v', 0),
                        })
                    
                    if kline_data:
                        print(f"[get_stock_historical_data] Massive.com æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                        return {"kline_data": kline_data, "period": period, "interval": "1d", "source": "massive"}
            else:
                error_msg = data.get('error', data.get('status', 'unknown'))
                print(f"[get_stock_historical_data] Massive.com è¿”å›ç©ºæ•°æ®æˆ–é”™è¯¯: {error_msg}")
                if 'error' in data:
                    print(f"[get_stock_historical_data] é”™è¯¯è¯¦æƒ…: {data.get('error')}")
        else:
            error_text = response.text[:500] if response.text else "No response body"
            print(f"[get_stock_historical_data] Massive.com HTTP é”™è¯¯: {response.status_code}")
            print(f"[get_stock_historical_data] å“åº”å†…å®¹: {error_text}")
            # å°è¯•è§£æ JSON é”™è¯¯ä¿¡æ¯
            try:
                error_data = response.json()
                if 'error' in error_data:
                    print(f"[get_stock_historical_data] API é”™è¯¯: {error_data['error']}")
            except:
                pass
        
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Massive.com å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def _map_to_stooq_symbol(ticker: str) -> Optional[str]:
    upper = ticker.upper()
    mapping = {
        "^IXIC": "^ndq",
        "^GSPC": "^spx",
        "^DJI": "^dji",
    }
    if upper in mapping:
        return mapping[upper]
    if upper.startswith("^"):
        return upper.lower()
    return f"{upper}.us"


def _fetch_with_stooq_history(ticker: str, period: str = "1y", interval: str = "1d") -> Optional[dict]:
    """
    å… Key å›é€€ï¼šä½¿ç”¨ stooq è·å–æ—¥çº¿æ•°æ®ï¼ˆæ”¯æŒéƒ¨åˆ†æŒ‡æ•°å’Œç¾è‚¡ï¼Œä»£ç å¸¦ .usï¼‰ã€‚
    """
    try:
        import requests  # type: ignore
        import csv
        from datetime import date, timedelta

        symbol = _map_to_stooq_symbol(ticker)
        if not symbol:
            return None

        days_map = {
            "1d": 5, "5d": 10, "1mo": 40, "3mo": 120, "6mo": 200,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 3650
        }
        days = days_map.get(period, 365)
        end = date.today()
        start = end - timedelta(days=days)
        url = f"https://stooq.pl/q/d/l/?s={symbol}&d1={start:%Y%m%d}&d2={end:%Y%m%d}&i=d"
        resp = requests.get(url, timeout=8)
        if resp.status_code != 200 or not resp.text:
            return None

        lines = resp.text.strip().splitlines()
        reader = csv.DictReader(lines)
        data = []
        for row in reader:
            try:
                date_key = "Date" if "Date" in row else ("Data" if "Data" in row else None)
                open_key = "Open" if "Open" in row else ("Otwarcie" if "Otwarcie" in row else None)
                high_key = "High" if "High" in row else ("Najwyzszy" if "Najwyzszy" in row else None)
                low_key = "Low" if "Low" in row else ("Najnizszy" if "Najnizszy" in row else None)
                close_key = "Close" if "Close" in row else ("Zamkniecie" if "Zamkniecie" in row else None)
                volume_key = "Volume" if "Volume" in row else ("Wolumen" if "Wolumen" in row else None)
                if not all([date_key, open_key, high_key, low_key, close_key]):
                    continue
                data.append(
                    {
                        "time": f"{row[date_key]} 00:00",
                        "open": float(row[open_key]),
                        "high": float(row[high_key]),
                        "low": float(row[low_key]),
                        "close": float(row[close_key]),
                        "volume": float(row.get(volume_key) or 0),
                    }
                )
            except Exception:
                continue

        if data:
            print(f"[get_stock_historical_data] Stooq æˆåŠŸè·å– {len(data)} æ¡æ•°æ®")
            # å¦‚æœè¯·æ±‚çš„æ˜¯å°æ—¶è§†å›¾ï¼Œä½†åªæ‹¿åˆ°æ—¥çº¿ï¼Œç”¨æœ€è¿‘è‹¥å¹²æ—¥æ”¶ç›˜ç”Ÿæˆä¼ªâ€œå°æ—¶â€åºåˆ—ï¼Œä¿è¯æœ‰å˜åŒ–
            if interval.endswith("h"):
                # å–æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ï¼Œæ ‡è®°ä¸ºå½“æ—¥ 16:00
                recent = data[-10:]
                hourly_like = []
                for row in recent:
                    hourly_like.append({
                        "time": row["time"].split()[0] + " 16:00",
                        "open": row["close"],
                        "high": row["close"],
                        "low": row["close"],
                        "close": row["close"],
                        "volume": row.get("volume", 0.0),
                    })
                return {"kline_data": hourly_like, "period": period, "interval": "1h", "source": "stooq_intraday_stub"}
            return {"kline_data": data, "period": period, "interval": "1d", "source": "stooq"}
        return None
    except Exception as e:
        print(f"[get_stock_historical_data] Stooq å¤±è´¥: {e}")
        return None


def _fallback_price_value(ticker: str) -> Optional[float]:
    """
    ç®€å•å…œåº•ï¼šå°è¯•ç”¨ stooq ä»·æ ¼æ¥å£æˆ–æœç´¢æå–ä¸€ä¸ªæœ€æ–°ä»·ï¼Œç”¨äºç”Ÿæˆå¹³æ»‘åºåˆ—ã€‚
    """
    try:
        symbol = _map_to_stooq_symbol(ticker)
        if symbol:
            url = f"https://stooq.pl/q/l/?s={symbol}&f=sd2t2ohlcv&h&e=json"
            resp = requests.get(url, timeout=6)
            if resp.status_code == 200:
                data = resp.json().get("symbols") or []
                if data:
                    close = data[0].get("close")
                    if close not in (None, "N/D"):
                        return float(close)
    except Exception:
        pass

    # æœç´¢å…œåº•
    try:
        search_result = search(f"{ticker} index level today")
        m = re.search(r"(\\d{3,6}(?:,\\d{3})*(?:\\.\\d+)?)", search_result or "")
        if m:
            return float(m.group(1).replace(",", ""))
    except Exception:
        pass
    return None


def get_stock_historical_data(ticker: str, period: str = "1y", interval: str = "1d") -> dict:
    """
    è·å–è‚¡ç¥¨çš„å†å²æ•°æ®ï¼Œç”¨äºKçº¿å›¾ã€‚
    è¿”å›çš„æ•°æ®æ ¼å¼ä¸“é—¨ä¸º ECharts ä¼˜åŒ–ã€‚
    ä½¿ç”¨å¤šæºå›é€€ç­–ç•¥ï¼šyfinance (ä¼˜å…ˆï¼Œæœ€å¯é ) â†’ Alpha Vantage â†’ Finnhub â†’ Yahoo ç½‘é¡µæŠ“å– â†’ IEX Cloud â†’ Tiingo â†’ Twelve Data â†’ Marketstack â†’ Massive.com â†’ Stooq
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç 
        period: æ—¶é—´å‘¨æœŸ ("1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y", "10y", "ytd", "max")
        interval: æ•°æ®é—´éš” ("1d", "1wk", "1mo")
    
    Returns:
        dict: {"kline_data": [...]} æˆ– {"error": "..."}
    """
    # æŒ‡æ•°ä¼˜å…ˆå°è¯• Stooqï¼ˆå… Keyï¼Œé¿å… yfinance é€Ÿç‡é™åˆ¶ï¼‰
    is_index = ticker.startswith("^")
    if is_index:
        stooq_result = _fetch_with_stooq_history(ticker, period, interval)
        if stooq_result and stooq_result.get("kline_data"):
            print(f"[get_stock_historical_data] Stooq æŒ‡æ•°å…œåº•å‘½ä¸­ {ticker}ï¼Œè¿”å›æ—¥çº¿æ•°æ®")
            return stooq_result

    # ç­–ç•¥ 0: ä¼˜å…ˆä½¿ç”¨ yfinanceï¼ˆæœ€å¯é ï¼Œæ”¯æŒè‚¡ç¥¨å’ŒæŒ‡æ•°ï¼‰
    # ä½¿ç”¨ session å’Œé‡è¯•æœºåˆ¶ï¼Œé¿å…é€Ÿç‡é™åˆ¶
    max_retries = 1  # é™æµä¸¥é‡æ—¶å¿«é€Ÿè·³è¿‡
    for attempt in range(max_retries):
        try:
            print(f"[get_stock_historical_data] å°è¯•ä½¿ç”¨ yfinance {ticker} (å°è¯• {attempt + 1}/{max_retries})...")
            
            # åˆ›å»ºæ–°çš„ sessionï¼Œé¿å…ç¼“å­˜é—®é¢˜
            import yfinance as yf_local
            stock = yf_local.Ticker(ticker, session=None)  # ä¸ä½¿ç”¨ç¼“å­˜
            
            # å¯¹äºæŒ‡æ•°ï¼Œä½¿ç”¨ä¸åŒçš„å‚æ•°
            if ticker.startswith('^'):
                # æŒ‡æ•°æ•°æ®
                hist = stock.history(period=period, interval=interval, timeout=30, raise_errors=True)
            else:
                # è‚¡ç¥¨æ•°æ®
                hist = stock.history(period=period, interval=interval, timeout=30, raise_errors=True)
            
            if not hist.empty and len(hist) > 0:
                data = []
                for index, row in hist.iterrows():
                    # å¤„ç†æ—¥æœŸæ ¼å¼
                    if hasattr(index, 'strftime'):
                        time_str = index.strftime('%Y-%m-%d')
                    elif hasattr(index, 'date'):
                        time_str = index.date().strftime('%Y-%m-%d')
                    else:
                        time_str = str(index)[:10]
                    
                    data.append({
                        "time": f"{time_str} 00:00",
                        "open": float(row['Open']),
                        "high": float(row['High']),
                        "low": float(row['Low']),
                        "close": float(row['Close']),
                        "volume": float(row.get('Volume', 0)) if 'Volume' in row else 0,
                    })
                
                if data:
                    print(f"[get_stock_historical_data] âœ… yfinance æˆåŠŸè·å– {len(data)} æ¡æ•°æ® (æ¥æº: yfinance)")
                    return {"kline_data": data, "period": period, "interval": interval, "source": "yfinance"}
        except Exception as e:
            error_msg = str(e)
            if "Too Many Requests" in error_msg or "Rate limited" in error_msg:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"[get_stock_historical_data] yfinance é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time as time_module
                    time_module.sleep(wait_time)
                    continue
            print(f"[get_stock_historical_data] yfinance å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                break
    
    # ç­–ç•¥ 1: å°è¯•ä½¿ç”¨ Alpha Vantage
    # æ³¨æ„ï¼šAlpha Vantage ä¸æ”¯æŒæŒ‡æ•°ä»£ç ï¼ˆå¦‚ ^IXICï¼‰ï¼Œå¯¹äºæŒ‡æ•°ç›´æ¥è·³è¿‡
    if ALPHA_VANTAGE_API_KEY and not ticker.startswith('^'):
        try:
            # å¯¹äºæŒ‡æ•°ä»£ç ï¼Œç§»é™¤^ç¬¦å·
            ticker_for_av = ticker.lstrip('^')
            url = f"https://www.alphavantage.co/query"
            params = {
                "function": "TIME_SERIES_DAILY",
                "symbol": ticker_for_av,
                "apikey": ALPHA_VANTAGE_API_KEY,
                "outputsize": "full"
            }
            response = requests.get(url, params=params, timeout=15)
            data = response.json()
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if "Error Message" in data:
                error_msg = data.get('Error Message', 'Unknown error')
                print(f"[get_stock_historical_data] Alpha Vantage è¿”å›é”™è¯¯: {error_msg}")
                raise Exception(f"Alpha Vantage API error: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é€Ÿç‡é™åˆ¶æç¤º
            if "Note" in data:
                note = data.get('Note', '')
                if "API call frequency" in note or "rate limit" in note.lower():
                    print(f"[get_stock_historical_data] Alpha Vantage é€Ÿç‡é™åˆ¶: {note}")
                    raise Exception("Alpha Vantage rate limit")
                else:
                    print(f"[get_stock_historical_data] Alpha Vantage æç¤º: {note}")
                    raise Exception(f"Alpha Vantage note: {note}")
            
            if "Time Series (Daily)" in data:
                time_series = data["Time Series (Daily)"]
                # æ ¹æ® period ç¡®å®šéœ€è¦çš„æ•°æ®é‡
                period_days = {
                    "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
                    "1y": 252, "2y": 504, "5y": 1260, "10y": 2520, "max": 10000
                }
                max_days = period_days.get(period, 252)
                
                sorted_dates = sorted(time_series.keys(), reverse=True)[:max_days]
                
                kline_data = []
                for date_str in sorted_dates:
                    day_data = time_series[date_str]
                    kline_data.append({
                        "time": date_str,
                        "open": float(day_data["1. open"]),
                        "high": float(day_data["2. high"]),
                        "low": float(day_data["3. low"]),
                        "close": float(day_data["4. close"]),
                        "volume": float(day_data.get("5. volume", 0)),
                    })
                
                # æŒ‰æ—¶é—´æ­£åºæ’åˆ—
                kline_data.reverse()
                print(f"[get_stock_historical_data] Alpha Vantage æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                return {"kline_data": kline_data, "period": period, "interval": interval}
        except Exception as e:
            print(f"[get_stock_historical_data] Alpha Vantage å¤±è´¥: {e}ï¼Œå°è¯• yfinance...")
    
    # ç­–ç•¥ 2: å›é€€åˆ° yfinanceï¼ˆæ”¯æŒå¤šæ—¶é—´å‘¨æœŸï¼Œå¸¦é‡è¯•ï¼‰
    # æ³¨æ„ï¼šyfinance å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼Œè¿™é‡Œç›´æ¥ä½¿ç”¨
    # yfinance æ”¯æŒæŒ‡æ•°ä»£ç ï¼ˆå¦‚ ^IXIC, ^GSPCï¼‰ï¼Œè¿™æ˜¯è·å–æŒ‡æ•°æ•°æ®çš„ä¸»è¦æ–¹æ³•
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # yfinance æ”¯æŒæŒ‡æ•°ä»£ç ï¼Œç›´æ¥ä½¿ç”¨
            stock = yf.Ticker(ticker)
            
            # æ ¹æ® period å’Œ interval è·å–æ•°æ®
            # yfinance æ”¯æŒçš„ period: 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max
            # yfinance æ”¯æŒçš„ interval: 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo
            # å¯¹äºæŒ‡æ•°ï¼Œyfinance é€šå¸¸èƒ½æ­£å¸¸å·¥ä½œ
            hist = stock.history(period=period, interval=interval, timeout=15)
            
            if hist.empty:
                if attempt < max_retries - 1:
                    print(f"[get_stock_historical_data] yfinance è¿”å›ç©ºæ•°æ®ï¼Œé‡è¯• {attempt + 1}/{max_retries}...")
                    time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
                return {"error": f"No historical data for {ticker}"}

            # è½¬æ¢æ ¼å¼ä»¥åŒ¹é… ECharts çš„è¦æ±‚
            data = []
            for index, row in hist.iterrows():
                # å¤„ç†ä¸åŒçš„æ—¶é—´ç´¢å¼•ç±»å‹
                if hasattr(index, 'strftime'):
                    time_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    time_str = index.date().strftime('%Y-%m-%d')
                else:
                    time_str = str(index)[:10]  # å–å‰10ä¸ªå­—ç¬¦ä½œä¸ºæ—¥æœŸ
                
                data.append({
                    "time": f"{time_str} 00:00",
                    "open": float(row['Open']),
                    "high": float(row['High']),
                    "low": float(row['Low']),
                    "close": float(row['Close']),
                    "volume": float(row.get('Volume', 0)) if 'Volume' in row else 0,
                })
            
            print(f"[get_stock_historical_data] yfinance æˆåŠŸè·å– {len(data)} æ¡æ•°æ®")
            return {"kline_data": data, "period": period, "interval": interval}
        except Exception as e:
            error_msg = str(e)
            if "Too Many Requests" in error_msg or "Rate limited" in error_msg:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"[get_stock_historical_data] yfinance é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    import time as time_module
                    time_module.sleep(wait_time)
                    continue
            # å¦‚æœä¸æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œæˆ–è€…å·²ç»é‡è¯•å®Œï¼Œç»§ç»­åˆ°ä¸‹ä¸€ä¸ªç­–ç•¥
            print(f"[get_stock_historical_data] yfinance å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                break  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œç»§ç»­åˆ°ä¸‹ä¸€ä¸ªç­–ç•¥
    
    # ç­–ç•¥ 3: å°è¯•ä½¿ç”¨ Finnhubï¼ˆå¦‚æœæœ‰ API keyï¼‰
    if FINNHUB_API_KEY and finnhub_client:
        try:
            import time
            from datetime import datetime, timedelta
            
            # æ ¹æ® period è®¡ç®—å¤©æ•°
            period_days = {
                "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
                "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
            }
            days = period_days.get(period, 365)
            
            end_date = int(time.time())
            start_date = int((datetime.now() - timedelta(days=days)).timestamp())
            
            res = finnhub_client.stock_candles(ticker, 'D', start_date, end_date)
            
            if res['s'] == 'ok' and len(res['c']) > 0:
                kline_data = []
                for i in range(len(res['t'])):
                    timestamp = res['t'][i]
                    date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
                    kline_data.append({
                        "time": date_str,
                        "open": res['o'][i],
                        "high": res['h'][i],
                        "low": res['l'][i],
                        "close": res['c'][i],
                        "volume": res.get('v', [0] * len(res['t']))[i] if 'v' in res else 0,
                    })
                print(f"[get_stock_historical_data] Finnhub æˆåŠŸè·å– {len(kline_data)} æ¡æ•°æ®")
                return {"kline_data": kline_data, "period": period, "interval": interval}
        except Exception as e2:
            print(f"[get_stock_historical_data] Finnhub ä¹Ÿå¤±è´¥: {e2}")
    
    # ç­–ç•¥ 4: å°è¯•ä» Yahoo Finance ç½‘é¡µç›´æ¥æŠ“å–ï¼ˆå¯¹æŒ‡æ•°ä»£ç ç‰¹åˆ«æœ‰æ•ˆï¼‰
    try:
        result = _fetch_with_yahoo_scrape_historical(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e3:
        print(f"[get_stock_historical_data] Yahoo Finance ç½‘é¡µæŠ“å–å¤±è´¥: {e3}")
    
    # å¯¹äºæŒ‡æ•°ä»£ç ï¼Œä¼˜å…ˆä½¿ç”¨ yfinanceï¼ˆå³ä½¿ä¹‹å‰å¤±è´¥ï¼Œå†è¯•ä¸€æ¬¡ï¼Œå› ä¸ºæŒ‡æ•°å¯èƒ½æ”¯æŒï¼‰
    if ticker.startswith('^'):
        print(f"[get_stock_historical_data] æ£€æµ‹åˆ°æŒ‡æ•°ä»£ç  {ticker}ï¼Œå°è¯•ä½¿ç”¨ yfinance ä¸“é—¨è·å–æŒ‡æ•°æ•°æ®...")
        try:
            # å¯¹äºæŒ‡æ•°ï¼Œyfinance é€šå¸¸æ”¯æŒï¼Œä½†å¯èƒ½éœ€è¦ç‰¹æ®Šå¤„ç†
            stock = yf.Ticker(ticker)
            hist = stock.history(period=period, interval=interval, timeout=20)
            
            if not hist.empty:
                data = []
                for index, row in hist.iterrows():
                    if hasattr(index, 'strftime'):
                        time_str = index.strftime('%Y-%m-%d')
                    elif hasattr(index, 'date'):
                        time_str = index.date().strftime('%Y-%m-%d')
                    else:
                        time_str = str(index)[:10]
                    
                    data.append({
                        "time": f"{time_str} 00:00",
                        "open": float(row['Open']),
                        "high": float(row['High']),
                        "low": float(row['Low']),
                        "close": float(row['Close']),
                        "volume": float(row.get('Volume', 0)),
                    })
                
                if data:
                    print(f"[get_stock_historical_data] yfinance æˆåŠŸè·å–æŒ‡æ•° {ticker} çš„ {len(data)} æ¡æ•°æ®")
                    return {"kline_data": data, "period": period, "interval": interval, "source": "yfinance_index"}
        except Exception as e_index:
            print(f"[get_stock_historical_data] yfinance è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e_index}")
    
    # ç­–ç•¥ 5a: å°è¯•ä½¿ç”¨ IEX Cloud (å…è´¹é¢åº¦å¤§ï¼Œä¼˜å…ˆä½¿ç”¨)
    try:
        result = _fetch_with_iex_cloud(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4a:
        print(f"[get_stock_historical_data] IEX Cloud å¤±è´¥: {e4a}")
    
    # ç­–ç•¥ 5b: å°è¯•ä½¿ç”¨ Tiingo (å…è´¹é¢åº¦: æ¯æ—¥500æ¬¡)
    try:
        result = _fetch_with_tiingo(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4b:
        print(f"[get_stock_historical_data] Tiingo å¤±è´¥: {e4b}")
    
    # ç­–ç•¥ 5c: å°è¯•ä½¿ç”¨ Twelve Data (å…è´¹é¢åº¦)
    try:
        result = _fetch_with_twelve_data(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4c:
        print(f"[get_stock_historical_data] Twelve Data å¤±è´¥: {e4c}")
    
    # ç­–ç•¥ 5d: å°è¯•ä½¿ç”¨ Marketstack (å…è´¹é¢åº¦: 1000æ¬¡/æœˆ)
    try:
        result = _fetch_with_marketstack(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4d:
        print(f"[get_stock_historical_data] Marketstack å¤±è´¥: {e4d}")
    
    # ç­–ç•¥ 5e: å°è¯•ä½¿ç”¨ Massive.com (åŸ Polygon.io)
    try:
        result = _fetch_with_massive_io(ticker, period)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4e:
        print(f"[get_stock_historical_data] Massive.com å¤±è´¥: {e4e}")

    # ç­–ç•¥ 5f: å°è¯• Stooq å… Key å›é€€
    try:
        result = _fetch_with_stooq_history(ticker, period, interval)
        if result and "kline_data" in result and len(result["kline_data"]) > 0:
            return result
    except Exception as e4f:
        print(f"[get_stock_historical_data] Stooq å¤±è´¥: {e4f}")

    # ç­–ç•¥ 6: æœ€åå°è¯• - ä½¿ç”¨ yfinance çš„å¤‡ç”¨æ–¹æ³•ï¼ˆä¸é€šè¿‡ Tickerï¼Œç›´æ¥ä¸‹è½½ï¼‰
    # ç­‰å¾…ä¸€æ®µæ—¶é—´åå†å°è¯•ï¼Œé¿å…é€Ÿç‡é™åˆ¶
    import time as time_module
    time_module.sleep(2)  # ç­‰å¾…2ç§’ï¼Œé¿å…é€Ÿç‡é™åˆ¶
    
    try:
        print(f"[get_stock_historical_data] å°è¯• yfinance å¤‡ç”¨æ–¹æ³•ï¼ˆç­‰å¾…åé‡è¯•ï¼‰...")
        # ä½¿ç”¨ yfinance çš„ download å‡½æ•°ï¼ˆyf å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼‰
        from datetime import datetime, timedelta
        
        period_days = {
            "1d": 1, "5d": 5, "1mo": 30, "3mo": 90, "6mo": 180,
            "1y": 365, "2y": 730, "5y": 1825, "10y": 3650, "max": 10000
        }
        days = period_days.get(period, 365)
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        # ä½¿ç”¨ yfinance.download ç›´æ¥ä¸‹è½½
        hist = yf.download(
            ticker,
            start=start_date.strftime('%Y-%m-%d'),
            end=end_date.strftime('%Y-%m-%d'),
            progress=False,
            timeout=20
        )
        
        if not hist.empty:
            data = []
            for index, row in hist.iterrows():
                if hasattr(index, 'strftime'):
                    time_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    time_str = index.date().strftime('%Y-%m-%d')
                else:
                    time_str = str(index)[:10]
                
                data.append({
                    "time": f"{time_str} 00:00",
                    "open": float(row['Open']),
                    "high": float(row['High']),
                    "low": float(row['Low']),
                    "close": float(row['Close']),
                    "volume": float(row.get('Volume', 0)) if 'Volume' in row else 0,
                })
            
            if data:
                print(f"[get_stock_historical_data] yfinance å¤‡ç”¨æ–¹æ³•æˆåŠŸè·å– {len(data)} æ¡æ•°æ®")
                return {"kline_data": data, "period": period, "interval": interval}
    except Exception as e5:
        print(f"[get_stock_historical_data] yfinance å¤‡ç”¨æ–¹æ³•å¤±è´¥: {e5}")
    
    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œå¦‚æœæ˜¯æŒ‡æ•°ï¼Œå°è¯•ä½¿ç”¨æœ€æ–°ä»·æ ¼ç”Ÿæˆå¹³æ»‘åºåˆ—
    if is_index:
        price_val = _fallback_price_value(ticker)
        if price_val:
            from datetime import datetime, timedelta
            data = []
            if interval.endswith('h'):
                # ç”Ÿæˆè¿‡å»24å°æ—¶çš„é€å°æ—¶å¹³æ»‘åºåˆ—
                now = datetime.utcnow()
                for i in range(24, 0, -1):
                    t = now - timedelta(hours=i)
                    data.append({
                        "time": t.strftime("%Y-%m-%d %H:%M"),
                        "open": float(price_val),
                        "high": float(price_val),
                        "low": float(price_val),
                        "close": float(price_val),
                        "volume": 0.0,
                    })
                print(f"[get_stock_historical_data] ä½¿ç”¨ price fallback ä¸º {ticker} ç”Ÿæˆé€å°æ—¶åºåˆ—")
                return {"kline_data": data, "period": period, "interval": interval, "source": "price_fallback_hourly"}
            else:
                from datetime import date
                end = date.today()
                for i in range(5, 0, -1):
                    d = end - timedelta(days=i)
                    data.append({
                        "time": d.strftime("%Y-%m-%d"),
                        "open": float(price_val),
                        "high": float(price_val),
                        "low": float(price_val),
                        "close": float(price_val),
                        "volume": 0.0,
                    })
                print(f"[get_stock_historical_data] ä½¿ç”¨ price fallback ä¸º {ticker} ç”Ÿæˆå¹³æ»‘åºåˆ—")
                return {"kline_data": data, "period": period, "interval": "1d", "source": "price_fallback"}

    # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯
    return {"error": f"Failed to fetch historical data for {ticker}: All data sources failed. Please try again later or check your internet connection."}

