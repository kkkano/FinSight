# -*- coding: utf-8 -*-
"""
ConversationAgent - å¯¹è¯å¼ Agent ç»Ÿä¸€å…¥å£
æ•´åˆ Routerã€Contextã€Handlers æä¾›ç»Ÿä¸€çš„å¯¹è¯æ¥å£
"""

import logging
import sys
import os
import asyncio
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, Generator, List
from datetime import datetime

logger = logging.getLogger(__name__)


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from backend.conversation.context import ContextManager
from backend.conversation.router import ConversationRouter, Intent
from backend.handlers.chat_handler import ChatHandler
from backend.handlers.followup_handler import FollowupHandler
from backend.orchestration.supervisor_agent import SupervisorAgent
from backend.orchestration.intent_classifier import IntentClassifier, Intent as AgentIntent


@dataclass
class AgentGateDecision:
    """Decision record for reliability-first agent gating."""
    need_agent: bool = False
    should_use_supervisor: bool = False
    used_supervisor: Optional[bool] = None
    agent_path: Optional[str] = None
    policy: str = "reliability_first"
    router_intent: Optional[str] = None
    hard_triggers: List[str] = field(default_factory=list)
    soft_triggers: List[str] = field(default_factory=list)
    exclusion_reason: Optional[str] = None
    classifier_intent: Optional[str] = None
    classifier_confidence: Optional[float] = None
    classifier_method: Optional[str] = None
    classifier_reasoning: Optional[str] = None
    evidence_required: bool = False

    def to_dict(self) -> Dict[str, Any]:
        payload = {
            "policy": self.policy,
            "router_intent": self.router_intent,
            "need_agent": self.need_agent,
            "should_use_supervisor": self.should_use_supervisor,
            "used_agent": self.used_supervisor,
            "agent_path": self.agent_path,
            "decision": self.agent_path or ("supervisor" if self.used_supervisor else "chat_handler"),
            "hard_triggers": self.hard_triggers,
            "soft_triggers": self.soft_triggers,
            "exclusion_reason": self.exclusion_reason,
            "classifier_intent": self.classifier_intent,
            "classifier_confidence": self.classifier_confidence,
            "classifier_method": self.classifier_method,
            "classifier_reasoning": self.classifier_reasoning,
            "evidence_required": self.evidence_required,
        }
        return {k: v for k, v in payload.items() if v not in (None, [], {})}


class ConversationAgent:
    """
    å¯¹è¯å¼è‚¡ç¥¨åˆ†æ Agent

    ç»Ÿä¸€å…¥å£ï¼Œæ•´åˆï¼š
    - ConversationRouter: æ„å›¾è¯†åˆ«
    - ContextManager: ä¸Šä¸‹æ–‡ç®¡ç†
    - ChatHandler: å¿«é€Ÿå¯¹è¯
    - ReportHandler: æ·±åº¦æŠ¥å‘Š
    - FollowupHandler: è¿½é—®å¤„ç†
    - SupervisorAgent: å¤š Agent è°ƒåº¦ (Phase 1 æ–°å¢)

    ä½¿ç”¨æ–¹å¼:
        agent = ConversationAgent()
        response = agent.chat("åˆ†æ AAPL")
    """

    def __init__(
        self,
        llm=None,
        orchestrator=None,
        report_agent=None,
        supervisor=None,
        max_context_turns: int = 10
    ):
        """
        åˆå§‹åŒ–å¯¹è¯ Agent

        Args:
            llm: LLM å®ä¾‹ï¼ˆç”¨äºå¢å¼ºå“åº”ï¼‰
            orchestrator: ToolOrchestrator å®ä¾‹
            report_agent: ç°æœ‰çš„æŠ¥å‘Šç”Ÿæˆ Agentï¼ˆlangchain_agentï¼‰
            supervisor: SupervisorAgent å®ä¾‹
            max_context_turns: æœ€å¤§ä¸Šä¸‹æ–‡è½®æ•°
        """
        self.llm = llm
        self.orchestrator = orchestrator
        self.report_agent = report_agent
        self.supervisor = supervisor

        # P1: åˆå§‹åŒ–å­ Agent ä¾› ChatHandler ä½¿ç”¨
        self.news_agent = None
        self.price_agent = None
        self._init_sub_agents()

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.context = ContextManager(max_turns=max_context_turns)
        self.router = ConversationRouter(llm=llm)

        # åˆå§‹åŒ–å¤„ç†å™¨ - P1: ä¼ é€’å­ Agent
        self.chat_handler = ChatHandler(
            llm=llm,
            orchestrator=orchestrator,
            news_agent=self.news_agent,
            price_agent=self.price_agent
        )
        # NOTE: ReportHandler å·²åºŸå¼ƒï¼ŒæŠ¥å‘Šç”Ÿæˆç»Ÿä¸€èµ° Supervisor â†’ Forum æµç¨‹
        self.followup_handler = FollowupHandler(llm=llm, orchestrator=orchestrator)

        # æ³¨å†Œå¤„ç†å™¨åˆ°è·¯ç”±å™¨
        self._register_handlers()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_queries': 0,
            'intents': {
                'chat': 0,
                'report': 0,
                'alert': 0,
                'economic_events': 0,
                'news_sentiment': 0,
                'followup': 0,
                'clarify': 0,
                'greeting': 0
            },
            'errors': 0,
            'session_start': datetime.now(),
        }
        self._agent_intent_classifier: Optional[IntentClassifier] = None

    def _init_sub_agents(self):
        """P1: åˆå§‹åŒ–å­ Agent ä¾› ChatHandler ä½¿ç”¨"""
        if not self.llm:
            logger.info("[ConversationAgent] Sub-agents skipped: LLM not available")
            return
        if not self.orchestrator:
            logger.info("[ConversationAgent] Sub-agents skipped: Orchestrator not available")
            return

        try:
            from backend.agents.news_agent import NewsAgent
            from backend.agents.price_agent import PriceAgent
            from backend.services.circuit_breaker import CircuitBreaker

            cache = getattr(self.orchestrator, 'cache', None)
            tools_module = getattr(self.orchestrator, 'tools_module', None)

            # ä½¿ç”¨ is None æ£€æŸ¥ï¼Œé¿å…ç©ºç¼“å­˜è¢«è¯¯åˆ¤ä¸º falsy
            if cache is None:
                logger.info("[ConversationAgent] Sub-agents skipped: cache not available")
                return
            if tools_module is None:
                logger.info("[ConversationAgent] Sub-agents skipped: tools_module not available")
                return

            cb = CircuitBreaker()
            try:
                self.news_agent = NewsAgent(self.llm, cache, tools_module, cb)
                logger.info("[ConversationAgent] NewsAgent initialized")
            except Exception as e:
                logger.info(f"[ConversationAgent] NewsAgent init failed: {e}")

            try:
                self.price_agent = PriceAgent(self.llm, cache, tools_module, cb)
                logger.info("[ConversationAgent] PriceAgent initialized")
            except Exception as e:
                logger.info(f"[ConversationAgent] PriceAgent init failed: {e}")

        except ImportError as e:
            logger.info(f"[ConversationAgent] Failed to import sub-agents: {e}")
        except Exception as e:
            logger.info(f"[ConversationAgent] Failed to init sub-agents: {e}")

    def _register_handlers(self):
        """æ³¨å†Œæ„å›¾å¤„ç†å™¨"""
        self.router.register_handler(Intent.CHAT, self._handle_chat)
        self.router.register_handler(Intent.REPORT, self._handle_report)
        self.router.register_handler(Intent.ALERT, self._handle_alert)
        self.router.register_handler(Intent.ECONOMIC_EVENTS, self._handle_economic_events)
        self.router.register_handler(Intent.NEWS_SENTIMENT, self._handle_news_sentiment)
        self.router.register_handler(Intent.FOLLOWUP, self._handle_followup)
        self.router.register_handler(Intent.CLARIFY, self._handle_clarify)
        self.router.register_handler(Intent.GREETING, self._handle_greeting)

    def _add_thinking_step(self, steps, stage: str, message: str) -> Dict[str, Any]:
        step = {
            "stage": stage,
            "message": message,
            "timestamp": datetime.now().isoformat(),
        }
        steps.append(step)
        return step

    @staticmethod
    def _trim_text(value: Optional[str], limit: int = 200) -> Optional[str]:
        if value is None:
            return None
        return value if len(value) <= limit else value[:limit] + "..."

    @staticmethod
    def _compact_dict(payload: Dict[str, Any]) -> Dict[str, Any]:
        return {key: value for key, value in payload.items() if value not in (None, [], {})}

    def _get_agent_intent_classifier(self) -> IntentClassifier:
        if self._agent_intent_classifier is None:
            self._agent_intent_classifier = IntentClassifier(self.llm)
        return self._agent_intent_classifier

    def _serialize_agent_outputs(self, agent_outputs: Any) -> Any:
        if not isinstance(agent_outputs, dict):
            return agent_outputs
        serialized = {}
        for name, output in agent_outputs.items():
            if isinstance(output, dict):
                serialized[name] = output
                continue
            serialized[name] = {
                "summary": getattr(output, "summary", ""),
                "confidence": getattr(output, "confidence", None),
                "data_sources": getattr(output, "data_sources", None),
                "evidence": getattr(output, "evidence", None),
                "trace": getattr(output, "trace", None),
            }
        return serialized

    def _evaluate_agent_gate(
        self,
        query: str,
        intent: Intent,
        metadata: Dict[str, Any],
    ) -> AgentGateDecision:
        decision = AgentGateDecision(router_intent=intent.value if intent else None)

        # Hard exclusions
        if intent in {Intent.GREETING, Intent.CLARIFY}:
            decision.exclusion_reason = f"router_{intent.value}"
            return decision
        if intent == Intent.ALERT:
            decision.exclusion_reason = "alert_flow"
            return decision

        if not self.supervisor:
            decision.exclusion_reason = "supervisor_unavailable"
            return decision

        query_lower = query.lower()
        tickers = metadata.get("tickers", []) if isinstance(metadata, dict) else []

        time_keywords = [
            "ç°åœ¨", "æœ€æ–°", "ä»Šå¤©", "æœ¬å‘¨", "è¿‘æœŸ", "æœ€è¿‘", "å®æ—¶",
            "current", "latest", "today", "this week", "recent",
        ]
        decision_keywords = [
            "æ¨è", "ä¹°", "å–", "å€¼ä¸å€¼å¾—", "å€¼å¾—", "åº”è¯¥", "å‰æ™¯", "é£é™©",
            "åŸå› ", "ä¸ºä»€ä¹ˆ", "é€»è¾‘", "é¢„æµ‹", "å»ºè®®", "æ€ä¹ˆåš", "ä¹°å…¥", "å–å‡º", "æŒæœ‰",
            "recommend", "should i", "worth", "risk", "why", "reason", "forecast",
        ]
        comparison_keywords = [
            "å¯¹æ¯”", "æ¯”è¾ƒ", "vs", "versus", "å“ªä¸ªå¥½", "å“ªä¸ªæ›´å¥½", "é€‰å“ªä¸ª",
            "difference", "compare",
        ]
        analysis_keywords = [
            "åˆ†æ", "ç ”æŠ¥", "æŠ¥å‘Š", "æ·±åº¦", "ç ”ç©¶", "analysis", "report", "research",
        ]
        financial_keywords = [
            "è´¢æŠ¥", "è¥æ”¶", "åˆ©æ¶¦", "ç°é‡‘æµ", "èµ„äº§è´Ÿå€º", "ä¼°å€¼", "pe", "eps", "roe",
            "roa", "å¸‚ç›ˆç‡", "å¸‚å‡€ç‡", "åŸºæœ¬é¢", "earnings", "revenue", "profit",
            "cash flow", "valuation",
        ]
        news_keywords = ["æ–°é—»", "å¿«è®¯", "æ¶ˆæ¯", "å¤´æ¡", "news", "headline", "çƒ­ç‚¹", "å…¬å‘Š", "äº‹ä»¶"]
        sentiment_keywords = ["æƒ…ç»ª", "ææƒ§", "è´ªå©ª", "èˆ†æƒ…", "sentiment", "fear", "greed", "media sentiment"]
        macro_keywords = [
            "å®è§‚", "cpi", "ppi", "gdp", "fomc", "åˆ©ç‡", "éå†œ", "å°±ä¸š", "é€šèƒ€",
            "macro", "economic calendar", "economic events", "å¤®è¡Œ",
        ]

        has_financial_context = bool(tickers) or any(
            kw in query_lower for kw in (financial_keywords + news_keywords + sentiment_keywords + macro_keywords)
        )

        if any(kw in query_lower for kw in time_keywords):
            decision.hard_triggers.append("timeliness")
        if any(kw in query_lower for kw in decision_keywords):
            decision.hard_triggers.append("decision")
        if metadata.get("is_comparison") or any(kw in query_lower for kw in comparison_keywords):
            decision.hard_triggers.append("comparison")
        if any(kw in query_lower for kw in financial_keywords):
            decision.hard_triggers.append("fundamental")
        if any(kw in query_lower for kw in news_keywords):
            decision.hard_triggers.append("news")
        if any(kw in query_lower for kw in sentiment_keywords):
            decision.hard_triggers.append("sentiment")
        if any(kw in query_lower for kw in macro_keywords):
            decision.hard_triggers.append("macro")
        if has_financial_context and any(kw in query_lower for kw in analysis_keywords):
            decision.hard_triggers.append("analysis")

        classifier = self._get_agent_intent_classifier()
        classification = classifier.classify(query, tickers, context_summary=self.context.get_summary())
        decision.classifier_intent = classification.intent.value
        decision.classifier_confidence = classification.confidence
        decision.classifier_method = classification.method
        decision.classifier_reasoning = classification.reasoning

        if classification.confidence < 0.70:
            decision.soft_triggers.append("low_confidence")
        if len(tickers) >= 2 and "comparison" not in decision.hard_triggers:
            decision.soft_triggers.append("multi_ticker")
        if tickers and not decision.hard_triggers and classification.intent in {
            AgentIntent.SEARCH, AgentIntent.CLARIFY, AgentIntent.OFF_TOPIC
        }:
            decision.soft_triggers.append("ticker_unclear")
        if classification.intent in {
            AgentIntent.REPORT, AgentIntent.COMPARISON, AgentIntent.FUNDAMENTAL,
            AgentIntent.TECHNICAL, AgentIntent.MACRO, AgentIntent.NEWS, AgentIntent.SENTIMENT
        } and classification.confidence >= 0.70:
            decision.soft_triggers.append("classifier_requires_agent")

        decision.need_agent = bool(decision.hard_triggers or decision.soft_triggers)
        decision.evidence_required = decision.need_agent
        decision.should_use_supervisor = decision.need_agent

        return decision

    def evaluate_agent_gate(
        self,
        query: str,
        intent: Intent,
        metadata: Dict[str, Any],
    ) -> AgentGateDecision:
        """Public wrapper for agent gate evaluation."""
        return self._evaluate_agent_gate(query, intent, metadata)

    def _convert_supervisor_result(self, result: Any) -> Dict[str, Any]:
        classification = getattr(result, "classification", None)
        classification_payload = None
        if classification:
            classification_payload = {
                "intent": classification.intent.value,
                "confidence": classification.confidence,
                "method": classification.method,
                "reasoning": classification.reasoning,
                "scores": classification.scores,
                "tickers": classification.tickers,
            }
        data = {
            "agent_outputs": self._serialize_agent_outputs(getattr(result, "agent_outputs", None)),
            "classification": classification_payload,
            "errors": getattr(result, "errors", None),
            "budget": getattr(result, "budget", None),
        }
        response_text = str(result.response) if getattr(result, "response", None) is not None else ""
        return {
            "success": bool(getattr(result, "success", True)),
            "response": response_text,
            "data": self._compact_dict(data),
            "method": "supervisor",
            "agent_used": True,
            "agent_path": "supervisor",
            "agent_intent": getattr(result, "intent", None).value if getattr(result, "intent", None) else None,
        }

    async def _run_supervisor_process_async(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        if not self.supervisor:
            return {
                "success": False,
                "response": "Supervisor ä¸å¯ç”¨ï¼Œå·²å›é€€åˆ°å¿«é€Ÿå›ç­”ã€‚",
                "intent": "chat",
                "agent_used": False,
                "agent_path": "chat_handler",
            }
        tickers = metadata.get("tickers", []) if isinstance(metadata, dict) else []
        result = await self.supervisor.process(
            query=query,
            tickers=tickers,
            context_summary=self.context.get_summary(),
            context_ticker=self.context.current_focus,
        )
        return self._convert_supervisor_result(result)

    def _run_supervisor_process(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        if not self.supervisor:
            return {
                "success": False,
                "response": "Supervisor ä¸å¯ç”¨ï¼Œå·²å›é€€åˆ°å¿«é€Ÿå›ç­”ã€‚",
                "intent": "chat",
                "agent_used": False,
                "agent_path": "chat_handler",
            }
        tickers = metadata.get("tickers", []) if isinstance(metadata, dict) else []
        try:
            asyncio.get_running_loop()
            logger.info("[AgentGate] å·²æœ‰äº‹ä»¶å¾ªç¯ï¼Œæ— æ³•åŒæ­¥è°ƒç”¨ Supervisor")
            return {
                "success": False,
                "response": "Supervisor ä»…æ”¯æŒå¼‚æ­¥è°ƒç”¨ï¼Œè¯·ä½¿ç”¨æµå¼æ¥å£ã€‚",
                "intent": "chat",
                "agent_used": False,
                "agent_path": "chat_handler",
            }
        except RuntimeError:
            result = asyncio.run(self.supervisor.process(
                query=query,
                tickers=tickers,
                context_summary=self.context.get_summary(),
                context_ticker=self.context.current_focus,
            ))
            return self._convert_supervisor_result(result)

    def _build_collection_result(self, metadata: Dict[str, Any], result: Dict[str, Any]) -> Dict[str, Any]:
        data = result.get("data") or {}
        payload = {
            "ticker": metadata.get("tickers", [None])[0] if metadata.get("tickers") else None,
            "data_origin": data.get("data_origin") or data.get("source"),
            "tried_sources": data.get("tried_sources"),
            "fallback_used": data.get("fallback_used"),
            "as_of": data.get("as_of"),
            "trace": data.get("trace"),
            "plan": data.get("plan"),
            "plan_trace": data.get("plan_trace"),
        }
        deep_search = data.get("deep_search") if isinstance(data, dict) else None
        if isinstance(deep_search, dict):
            evidence = deep_search.get("evidence") or []
            pdf_count = sum(
                1 for item in evidence
                if isinstance(item, dict) and item.get("meta", {}).get("is_pdf")
            )
            payload["deep_search"] = self._compact_dict({
                "summary": deep_search.get("summary"),
                "confidence": deep_search.get("confidence"),
                "data_sources": deep_search.get("data_sources"),
                "evidence_count": len(evidence),
                "pdf_count": pdf_count,
                "evidence": evidence,
                "trace": deep_search.get("trace"),
            })

        agent_outputs = data.get("agent_outputs") if isinstance(data, dict) else None
        if isinstance(agent_outputs, dict):
            agents = []
            for name, output in agent_outputs.items():
                try:
                    if isinstance(output, dict):
                        summary = output.get("summary", "")
                        confidence = output.get("confidence")
                        data_sources = output.get("data_sources", [])
                        evidence = output.get("evidence") or []
                        trace = output.get("trace", [])
                    else:
                        summary = getattr(output, "summary", "")
                        confidence = getattr(output, "confidence", None)
                        data_sources = getattr(output, "data_sources", [])
                        evidence = getattr(output, "evidence", []) or []
                        trace = getattr(output, "trace", [])
                    agents.append(self._compact_dict({
                        "agent": name,
                        "summary": summary,
                        "confidence": confidence,
                        "data_sources": data_sources,
                        "evidence_count": len(evidence),
                        "trace": trace,
                    }))
                except Exception:
                    continue
            if agents:
                payload["agents"] = agents
        return self._compact_dict(payload)

    def _build_processing_result(
        self,
        intent: Intent,
        handler: Optional[Any],
        result: Dict[str, Any],
    ) -> Dict[str, Any]:
        data = result.get("data") or {}
        if handler:
            handler_name = handler.__name__
        else:
            handler_name = "supervisor" if result.get("agent_path") == "supervisor" else "default_handler"
        payload = {
            "intent": intent.value,
            "handler": handler_name,
            "method": result.get("method"),
            "success": result.get("success", True),
            "agent_used": result.get("agent_used"),
            "agent_path": result.get("agent_path"),
            "agent_intent": result.get("agent_intent"),
            "intent_detail": result.get("intent_detail"),
            "data_origin": data.get("data_origin") or data.get("source"),
            "tried_sources": data.get("tried_sources"),
            "fallback_used": data.get("fallback_used"),
            "response_preview": self._trim_text(result.get("response", "")),
            "note": result.get("thinking"),
            "report_present": bool(result.get("report")),
        }
        return self._compact_dict(payload)

    def chat(self, query: str, capture_thinking: bool = False) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ï¼ˆä¸»å…¥å£ï¼‰

        Args:
            query: ç”¨æˆ·è¾“å…¥
            capture_thinking: æ˜¯å¦æ•è·æ€è€ƒè¿‡ç¨‹

        Returns:
            åŒ…å«å“åº”å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        self.stats['total_queries'] += 1
        start_time = datetime.now()
        thinking_steps = [] if capture_thinking else None
        reference_step = None
        intent_step = None
        gate_step = None
        collection_step = None
        processing_step = None

        try:
            user_query = query
            preprocess = self.context.preprocess_query(query)
            prepared_query = preprocess.get("query", query)

            # 1. è§£ææŒ‡ä»£ï¼ˆå¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼‰
            if capture_thinking:
                reference_step = self._add_thinking_step(
                    thinking_steps,
                    "reference_resolution",
                    "æ­£åœ¨è§£æä¸Šä¸‹æ–‡å¼•ç”¨..."
                )

            resolved_query = self.context.resolve_reference(prepared_query)
            if capture_thinking and reference_step is not None:
                reference_step["result"] = self._compact_dict({
                    "original_query": user_query,
                    "preprocessed_query": prepared_query,
                    "resolved_query": resolved_query,
                    "selection_reason": preprocess.get("selection_reason"),
                    "selected_ticker": preprocess.get("selected_ticker"),
                    "market_hint": preprocess.get("market_hint"),
                    "current_focus": self.context.current_focus,
                    "context_summary": self._trim_text(self.context.get_summary(), 200),
                })

            # 2. è·¯ç”±åˆ°å¯¹åº”å¤„ç†å™¨
            if capture_thinking:
                intent_step = self._add_thinking_step(
                    thinking_steps,
                    "intent_classification",
                    "æ­£åœ¨è¯†åˆ«æŸ¥è¯¢æ„å›¾..."
                )

            intent, metadata, handler = self.router.route(resolved_query, self.context)

            if capture_thinking and intent_step is not None:
                intent_step["result"] = self._compact_dict({
                    "intent": intent.value,
                    "tickers": metadata.get('tickers', []),
                    "company_names": metadata.get('company_names', []),
                    "is_comparison": metadata.get('is_comparison'),
                })

            # 2.1 Agent gate (reliability-first)
            if capture_thinking:
                gate_step = self._add_thinking_step(
                    thinking_steps,
                    "agent_gate",
                    "è¯„ä¼°æ˜¯å¦éœ€è¦è°ƒç”¨å¤šAgent..."
                )
            gate_decision = self._evaluate_agent_gate(resolved_query, intent, metadata)
            use_supervisor = bool(gate_decision.should_use_supervisor and intent != Intent.REPORT and self.supervisor)
            gate_decision.used_supervisor = bool(
                use_supervisor or (intent == Intent.REPORT and self.supervisor)
            )
            gate_decision.agent_path = "supervisor" if gate_decision.used_supervisor else "chat_handler"
            metadata["agent_gate"] = gate_decision.to_dict()
            if capture_thinking and gate_step is not None:
                gate_step["result"] = self._compact_dict(gate_decision.to_dict())

            # 3. æ›´æ–°ç»Ÿè®¡
            self.stats['intents'][intent.value] = self.stats['intents'].get(intent.value, 0) + 1

            # 4. æ•°æ®æ”¶é›†é˜¶æ®µï¼ˆå¦‚æœæœ‰è‚¡ç¥¨ä»£ç ï¼‰
            if capture_thinking and metadata.get('tickers'):
                ticker = metadata['tickers'][0]
                collection_step = self._add_thinking_step(
                    thinking_steps,
                    "data_collection",
                    f"æ­£åœ¨è·å– {ticker} çš„æ•°æ®..."
                )

            # 5. è°ƒç”¨å¤„ç†å™¨
            if capture_thinking:
                processing_step = self._add_thinking_step(
                    thinking_steps,
                    "processing",
                    f"æ­£åœ¨ç”Ÿæˆ{intent.value}å“åº”..."
                )

            handler_used = handler
            if intent == Intent.REPORT and self.supervisor:
                result = self._handle_report(resolved_query, metadata)
                handler_used = None
            elif use_supervisor:
                result = self._run_supervisor_process(resolved_query, metadata)
                handler_used = None
            elif handler:
                result = handler(resolved_query, metadata)
            else:
                result = self._default_handler(resolved_query, metadata)

            if isinstance(result, dict):
                result.setdefault("agent_used", bool(use_supervisor or (intent == Intent.REPORT and self.supervisor)))
                result.setdefault("agent_path", "supervisor" if result.get("agent_used") else "chat_handler")
                if result.get("agent_used") and not result.get("agent_intent"):
                    result["agent_intent"] = "report" if intent == Intent.REPORT else None
                result["agent_gate"] = metadata.get("agent_gate")

            if capture_thinking:
                if collection_step is not None:
                    collection_step["result"] = self._build_collection_result(metadata, result)
                if processing_step is not None:
                    processing_step["result"] = self._build_processing_result(intent, handler_used, result)
                complete_step = self._add_thinking_step(
                    thinking_steps,
                    "complete",
                    "å¤„ç†å®Œæˆ"
                )
                complete_step["result"] = self._compact_dict({
                    "elapsed_seconds": round((datetime.now() - start_time).total_seconds(), 2),
                    "success": result.get("success", True),
                    "report_present": bool(result.get("report")),
                })

            # 6. æ›´æ–°ä¸Šä¸‹æ–‡
            self.context.add_turn(
                query=user_query,
                intent=intent.value,
                response=result.get('response', ''),
                metadata=metadata
            )

            # 7. è‡ªåŠ¨æ·»åŠ å›¾è¡¨æ ‡è®°ï¼ˆæ ¹æ®ä¸Šä¸‹æ–‡å’ŒæŸ¥è¯¢ï¼‰
            # åªæœ‰ CHAT/REPORT æ„å›¾æ‰å°è¯•ç”Ÿæˆå›¾è¡¨ï¼Œé—²èŠä¸ç”Ÿæˆ
            if intent in [Intent.CHAT, Intent.REPORT, Intent.FOLLOWUP]:
                result = self._add_chart_marker(result, user_query, metadata, resolved_query)

            # 8. æ·»åŠ å…ƒä¿¡æ¯
            result['intent'] = intent.value
            result['metadata'] = metadata
            result['response_time_ms'] = (datetime.now() - start_time).total_seconds() * 1000
            result['thinking_elapsed_seconds'] = round((datetime.now() - start_time).total_seconds(), 2)
            result['current_focus'] = self.context.current_focus

            if capture_thinking and thinking_steps:
                result['thinking'] = thinking_steps

            return result

        except Exception as e:
            self.stats['errors'] += 1
            import traceback
            traceback.print_exc()
            error_result = {
                'success': False,
                'response': f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'response_time_ms': (datetime.now() - start_time).total_seconds() * 1000,
                'thinking_elapsed_seconds': round((datetime.now() - start_time).total_seconds(), 2),
            }
            if capture_thinking and thinking_steps is not None:
                error_step = self._add_thinking_step(
                    thinking_steps,
                    "error",
                    "å¤„ç†å¤±è´¥"
                )
                error_step["result"] = {"error": str(e)}
                error_result['thinking'] = thinking_steps
            return error_result


    async def chat_async(self, query: str, capture_thinking: bool = False) -> Dict[str, Any]:
        """
        Async version of chat() that can await Supervisor paths.
        """
        self.stats['total_queries'] += 1
        start_time = datetime.now()
        thinking_steps = [] if capture_thinking else None
        reference_step = None
        intent_step = None
        gate_step = None
        collection_step = None
        processing_step = None

        try:
            user_query = query
            preprocess = self.context.preprocess_query(query)
            prepared_query = preprocess.get("query", query)

            if capture_thinking:
                reference_step = self._add_thinking_step(
                    thinking_steps,
                    "reference_resolution",
                    "æ­£åœ¨è§£æä¸Šä¸‹æ–‡å¼•ç”¨..."
                )

            resolved_query = self.context.resolve_reference(prepared_query)
            if capture_thinking and reference_step is not None:
                reference_step["result"] = self._compact_dict({
                    "original_query": user_query,
                    "preprocessed_query": prepared_query,
                    "resolved_query": resolved_query,
                    "selection_reason": preprocess.get("selection_reason"),
                    "selected_ticker": preprocess.get("selected_ticker"),
                    "market_hint": preprocess.get("market_hint"),
                    "current_focus": self.context.current_focus,
                    "context_summary": self._trim_text(self.context.get_summary(), 200),
                })

            if capture_thinking:
                intent_step = self._add_thinking_step(
                    thinking_steps,
                    "intent_classification",
                    "æ­£åœ¨è¯†åˆ«æŸ¥è¯¢æ„å›¾..."
                )

            intent, metadata, handler = self.router.route(resolved_query, self.context)

            if capture_thinking and intent_step is not None:
                intent_step["result"] = self._compact_dict({
                    "intent": intent.value,
                    "tickers": metadata.get('tickers', []),
                    "company_names": metadata.get('company_names', []),
                    "is_comparison": metadata.get('is_comparison'),
                })

            # Agent gate (reliability-first)
            if capture_thinking:
                gate_step = self._add_thinking_step(
                    thinking_steps,
                    "agent_gate",
                    "è¯„ä¼°æ˜¯å¦éœ€è¦è°ƒç”¨å¤šAgent..."
                )
            gate_decision = self._evaluate_agent_gate(resolved_query, intent, metadata)
            use_supervisor = bool(gate_decision.should_use_supervisor and intent != Intent.REPORT and self.supervisor)
            gate_decision.used_supervisor = bool(
                use_supervisor or (intent == Intent.REPORT and self.supervisor)
            )
            gate_decision.agent_path = "supervisor" if gate_decision.used_supervisor else "chat_handler"
            metadata["agent_gate"] = gate_decision.to_dict()
            if capture_thinking and gate_step is not None:
                gate_step["result"] = self._compact_dict(gate_decision.to_dict())

            self.stats['intents'][intent.value] = self.stats['intents'].get(intent.value, 0) + 1

            if capture_thinking and metadata.get('tickers'):
                ticker = metadata['tickers'][0]
                collection_step = self._add_thinking_step(
                    thinking_steps,
                    "data_collection",
                    f"æ­£åœ¨è·å– {ticker} çš„æ•°æ®..."
                )

            if capture_thinking:
                processing_step = self._add_thinking_step(
                    thinking_steps,
                    "processing",
                    f"æ­£åœ¨ç”Ÿæˆ{intent.value}å“åº”..."
                )

            handler_used = handler
            if intent == Intent.REPORT and self.supervisor and metadata.get('tickers'):
                result = await self._handle_report_async(resolved_query, metadata)
                handler_used = None
            elif use_supervisor:
                result = await self._run_supervisor_process_async(resolved_query, metadata)
                handler_used = None
            elif handler:
                result = await asyncio.to_thread(handler, resolved_query, metadata)
            else:
                result = await asyncio.to_thread(self._default_handler, resolved_query, metadata)

            if isinstance(result, dict):
                result.setdefault("agent_used", bool(use_supervisor or (intent == Intent.REPORT and self.supervisor)))
                result.setdefault("agent_path", "supervisor" if result.get("agent_used") else "chat_handler")
                if result.get("agent_used") and not result.get("agent_intent"):
                    result["agent_intent"] = "report" if intent == Intent.REPORT else None
                result["agent_gate"] = metadata.get("agent_gate")

            if capture_thinking:
                if collection_step is not None:
                    collection_step["result"] = self._build_collection_result(metadata, result)
                if processing_step is not None:
                    processing_step["result"] = self._build_processing_result(intent, handler_used, result)
                complete_step = self._add_thinking_step(
                    thinking_steps,
                    "complete",
                    "å¤„ç†å®Œæˆ"
                )
                complete_step["result"] = self._compact_dict({
                    "elapsed_seconds": round((datetime.now() - start_time).total_seconds(), 2),
                    "success": result.get("success", True),
                    "report_present": bool(result.get("report")),
                })

            self.context.add_turn(
                query=user_query,
                intent=intent.value,
                response=result.get('response', ''),
                metadata=metadata
            )

            if intent in [Intent.CHAT, Intent.REPORT, Intent.FOLLOWUP]:
                result = self._add_chart_marker(result, user_query, metadata, resolved_query)

            result['intent'] = intent.value
            result['metadata'] = metadata
            result['response_time_ms'] = (datetime.now() - start_time).total_seconds() * 1000
            result['thinking_elapsed_seconds'] = round((datetime.now() - start_time).total_seconds(), 2)
            result['current_focus'] = self.context.current_focus

            if capture_thinking and thinking_steps:
                result['thinking'] = thinking_steps

            return result

        except Exception as e:
            self.stats['errors'] += 1
            import traceback
            traceback.print_exc()
            error_result = {
                'success': False,
                'response': f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'response_time_ms': (datetime.now() - start_time).total_seconds() * 1000,
                'thinking_elapsed_seconds': round((datetime.now() - start_time).total_seconds(), 2),
            }
            if capture_thinking and thinking_steps is not None:
                error_step = self._add_thinking_step(
                    thinking_steps,
                    "error",
                    "å¤„ç†å¤±è´¥"
                )
                error_step["result"] = {"error": str(e)}
                error_result['thinking'] = thinking_steps
            return error_result

    def _handle_chat(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å¿«é€Ÿå¯¹è¯"""
        if self.llm:
            return self.chat_handler.handle_with_llm(query, metadata, self.context)
        return self.chat_handler.handle(query, metadata, self.context)


    async def _handle_report_async(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Async report path - ç»Ÿä¸€èµ° Supervisor â†’ Forum æµç¨‹"""
        if not self.supervisor:
            return {
                'success': False,
                'response': 'æŠ¥å‘Šç”ŸæˆæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ Supervisor é…ç½®ã€‚',
                'intent': 'report',
            }
        
        tickers = metadata.get('tickers', [])
        if not tickers:
            return {
                'success': False,
                'response': 'è¯·æŒ‡å®šè¦åˆ†æçš„è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šåˆ†æ AAPL',
                'intent': 'report',
            }
        
        ticker = tickers[0]
        try:
            analysis_result = await self.supervisor.analyze(query, ticker, user_profile=None)
            forum_output = analysis_result.get("forum_output")

            response_text = forum_output.consensus if forum_output else ""
            result = {
                'success': True,
                'response': response_text,
                'data': analysis_result,
                'method': 'supervisor',
            }
            return result
        except Exception as e:
            logger.error(f"[Agent] Supervisor async call failed: {e}")
            return {
                'success': False,
                'response': f'æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}',
                'intent': 'report',
            }

    def _handle_report(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æŠ¥å‘Šè¯·æ±‚ - ç»Ÿä¸€èµ° Supervisor æµç¨‹"""
        if not self.supervisor:
            return {
                'success': False,
                'response': 'æŠ¥å‘Šç”ŸæˆæœåŠ¡ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ Supervisor é…ç½®ã€‚',
                'intent': 'report',
            }
        
        tickers = metadata.get('tickers', [])
        if not tickers:
            return {
                'success': False,
                'response': 'è¯·æŒ‡å®šè¦åˆ†æçš„è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šåˆ†æ AAPL',
                'intent': 'report',
            }
        
        # å°è¯•å¼‚æ­¥æ‰§è¡Œ
        try:
            asyncio.get_running_loop()
            logger.info(f"[Agent._handle_report] å·²æœ‰äº‹ä»¶å¾ªç¯ï¼Œæ— æ³•åŒæ­¥è°ƒç”¨ Supervisor")
            return {
                'success': False,
                'response': 'è¯·ä½¿ç”¨æµå¼æ¥å£ /api/chat ç”ŸæˆæŠ¥å‘Š',
                'intent': 'report',
            }
        except RuntimeError:
            return asyncio.run(self._handle_report_async(query, metadata))

    def _handle_alert(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç›‘æ§è¯·æ±‚ï¼ˆå¾…å®ç°ï¼‰"""
        tickers = metadata.get('tickers', [])
        ticker = tickers[0] if tickers else None
        explicit_company = bool(metadata.get('company_names') or metadata.get('company_mentions'))
        if not ticker and self.context.current_focus and not explicit_company:
            ticker = self.context.current_focus
        if explicit_company and not ticker:
            return self.chat_handler._handle_company_clarification(query, metadata)

        return {
            'success': True,
            'response': f"""ğŸ“Š ç›‘æ§åŠŸèƒ½è¯´æ˜

æ‚¨æƒ³ç›‘æ§ {ticker or 'æŸæ”¯è‚¡ç¥¨'} çš„ä»·æ ¼å˜åŠ¨ã€‚

ç›®å‰ç›‘æ§åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œå³å°†æ”¯æŒï¼š
1. ä»·æ ¼çªç ´æé†’
2. æ¶¨è·Œå¹…æé†’
3. æˆäº¤é‡å¼‚å¸¸æé†’
4. æ–°é—»åŠ¨æ€æé†’

è¯·ç¨åå†è¯•ï¼Œæˆ–å…ˆä½¿ç”¨ä»·æ ¼æŸ¥è¯¢åŠŸèƒ½äº†è§£å½“å‰è¡Œæƒ…ã€‚""",
            'intent': 'alert',
            'feature_status': 'coming_soon',
        }

    def _handle_economic_events(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†ç»æµæ—¥å†/å®è§‚äº‹ä»¶æŸ¥è¯¢"""
        return self.chat_handler._handle_economic_events(query, self.context)

    def _handle_news_sentiment(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ–°é—»æƒ…ç»ª/èˆ†æƒ…æŸ¥è¯¢"""
        tickers = metadata.get('tickers', [])
        ticker = tickers[0] if tickers else None
        explicit_company = bool(metadata.get('company_names') or metadata.get('company_mentions'))
        if not ticker and self.context.current_focus and not explicit_company:
            ticker = self.context.current_focus
        if explicit_company and not ticker:
            return self.chat_handler._handle_company_clarification(query, metadata)
        return self.chat_handler._handle_news_sentiment_query(ticker, query, self.context)

    def _handle_followup(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†è¿½é—®"""
        return self.followup_handler.handle(query, metadata, self.context)

    def _handle_greeting(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é—®å€™å’Œæ—¥å¸¸é—²èŠ (ä¸è°ƒç”¨æœç´¢)"""
        if any(kw in query.lower() for kw in ['è‡ªæˆ‘ä»‹ç»', 'ä½ æ˜¯è°', 'introduce yourself', 'who are you', 'ä½ æ˜¯åš', 'ä½ æ˜¯å¹²']):
            response = """æˆ‘æ˜¯ä¸€ä¸ªä¸“ä¸šçš„**é‡‘èå¯¹è¯å¼åˆ†æ Agent**ï¼Œåå« FinSight AIã€‚

æˆ‘çš„ä¸»è¦å·¥ä½œæ˜¯å¸®åŠ©æ‚¨å¿«é€Ÿè·å–å’Œåˆ†æå…¨çƒè‚¡ç¥¨ã€æŒ‡æ•°ã€ETF ç­‰é‡‘èå¸‚åœºä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
1. **å®æ—¶è¡Œæƒ…æŸ¥è¯¢**ï¼šè‚¡ä»·ã€æ¶¨è·Œå¹…ã€K çº¿å›¾ç­‰ã€‚
2. **æ·±åº¦æŠ¥å‘Šç”Ÿæˆ**ï¼šå¯¹ç‰¹å®šè‚¡ç¥¨è¿›è¡ŒåŸºæœ¬é¢ã€è´¢åŠ¡ã€ä¼°å€¼ã€é£é™©åˆ†æã€‚
3. **è¡Œä¸šè¶‹åŠ¿æ´å¯Ÿ**ï¼šåˆ†æå¸‚åœºçƒ­ç‚¹å’Œè¡Œä¸šåŠ¨å‘ã€‚
4. **æŠ•èµ„å»ºè®®**ï¼šæ ¹æ®æ‚¨çš„éœ€æ±‚æä¾›ä¸­è‚¯çš„æŠ•èµ„å»ºè®®ã€‚

æ‚¨æœ‰ä»€ä¹ˆæƒ³äº†è§£çš„è‚¡ç¥¨ï¼ˆä¾‹å¦‚ï¼š**AAPL**ï¼‰æˆ–é‡‘èé—®é¢˜å—ï¼Ÿ"""
        else:
            response = "æ‚¨å¥½ï¼æˆ‘æ˜¯ FinSight AI é‡‘èåŠ©æ‰‹ã€‚æ‚¨ä»Šå¤©æƒ³äº†è§£å“ªæ”¯è‚¡ç¥¨çš„è¡Œæƒ…ï¼Œæˆ–è€…éœ€è¦ç”Ÿæˆå“ªå®¶å…¬å¸çš„åˆ†ææŠ¥å‘Šå—ï¼Ÿ"

        return {
            'success': True,
            'response': response,
            'intent': 'greeting',
        }

    def _handle_clarify(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†éœ€è¦æ¾„æ¸…çš„æŸ¥è¯¢"""
        clarify_reason = metadata.get("clarify_reason")
        if metadata.get('company_names') or metadata.get('company_mentions'):
            return self.chat_handler._handle_company_clarification(query, metadata)
        if clarify_reason == "followup_without_context":
            response = """çœ‹èµ·æ¥ä½ æ˜¯åœ¨è¿½é—®ä¸Šä¸€æ¡å†…å®¹ï¼Œä½†æˆ‘è¿™è¾¹æ²¡æœ‰ä¸Šä¸‹æ–‡ã€‚å¯ä»¥å‘Šè¯‰æˆ‘ä½ å…·ä½“æƒ³è¿½é—®å“ªåªè‚¡ç¥¨/æŒ‡æ•°/è¡Œä¸šæˆ–å“ªæ¡æ–°é—»å—ï¼Ÿ

ä¾‹å¦‚ï¼š
1. "AAPL ä¸ºä»€ä¹ˆä»Šå¤©ä¸‹è·Œï¼Ÿ"
2. "æœ€è¿‘å¸‚åœºçƒ­ç‚¹æœ‰å“ªäº›ï¼Ÿ"
3. "è§£é‡Šä¸€ä¸‹åˆšæ‰çš„ç»“è®ºï¼šXXX"
"""
            return {
                'success': True,
                'response': response,
                'intent': 'clarify',
                'needs_clarification': True,
            }

        return {
            'success': True,
            'response': """æŠ±æ­‰ï¼Œæˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³äº†è§£ä»€ä¹ˆã€‚

æˆ‘æ˜¯ä¸“æ³¨äº**é‡‘èå¸‚åœºåˆ†æ**çš„åŠ©æ‰‹ã€‚å¯¹äºéé‡‘èç±»é—®é¢˜ï¼ˆå¦‚ç¼–ç¨‹ä»£ç ã€å¤©æ°”ã€å…«å¦å¨±ä¹ç­‰ï¼‰ï¼Œæˆ‘å¯èƒ½æ— æ³•æä¾›å‡†ç¡®å¸®åŠ©ã€‚

æ‚¨å¯ä»¥å°è¯•é—®æˆ‘ï¼š
1. è‚¡ç¥¨è¡Œæƒ…ï¼š**"AAPL ç°åœ¨å¤šå°‘é’±ï¼Ÿ"**
2. å…¬å¸åˆ†æï¼š**"åˆ†æä¸€ä¸‹ç‰¹æ–¯æ‹‰"**
3. æŠ•èµ„å»ºè®®ï¼š**"ç°åœ¨ä¹°è‹±ä¼Ÿè¾¾æ€ä¹ˆæ ·ï¼Ÿ"**

è¯·æä¾›å…·ä½“çš„è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°ï¼Œé‡æ–°æé—®ï¼""",
            'intent': 'clarify',
            'needs_clarification': True,
        }

    def _default_handler(self, query: str, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """é»˜è®¤å¤„ç†å™¨"""
        return self._handle_chat(query, metadata)

    def _add_chart_marker(
        self,
        result: Dict[str, Any],
        original_query: str,
        metadata: Dict[str, Any],
        resolved_query: str
    ) -> Dict[str, Any]:
        """
        æ ¹æ®ä¸Šä¸‹æ–‡å’ŒæŸ¥è¯¢è‡ªåŠ¨æ·»åŠ å›¾è¡¨æ ‡è®°

        å›¾è¡¨æ ‡è®°æ ¼å¼: [CHART:TICKER:TYPE]
        """
        try:
            # é—®å€™/æ¾„æ¸…ç­‰éè¡Œæƒ…æ„å›¾ä¸è‡ªåŠ¨åŠ å›¾è¡¨
            intent = result.get('intent') or metadata.get('intent')
            if intent in {'greeting', 'clarify', 'followup', 'alert', 'economic_events', 'news_sentiment', 'market_sentiment'}:
                return result

            from backend.api.chart_detector import ChartTypeDetector

            # ä»…ä½¿ç”¨æ˜¾å¼è§£æåˆ°çš„ tickerï¼Œé¿å…æ²¿ç”¨æ—§çš„ current_focus è¯¯åŠ å›¾è¡¨
            ticker = None
            if metadata.get('tickers'):
                ticker = metadata['tickers'][0]

            if not ticker:
                return result

            # æ£€æµ‹å›¾è¡¨ç±»å‹
            query_lower = resolved_query.lower()

            # ç‰¹æ®Šå¤„ç†ï¼šæŒä»“æƒ…å†µ -> é¥¼å›¾
            if any(kw in query_lower for kw in ['æŒä»“', 'æˆåˆ†', 'ç»„æˆ', 'å æ¯”', 'åˆ†å¸ƒ', 'holdings', 'constituent', 'composition']):
                chart_type = 'pie'
            # å¯¹æ¯”æŸ¥è¯¢ -> æŸ±çŠ¶å›¾
            elif any(kw in query_lower for kw in ['å¯¹æ¯”', 'æ¯”è¾ƒ', 'vs', 'åŒºåˆ«', 'compare', 'difference']):
                chart_type = 'bar'
            # ä»·æ ¼/èµ°åŠ¿æŸ¥è¯¢ -> Kçº¿å›¾æˆ–æŠ˜çº¿å›¾
            elif any(kw in query_lower for kw in ['ä»·æ ¼', 'èµ°åŠ¿', 'è¶‹åŠ¿', 'kçº¿', 'æ¶¨è·Œ', 'è¡¨ç°', 'price', 'trend', 'chart']):
                chart_type = 'candlestick' if 'kçº¿' in query_lower or 'candlestick' in query_lower else 'line'
            # ä½¿ç”¨ ChartTypeDetector æ£€æµ‹
            else:
                chart_detection = ChartTypeDetector.detect_chart_type(resolved_query, ticker)
                chart_type = chart_detection.get('chart_type', 'line')

            # å¦‚æœæ£€æµ‹åˆ°éœ€è¦å›¾è¡¨ï¼Œæ·»åŠ æ ‡è®°
            if chart_type and ChartTypeDetector.should_generate_chart(resolved_query):
                chart_marker = f"[CHART:{ticker}:{chart_type}]"
                # åœ¨å“åº”æœ«å°¾æ·»åŠ å›¾è¡¨æ ‡è®°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
                if chart_marker not in result.get('response', ''):
                    result['response'] = result.get('response', '') + f'''

{chart_marker}'''
                    logger.info(f"[Agent] è‡ªåŠ¨æ·»åŠ å›¾è¡¨æ ‡è®°: {chart_marker}")

        except Exception as e:
            logger.info(f"[Agent] æ·»åŠ å›¾è¡¨æ ‡è®°å¤±è´¥: {e}")

        return result

    def get_context_summary(self) -> str:
        """è·å–å½“å‰ä¸Šä¸‹æ–‡æ‘˜è¦"""
        return self.context.get_summary()

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            'context_turns': len(self.context.history),
            'current_focus': self.context.current_focus,
            'session_duration_seconds': (datetime.now() - self.stats['session_start']).total_seconds(),
        }

    def reset(self) -> None:
        """é‡ç½®å¯¹è¯çŠ¶æ€"""
        self.context.clear()
        self.stats = {
            'total_queries': 0,
            'intents': {
                'chat': 0,
                'report': 0,
                'alert': 0,
                'economic_events': 0,
                'news_sentiment': 0,
                'followup': 0,
                'clarify': 0,
                'greeting': 0,
            },
            'errors': 0,
            'session_start': datetime.now(),
        }

    def set_focus(self, ticker: str, company_name: str = None) -> None:
        """æ‰‹åŠ¨è®¾ç½®å½“å‰ç„¦ç‚¹"""
        self.context.current_focus = ticker
        if company_name:
            self.context.current_focus_name = company_name

    def describe_report_agent(self) -> Dict[str, Any]:
        """
        è¯Šæ–­æŠ¥å‘Š Agentï¼ˆLangGraphï¼‰çŠ¶æ€ï¼Œä¾›å‰ç«¯æµæ°´çº¿é¢æ¿/å¥åº·æ£€æŸ¥ä½¿ç”¨ã€‚
        ä¸è§¦å‘å¤–éƒ¨ LLM è°ƒç”¨ã€‚
        """
        info: Dict[str, Any] = {"available": False}
        if not getattr(self, "report_agent", None):
            info["error"] = "report_agent_not_initialized"
            return info
        info["available"] = True
        # ä¼˜å…ˆä½¿ç”¨ self_checkï¼Œå…¶æ¬¡ get_agent_info
        if hasattr(self.report_agent, "self_check"):
            try:
                info["self_check"] = self.report_agent.self_check()
            except Exception as exc:  # pragma: no cover (è¯Šæ–­è·¯å¾„)
                info["self_check_error"] = str(exc)
        if hasattr(self.report_agent, "get_agent_info"):
            try:
                info["agent_info"] = self.report_agent.get_agent_info()
            except Exception as exc:  # pragma: no cover
                info["agent_info_error"] = str(exc)
        if hasattr(self.report_agent, "get_recent_trace"):
            try:
                info["recent_trace"] = self.report_agent.get_recent_trace(10)
            except Exception as exc:  # pragma: no cover
                info["recent_trace_error"] = str(exc)
        return info


# === ä¾¿æ·å‡½æ•° ===

def create_agent(
    use_llm: bool = False,
    use_orchestrator: bool = True,
    use_report_agent: bool = False
) -> ConversationAgent:
    """
    åˆ›å»º ConversationAgent å®ä¾‹

    Args:
        use_llm: æ˜¯å¦ä½¿ç”¨ LLM å¢å¼º
        use_orchestrator: æ˜¯å¦ä½¿ç”¨ ToolOrchestrator
        use_report_agent: æ˜¯å¦ä½¿ç”¨ç°æœ‰çš„ LangChain Agent

    Returns:
        ConversationAgent å®ä¾‹
    """
    llm = None
    orchestrator = None
    report_agent = None
    supervisor = None

    # åˆå§‹åŒ– LLMï¼ˆä½¿ç”¨ç»Ÿä¸€çš„å·¥å‚å‡½æ•°ï¼Œå†å²é—ç•™ä»£ç å·²æå–åˆ° llm_config.pyï¼‰
    if use_llm:
        try:
            from backend.llm_config import create_llm
            llm = create_llm(
                provider="gemini_proxy",
                temperature=0.3,
                max_tokens=4000,
                request_timeout=300,
            )
            logger.info("[ConversationAgent] LLM åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.info(f"[ConversationAgent] åˆå§‹åŒ– LLM å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            llm = None

    # åˆå§‹åŒ– Orchestrator
    if use_orchestrator:
        try:
            from backend.orchestration.orchestrator import ToolOrchestrator
            from backend.orchestration.tools_bridge import register_all_financial_tools

            orchestrator = ToolOrchestrator()
            register_all_financial_tools(orchestrator)
        except Exception as e:
            logger.info(f"[ConversationAgent] åˆå§‹åŒ– Orchestrator å¤±è´¥: {e}")

    # åˆå§‹åŒ– Report Agent
    if use_report_agent:
        try:
            from backend.langchain_agent import create_financial_agent
            report_agent = create_financial_agent()
            logger.info("[ConversationAgent] Report Agent åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.info(f"[ConversationAgent] åˆå§‹åŒ– Report Agent å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # åˆå§‹åŒ– Agent Supervisor (New in Phase 1)
    if llm and orchestrator:
        try:
            from backend.orchestration.supervisor_agent import SupervisorAgent
            # éœ€è¦ä¼ å…¥ cache å’Œ circuit_breaker
            supervisor = SupervisorAgent(
                llm=llm,
                tools_module=orchestrator.tools_module, # Bridge æ³¨å†Œåçš„ module
                cache=orchestrator.cache,
                circuit_breaker=orchestrator.circuit_breaker
            )
            logger.info("[ConversationAgent] Agent Supervisor åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.info(f"[ConversationAgent] åˆå§‹åŒ– Supervisor å¤±è´¥: {e}")

    return ConversationAgent(
        llm=llm,
        orchestrator=orchestrator,
        report_agent=report_agent,
        supervisor=supervisor
    )
