# -*- coding: utf-8 -*-
"""
SupervisorAgent - Supervisor Pattern
Mature multi-Agent architecture: Intent Classification â†’ Supervisor Coordination â†’ Worker Agents â†’ Forum Synthesis
"""

import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass

from backend.orchestration.intent_classifier import IntentClassifier, Intent, ClassificationResult
from backend.orchestration.forum import ForumHost
from backend.agents.base_agent import AgentOutput


@dataclass
class SupervisorResult:
    """Supervisor execution result"""
    success: bool
    intent: Intent
    response: str
    agent_outputs: Dict[str, Any] = None
    forum_output: Any = None
    classification: ClassificationResult = None
    errors: List[str] = None


# Greeting response templates (Chinese output for users)
GREETING_RESPONSES = {
    "default": "æ‚¨å¥½ï¼æˆ‘æ˜¯ FinSight AI é‡‘èåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼ã€åˆ†ææ–°é—»ã€ç”ŸæˆæŠ•èµ„æŠ¥å‘Šç­‰ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ",
    "help": "æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\nâ€¢ æŸ¥è¯¢è‚¡ç¥¨å®æ—¶ä»·æ ¼ï¼ˆå¦‚ï¼šAAPL ä»·æ ¼ï¼‰\nâ€¢ è·å–å…¬å¸æ–°é—»ï¼ˆå¦‚ï¼šç‰¹æ–¯æ‹‰æ–°é—»ï¼‰\nâ€¢ åˆ†æå¸‚åœºæƒ…ç»ª\nâ€¢ ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Šï¼ˆå¦‚ï¼šè¯¦ç»†åˆ†æè‹¹æœï¼‰\nâ€¢ å¯¹æ¯”å¤šä¸ªè‚¡ç¥¨ï¼ˆå¦‚ï¼šå¯¹æ¯” AAPL å’Œ MSFTï¼‰",
}


class SupervisorAgent:
    """
    Supervisor Agent - Industry-standard multi-Agent architecture

    Flow:
    1. IntentClassifier classifies intent (rule-first, LLM fallback)
    2. Route based on intent
    3. Call corresponding Worker Agent(s)
    4. Forum synthesizes results (complex queries)
    """

    def __init__(self, llm, tools_module, cache, circuit_breaker=None):
        self.llm = llm
        self.tools_module = tools_module

        # é˜²æŠ¤ï¼šç¡®ä¿ cache å’Œ circuit_breaker ä¸ä¸º None
        if cache is None:
            from backend.orchestration.cache import DataCache
            cache = DataCache()
        self.cache = cache

        if circuit_breaker is None:
            from backend.services.circuit_breaker import CircuitBreaker
            circuit_breaker = CircuitBreaker()
        self.circuit_breaker = circuit_breaker

        # Intent classifier
        self.classifier = IntentClassifier(llm)

        # Forum host
        self.forum = ForumHost(llm)

        # Worker Agents (lazy initialization)
        self._agents = None

    @property
    def agents(self):
        """Lazy initialize Agents"""
        if self._agents is None:
            from backend.agents.price_agent import PriceAgent
            from backend.agents.news_agent import NewsAgent
            from backend.agents.deep_search_agent import DeepSearchAgent
            from backend.agents.macro_agent import MacroAgent
            from backend.agents.technical_agent import TechnicalAgent
            from backend.agents.fundamental_agent import FundamentalAgent

            self._agents = {
                "price": PriceAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "news": NewsAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "deep_search": DeepSearchAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "macro": MacroAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "technical": TechnicalAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "fundamental": FundamentalAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
            }
        return self._agents

    async def process(self, query: str, tickers: List[str] = None, user_profile: Any = None, context_summary: str = None, context_ticker: str = None) -> SupervisorResult:
        """
        Process user query

        Args:
            query: User query
            tickers: Detected stock tickers
            user_profile: User profile
            context_summary: å¯¹è¯ä¸Šä¸‹æ–‡æ‘˜è¦
            context_ticker: ä¸Šä¸‹æ–‡ä¸­æå–çš„è‚¡ç¥¨ä»£ç 

        Returns:
            SupervisorResult
        """
        # å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ ticker ä½†å½“å‰æ²¡æœ‰ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡çš„
        if context_ticker and not tickers:
            tickers = [context_ticker]

        # 1. Intent classification (å¸¦ä¸Šä¸‹æ–‡)
        classification = self.classifier.classify(query, tickers, context_summary=context_summary)
        print(f"[Supervisor] Intent: {classification.intent.value} (method: {classification.method}, confidence: {classification.confidence})")

        # 2. Route based on intent
        intent = classification.intent

        # Simple intents - rule-based direct handling (cost-free)
        if intent == Intent.GREETING:
            return self._handle_greeting(query, classification)

        if intent == Intent.OFF_TOPIC:
            return SupervisorResult(
                success=True,
                intent=intent,
                response="æŠ±æ­‰ï¼Œæˆ‘æ˜¯é‡‘èåŠ©æ‰‹ï¼Œåªèƒ½å›ç­”é‡‘èç›¸å…³çš„é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆè‚¡ç¥¨æˆ–å¸‚åœºæ–¹é¢çš„é—®é¢˜å—ï¼Ÿ",
                classification=classification
            )

        if intent == Intent.CLARIFY:
            return SupervisorResult(
                success=True,
                intent=intent,
                response="è¯·é—®æ‚¨æƒ³äº†è§£å“ªåªè‚¡ç¥¨ï¼Ÿå¯ä»¥å‘Šè¯‰æˆ‘è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°ã€‚",
                classification=classification
            )

        # Intents requiring Agent calls
        tickers_list = classification.tickers if isinstance(classification.tickers, list) else list(classification.tickers) if classification.tickers else []
        ticker = tickers_list[0] if tickers_list else None

        # Lightweight intents - single tool/agent
        # æ‰€æœ‰ handler éƒ½ä¼ é€’ context_summaryï¼Œè®©å®ƒä»¬å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡ä¼˜åŒ–å“åº”
        if intent == Intent.PRICE:
            return await self._handle_price(query, ticker, classification, context_summary)

        # NEWS æ„å›¾ï¼šå­æ„å›¾åˆ†ç±» - åŒºåˆ†"æŸ¥è¯¢æ–°é—»"å’Œ"åˆ†ææ–°é—»"
        if intent == Intent.NEWS:
            news_subintent = self._classify_news_subintent(query)
            if news_subintent == "analyze":
                # åˆ†æç±»è¯·æ±‚ï¼šèµ° NewsAgent + Forum æ·±åº¦åˆ†æ
                return await self._handle_news_analysis(query, ticker, classification, context_summary)
            else:
                # æŸ¥è¯¢ç±»è¯·æ±‚ï¼šè¿”å›åŸå§‹æ–°é—»åˆ—è¡¨ï¼ˆå¸¦é“¾æ¥ï¼‰
                return await self._handle_news(query, ticker, classification, context_summary)

        if intent == Intent.SENTIMENT:
            return await self._handle_sentiment(query, ticker, classification, context_summary)

        if intent == Intent.TECHNICAL:
            return await self._handle_single_agent("technical", query, ticker, classification, context_summary)

        if intent == Intent.FUNDAMENTAL:
            return await self._handle_single_agent("fundamental", query, ticker, classification, context_summary)

        if intent == Intent.MACRO:
            return await self._handle_single_agent("macro", query, ticker, classification, context_summary)

        # Complex intents - multi-Agent collaboration
        if intent == Intent.REPORT:
            return await self._handle_report(query, ticker, user_profile, classification, context_summary)

        if intent == Intent.COMPARISON:
            return await self._handle_comparison(query, tickers_list, classification, context_summary)

        # Fallback - search
        return await self._handle_search(query, ticker, classification, context_summary)

    def _handle_greeting(self, query: str, classification: ClassificationResult) -> SupervisorResult:
        """Handle greeting - rule-based direct response, free"""
        query_lower = query.lower()
        if any(kw in query_lower for kw in ['å¸®åŠ©', 'help', 'èƒ½åšä»€ä¹ˆ', 'ä½ æ˜¯è°']):
            response = GREETING_RESPONSES["help"]
        else:
            response = GREETING_RESPONSES["default"]

        return SupervisorResult(
            success=True,
            intent=Intent.GREETING,
            response=response,
            classification=classification
        )

    async def _handle_price(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle price query - lightweight tool, with context awareness"""
        if not ticker:
            return SupervisorResult(
                success=False,
                intent=Intent.PRICE,
                response="è¯·æä¾›è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šAAPL ä»·æ ¼",
                classification=classification
            )

        try:
            # Direct tool call, no Agent
            price_data = self.tools_module.get_stock_price(ticker)

            if isinstance(price_data, dict) and price_data.get("error"):
                return SupervisorResult(
                    success=False,
                    intent=Intent.PRICE,
                    response=f"è·å– {ticker} ä»·æ ¼å¤±è´¥ï¼š{price_data.get('error')}",
                    classification=classification
                )

            # Format response
            if isinstance(price_data, dict):
                price = price_data.get("price", "N/A")
                change = price_data.get("change_percent", 0)
                change_str = f"+{change:.2f}%" if change >= 0 else f"{change:.2f}%"
                base_response = f"**{ticker}** å½“å‰ä»·æ ¼: ${price} ({change_str})"
            else:
                base_response = f"**{ticker}** ä»·æ ¼æ•°æ®: {price_data}"

            # If there's context, enhance response with LLM
            if context_summary:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""ç”¨æˆ·è¯¢é—®è‚¡ç¥¨ä»·æ ¼ï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡ç»™å‡ºç®€æ´å›å¤ã€‚

ã€ä»·æ ¼æ•°æ®ã€‘
{base_response}

ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

è¯·ç”¨1-2å¥è¯å›å¤ï¼Œç»“åˆä¸Šä¸‹æ–‡ï¼ˆå¦‚ä¹‹å‰è®¨è®ºçš„è¯é¢˜ï¼‰ç»™å‡ºç›¸å…³è§£è¯»ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸ç›¸å…³ï¼Œå°±ç›´æ¥è¿”å›ä»·æ ¼ä¿¡æ¯ã€‚"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    return SupervisorResult(
                        success=True,
                        intent=Intent.PRICE,
                        response=response.content if hasattr(response, 'content') else str(response),
                        classification=classification
                    )
                except Exception as e:
                    print(f"[Supervisor] Price context enhancement failed: {e}")

            return SupervisorResult(
                success=True,
                intent=Intent.PRICE,
                response=base_response,
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.PRICE,
                response=f"è·å–ä»·æ ¼æ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    def _classify_news_subintent(self, query: str) -> str:
        """
        NEWS æ„å›¾çš„å­åˆ†ç±»ï¼šåŒºåˆ†"æŸ¥è¯¢æ–°é—»"å’Œ"åˆ†ææ–°é—»"

        ä¸šç•Œæœ€ä½³å®è·µï¼šSub-intent Classification
        - åˆ†æç±»ï¼šç”¨æˆ·æƒ³è¦å¯¹æ–°é—»è¿›è¡Œè§£è¯»ã€åˆ†æå½±å“
        - æŸ¥è¯¢ç±»ï¼šç”¨æˆ·åªæ˜¯æƒ³çœ‹æœ€æ–°æ–°é—»åˆ—è¡¨

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            str: "analyze" æˆ– "fetch"
        """
        query_lower = query.lower()

        # åˆ†æç±»å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
        analyze_keywords = [
            # ä¸­æ–‡åˆ†æè¯
            "åˆ†æ", "å½±å“", "è§£è¯»", "æ„å‘³", "è¯„ä¼°", "çœ‹æ³•", "è§‚ç‚¹",
            "èµ°åŠ¿", "é¢„æµ‹", "è§£æ", "æ·±åº¦", "è¯¦ç»†", "æ€ä¹ˆçœ‹", "ä¼šæ€æ ·",
            "å¸¦æ¥", "å¯¼è‡´", "é€ æˆ", "å¼•å‘", "è¯´æ˜", "åæ˜ ", "è¡¨æ˜",
            "åˆ©å¥½", "åˆ©ç©º", "æœºä¼š", "é£é™©", "è¶‹åŠ¿", "å‰æ™¯", "å±•æœ›",
            # è‹±æ–‡åˆ†æè¯
            "analyze", "analysis", "impact", "effect", "implication",
            "interpret", "predict", "forecast", "outlook", "assess"
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†æç±»å…³é”®è¯
        for keyword in analyze_keywords:
            if keyword in query_lower:
                return "analyze"

        # é»˜è®¤è¿”å›æŸ¥è¯¢ç±»
        return "fetch"

    async def _handle_news(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle news query - æ˜¾ç¤ºåŸå§‹æ–°é—»ï¼Œæœ‰ä¸Šä¸‹æ–‡æ—¶è¡¥å……åˆ†æ"""
        try:
            if ticker:
                news_data = self.tools_module.get_company_news(ticker)
            else:
                news_data = self.tools_module.search(query)

            if isinstance(news_data, dict) and news_data.get("error"):
                return SupervisorResult(
                    success=False,
                    intent=Intent.NEWS,
                    response=f"è·å–æ–°é—»å¤±è´¥ï¼š{news_data.get('error')}",
                    classification=classification
                )

            # æ ¼å¼åŒ–åŸå§‹æ–°é—»æ•°æ®
            base_response = str(news_data) if news_data else "æš‚æ— ç›¸å…³æ–°é—»"

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œåœ¨åŸå§‹æ–°é—»åè¡¥å……ç®€çŸ­åˆ†æ
            if context_summary and news_data:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""åŸºäºä»¥ä¸‹æ–°é—»å’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œç”¨1-2å¥è¯è¡¥å……è¯´æ˜æ–°é—»ä¸ä¸Šä¸‹æ–‡è¯é¢˜çš„å…³è”æ€§ã€‚

ã€æ–°é—»æ•°æ®ã€‘
{base_response[:1500]}

ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary}

è¯·åªè¾“å‡ºç®€çŸ­çš„å…³è”åˆ†æï¼ˆä¸è¦é‡å¤æ–°é—»å†…å®¹ï¼‰ï¼Œæ ¼å¼ï¼š\n\nğŸ’¡ **ä¸Šä¸‹æ–‡å…³è”**: [åˆ†æå†…å®¹]"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    context_analysis = response.content if hasattr(response, 'content') else str(response)
                    # å…ˆæ˜¾ç¤ºæ–°é—»ï¼Œå†æ˜¾ç¤ºä¸Šä¸‹æ–‡åˆ†æ
                    base_response = f"{base_response}\n\n{context_analysis}"
                except Exception as e:
                    print(f"[Supervisor] News context enhancement failed: {e}")

            return SupervisorResult(
                success=True,
                intent=Intent.NEWS,
                response=base_response,
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.NEWS,
                response=f"è·å–æ–°é—»æ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_general_news(self, query: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        Handle general news query without ticker (e.g., "ä»Šå¤©æœ‰ä»€ä¹ˆè´¢ç»æ–°é—»")
        ä½¿ç”¨é€šç”¨æœç´¢è·å–æ–°é—»ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡åˆ†æ
        """
        return await self._handle_news(query, None, classification, context_summary)

    async def _handle_news_analysis(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        å¤„ç†æ–°é—»åˆ†æè¯·æ±‚ - æ·±åº¦åˆ†ææ–°é—»å½±å“

        å½“ç”¨æˆ·è¯·æ±‚"åˆ†ææ–°é—»å½±å“"ã€"æ–°é—»è§£è¯»"ç­‰æ—¶è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        ä½¿ç”¨ NewsAgent çš„åæ€å¾ªç¯ + Forum ç»¼åˆåˆ†æã€‚

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            ticker: è‚¡ç¥¨ä»£ç 
            classification: æ„å›¾åˆ†ç±»ç»“æœ
            context_summary: ä¸Šä¸‹æ–‡æ‘˜è¦

        Returns:
            SupervisorResult: åŒ…å«æ·±åº¦æ–°é—»åˆ†æçš„ç»“æœ
        """
        try:
            from langchain_core.messages import HumanMessage

            # 1. å…ˆè·å–åŸå§‹æ–°é—»æ•°æ®
            if ticker:
                news_data = self.tools_module.get_company_news(ticker)
            else:
                news_data = self.tools_module.search(query)

            if isinstance(news_data, dict) and news_data.get("error"):
                return SupervisorResult(
                    success=False,
                    intent=Intent.NEWS,
                    response=f"è·å–æ–°é—»å¤±è´¥ï¼š{news_data.get('error')}",
                    classification=classification
                )

            news_text = str(news_data) if news_data else ""

            if not news_text or news_text == "æš‚æ— ç›¸å…³æ–°é—»":
                return SupervisorResult(
                    success=True,
                    intent=Intent.NEWS,
                    response="æš‚æ— ç›¸å…³æ–°é—»å¯ä¾›åˆ†æ",
                    classification=classification
                )

            # 2. ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦æ–°é—»åˆ†æ
            analysis_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„é‡‘èæ–°é—»åˆ†æå¸ˆï¼Œè¯·å¯¹ä»¥ä¸‹æ–°é—»è¿›è¡Œæ·±åº¦åˆ†æã€‚

## æ–°é—»æ•°æ®
{news_text[:3000]}

## ç”¨æˆ·é—®é¢˜
{query}

{"## å¯¹è¯ä¸Šä¸‹æ–‡" + chr(10) + context_summary if context_summary else ""}

## åˆ†æè¦æ±‚
è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œä¸“ä¸šåˆ†æï¼š

### ğŸ“° æ–°é—»æ‘˜è¦
ç®€è¦æ€»ç»“ä¸»è¦æ–°é—»äº‹ä»¶ï¼ˆ2-3å¥è¯ï¼‰

### ğŸ“Š å¸‚åœºå½±å“åˆ†æ
- **çŸ­æœŸå½±å“**ï¼šå¯¹è‚¡ä»·/å¸‚åœºçš„å³æ—¶å½±å“é¢„åˆ¤
- **ä¸­é•¿æœŸå½±å“**ï¼šæ½œåœ¨çš„æŒç»­æ€§å½±å“

### ğŸ¯ æŠ•èµ„å¯ç¤º
- è¿™äº›æ–°é—»å¯¹æŠ•èµ„è€…æ„å‘³ç€ä»€ä¹ˆï¼Ÿ
- éœ€è¦å…³æ³¨çš„åç»­å‘å±•

### âš ï¸ é£é™©æç¤º
- æ–°é—»ä¸­éšå«çš„é£é™©å› ç´ 
- éœ€è¦è­¦æƒ•çš„ä¸ç¡®å®šæ€§

è¯·æä¾›ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ´å¯ŸåŠ›çš„åˆ†æï¼Œé¿å…ç©ºæ³›çš„è¡¨è¿°ã€‚"""

            response = await self.llm.ainvoke([HumanMessage(content=analysis_prompt)])
            analysis_content = response.content if hasattr(response, 'content') else str(response)

            # 3. ç»„åˆåŸå§‹æ–°é—» + åˆ†æç»“æœ
            final_response = f"""## ğŸ“° ç›¸å…³æ–°é—»

{news_text}

---

## ğŸ” æ·±åº¦åˆ†æ

{analysis_content}"""

            return SupervisorResult(
                success=True,
                intent=Intent.NEWS,
                response=final_response,
                classification=classification
            )

        except Exception as e:
            print(f"[Supervisor] News analysis failed: {e}")
            # Fallback: è¿”å›åŸå§‹æ–°é—»
            return await self._handle_news(query, ticker, classification, context_summary)

    async def _handle_sentiment(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        Handle market sentiment query
        å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼ˆä¹‹å‰è®¨è®ºçš„è‚¡ç¥¨/æ–°é—»ï¼‰ï¼Œç»“åˆä¸Šä¸‹æ–‡æ¥åˆ†ææƒ…ç»ª
        """
        try:
            # 1. è·å–åŸºç¡€å¸‚åœºæƒ…ç»ªæ•°æ®
            sentiment_data = self.tools_module.get_market_sentiment()
            base_sentiment = str(sentiment_data) if sentiment_data else "æš‚æ— å¸‚åœºæƒ…ç»ªæ•°æ®"

            # 2. å¦‚æœæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œç›´æ¥è¿”å›åŸºç¡€æƒ…ç»ª
            if not context_summary and not ticker:
                return SupervisorResult(
                    success=True,
                    intent=Intent.SENTIMENT,
                    response=base_sentiment,
                    classification=classification
                )

            # 3. å¦‚æœæœ‰ä¸Šä¸‹æ–‡æˆ– tickerï¼Œä½¿ç”¨ LLM ç»“åˆåˆ†æ
            # è·å–ç›¸å…³æ–°é—»ï¼ˆå¦‚æœæœ‰ tickerï¼‰
            news_content = ""
            if ticker:
                try:
                    news_agent = self.agents.get("news")
                    if news_agent:
                        news_output = await news_agent.research(f"{ticker} news sentiment", ticker)
                        if news_output and news_output.summary:
                            news_content = f"\n\nã€{ticker} ç›¸å…³æ–°é—»ã€‘\n{news_output.summary}"
                except Exception as e:
                    print(f"[Supervisor] News fetch for sentiment failed: {e}")

            # 4. æ„å»º Prompt è®© LLM ç»¼åˆåˆ†æ
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯åˆ†æå¸‚åœºæƒ…ç»ªï¼š

ã€åŸºç¡€å¸‚åœºæƒ…ç»ªã€‘
{base_sentiment}
{news_content}

ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary or 'æ— '}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

è¯·ç»¼åˆä»¥ä¸Šä¿¡æ¯ï¼Œç”¨2-3å¥è¯åˆ†æå½“å‰å¸‚åœºæƒ…ç»ªï¼Œç‰¹åˆ«å…³æ³¨ä¸Šä¸‹æ–‡ä¸­æåˆ°çš„è‚¡ç¥¨æˆ–è¯é¢˜ã€‚
å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰å…·ä½“è‚¡ç¥¨ï¼ˆå¦‚ TSLAã€EV ç­‰ï¼‰ï¼Œè¯·é’ˆå¯¹è¯¥è‚¡ç¥¨/è¡Œä¸šè¿›è¡Œæƒ…ç»ªåˆ†æã€‚"""

            from langchain_core.messages import HumanMessage
            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            analysis = response.content if hasattr(response, 'content') else str(response)

            return SupervisorResult(
                success=True,
                intent=Intent.SENTIMENT,
                response=analysis,
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.SENTIMENT,
                response=f"è·å–å¸‚åœºæƒ…ç»ªæ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_single_agent(self, agent_name: str, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle single Agent query with context awareness"""
        if not ticker:
            return SupervisorResult(
                success=False,
                intent=classification.intent,
                response=f"è¯·æä¾›è‚¡ç¥¨ä»£ç è¿›è¡Œ{agent_name}åˆ†æ",
                classification=classification
            )

        try:
            agent = self.agents.get(agent_name)
            if not agent:
                return SupervisorResult(
                    success=False,
                    intent=classification.intent,
                    response=f"Agent {agent_name} ä¸å¯ç”¨",
                    classification=classification
                )

            # Enhance query with context if available
            enhanced_query = query
            if context_summary:
                enhanced_query = f"{query}\n\nã€å‚è€ƒä¸Šä¸‹æ–‡ã€‘\n{context_summary}"

            output = await agent.research(enhanced_query, ticker)
            base_response = output.summary if output else "åˆ†æå®Œæˆï¼Œä½†æ— ç»“æœ"

            # If context exists and agent returns result, optionally enhance with LLM
            if context_summary and output and output.summary:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""ç”¨æˆ·è¯¢é—®{agent_name}åˆ†æï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡ä¼˜åŒ–å›å¤ã€‚

ã€åˆ†æç»“æœã€‘
{output.summary[:1500]}

ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

è¯·åŸºäºåˆ†æç»“æœå›å¤ï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ç›¸å…³è¯é¢˜ï¼Œå°†å…¶èå…¥å›ç­”ã€‚ä¿æŒä¸“ä¸šç®€æ´ã€‚"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    base_response = response.content if hasattr(response, 'content') else str(response)
                except Exception as e:
                    print(f"[Supervisor] {agent_name} context enhancement failed: {e}")

            return SupervisorResult(
                success=True,
                intent=classification.intent,
                response=base_response,
                agent_outputs={agent_name: output},
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=classification.intent,
                response=f"{agent_name} åˆ†æå‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_report(self, query: str, ticker: str, user_profile: Any, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle deep report - multi-Agent collaboration with context awareness"""
        if not ticker:
            return SupervisorResult(
                success=False,
                intent=Intent.REPORT,
                response="è¯·æä¾›è‚¡ç¥¨ä»£ç è¿›è¡Œæ·±åº¦åˆ†æï¼Œä¾‹å¦‚ï¼šè¯¦ç»†åˆ†æ AAPL",
                classification=classification
            )

        try:
            # æ™ºèƒ½åˆ¤æ–­ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­çš„ ticker ä¸å½“å‰ä¸åŒï¼Œå¿½ç•¥ä¸Šä¸‹æ–‡
            relevant_context = None
            if context_summary:
                import re
                # ä»ä¸Šä¸‹æ–‡ä¸­æå–å¯èƒ½çš„ ticker
                context_tickers = re.findall(r'\b([A-Z]{2,5})\b', context_summary)
                stopwords = {'A', 'I', 'AM', 'PM', 'US', 'UK', 'AI', 'CEO', 'IPO', 'ETF', 'VS', 'PE', 'EPS', 'GDP', 'CPI', 'API', 'OK', 'THE', 'FOR', 'AND', 'NOT'}
                context_tickers = [t for t in context_tickers if t not in stopwords]

                # åˆ¤æ–­ä¸Šä¸‹æ–‡æ˜¯å¦ä¸å½“å‰ ticker ç›¸å…³
                if context_tickers and ticker.upper() not in [t.upper() for t in context_tickers]:
                    # ä¸Šä¸‹æ–‡ä¸­æœ‰å…¶ä»– tickerï¼Œä½†æ²¡æœ‰å½“å‰ ticker - å¿½ç•¥ä¸Šä¸‹æ–‡
                    print(f"[Supervisor] å¿½ç•¥ä¸ç›¸å…³ä¸Šä¸‹æ–‡ (context tickers: {context_tickers}, current: {ticker})")
                    relevant_context = None
                else:
                    relevant_context = context_summary

            # Enhance query with context only if relevant
            enhanced_query = query
            if relevant_context:
                enhanced_query = f"{query}\n\nã€å‚è€ƒä¸Šä¸‹æ–‡ã€‘\n{relevant_context}"

            # Parallel call multiple Agents
            agent_names = ["price", "news", "technical", "fundamental"]
            tasks = [self.agents[name].research(enhanced_query, ticker) for name in agent_names]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # Collect results
            valid_outputs = {}
            errors = []
            for name, result in zip(agent_names, results):
                if isinstance(result, Exception):
                    errors.append(f"{name}: {result}")
                    print(f"[Supervisor] Agent {name} failed: {result}")
                else:
                    valid_outputs[name] = result

            # Forum synthesis - pass relevant_context for better synthesis
            forum_result = await self.forum.synthesize(
                valid_outputs,
                user_profile=user_profile,
                context_summary=relevant_context  # åªä¼ ç›¸å…³ä¸Šä¸‹æ–‡
            )

            return SupervisorResult(
                success=True,
                intent=Intent.REPORT,
                response=forum_result.consensus if forum_result else "æŠ¥å‘Šç”Ÿæˆå®Œæˆ",
                agent_outputs=valid_outputs,
                forum_output=forum_result,
                classification=classification,
                errors=errors if errors else None
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.REPORT,
                response=f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_comparison(self, query: str, tickers: List[str], classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle comparison analysis with context awareness"""
        if len(tickers) < 2:
            return SupervisorResult(
                success=False,
                intent=Intent.COMPARISON,
                response="è¯·æä¾›è‡³å°‘ä¸¤ä¸ªè‚¡ç¥¨ä»£ç è¿›è¡Œå¯¹æ¯”ï¼Œä¾‹å¦‚ï¼šå¯¹æ¯” AAPL å’Œ MSFT",
                classification=classification
            )

        try:
            comparison_data = self.tools_module.get_performance_comparison(tickers)
            base_response = str(comparison_data) if comparison_data else "å¯¹æ¯”å®Œæˆï¼Œä½†æ— æ•°æ®"

            # If context exists, enhance with LLM
            if context_summary and comparison_data:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""ç”¨æˆ·è¿›è¡Œè‚¡ç¥¨å¯¹æ¯”åˆ†æï¼Œè¯·ç»“åˆä¸Šä¸‹æ–‡ç»™å‡ºè§£è¯»ã€‚

ã€å¯¹æ¯”æ•°æ®ã€‘
{base_response[:2000]}

ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary}

ã€ç”¨æˆ·é—®é¢˜ã€‘
{query}

è¯·ç”¨2-3å¥è¯æ€»ç»“å¯¹æ¯”ç»“æœï¼Œå¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ç›¸å…³è¯é¢˜ï¼ˆå¦‚æŠ•èµ„åå¥½ã€ä¹‹å‰è®¨è®ºçš„è‚¡ç¥¨ï¼‰ï¼Œå°†å…¶èå…¥åˆ†æã€‚"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    return SupervisorResult(
                        success=True,
                        intent=Intent.COMPARISON,
                        response=response.content if hasattr(response, 'content') else str(response),
                        classification=classification
                    )
                except Exception as e:
                    print(f"[Supervisor] Comparison context enhancement failed: {e}")

            return SupervisorResult(
                success=True,
                intent=Intent.COMPARISON,
                response=base_response,
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.COMPARISON,
                response=f"å¯¹æ¯”åˆ†æå‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_search(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Fallback search with context awareness"""
        try:
            search_result = self.tools_module.search(query)

            # Use LLM to synthesize search results with context
            from langchain_core.messages import HumanMessage

            context_section = ""
            if context_summary:
                context_section = f"""
ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€‘
{context_summary}

è¯·ç»“åˆä¸Šä¸‹æ–‡ä¸­çš„è¯é¢˜å›ç­”é—®é¢˜ã€‚"""

            prompt = f"""ç”¨æˆ·é—®é¢˜: {query}

æœç´¢ç»“æœ:
{search_result}
{context_section}

è¯·åŸºäºæœç´¢ç»“æœç»™å‡ºç®€æ´çš„å›ç­”ï¼ˆ2-4å¥è¯ï¼‰ï¼Œä½¿ç”¨ä¸­æ–‡å›å¤ã€‚"""

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])

            return SupervisorResult(
                success=True,
                intent=Intent.SEARCH,
                response=response.content if hasattr(response, 'content') else str(response),
                classification=classification
            )
        except Exception as e:
            return SupervisorResult(
                success=False,
                intent=Intent.SEARCH,
                response=f"æœç´¢å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    def _extract_context_info(self, conversation_context: List[Dict]) -> tuple:
        """
        ä»å¯¹è¯å†å²ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        å¦‚æœå‘ç°é“¾æ¥ï¼Œä¼šå°è¯•æŠ“å–å¹¶æ€»ç»“å†…å®¹

        Returns:
            (context_summary, context_ticker): ä¸Šä¸‹æ–‡æ‘˜è¦å’Œå½“å‰å…³æ³¨çš„è‚¡ç¥¨
        """
        import re

        if not conversation_context:
            return None, None

        # æå–æœ€è¿‘å¯¹è¯ä¸­çš„è‚¡ç¥¨ä»£ç 
        ticker_pattern = r'\b([A-Z]{1,5})\b'
        url_pattern = r'https?://[^\s\)\]<>\"\']+'
        found_tickers = []
        found_urls = []

        # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
        context_parts = []
        for msg in conversation_context[-4:]:  # æœ€è¿‘ 4 æ¡æ¶ˆæ¯
            role = msg.get("role", "")
            content = msg.get("content", "")

            if not content:
                continue

            # æå–è‚¡ç¥¨ä»£ç 
            matches = re.findall(ticker_pattern, content)
            # è¿‡æ»¤å¸¸è§éè‚¡ç¥¨è¯
            stopwords = {'A', 'I', 'AM', 'PM', 'US', 'UK', 'AI', 'CEO', 'IPO', 'ETF', 'VS', 'PE', 'EPS', 'GDP', 'CPI', 'API', 'OK', 'CNN', 'HTTP', 'HTTPS', 'WWW', 'COM', 'ORG', 'NET'}
            for m in matches:
                if m not in stopwords and len(m) >= 2:
                    found_tickers.append(m)

            # æå– URL
            urls = re.findall(url_pattern, content)
            found_urls.extend(urls)

            # æˆªæ–­é•¿å†…å®¹
            preview = content[:150] + "..." if len(content) > 150 else content
            context_parts.append(f"{role}: {preview}")

        # å¦‚æœæœ‰ URLï¼Œå°è¯•æŠ“å–å¹¶æ€»ç»“ï¼ˆæœ€å¤š 2 ä¸ªï¼‰
        url_summaries = []
        if found_urls and self.tools_module:
            for url in found_urls[:2]:  # æœ€å¤šå¤„ç† 2 ä¸ªé“¾æ¥
                try:
                    summary = self._fetch_and_summarize_url(url)
                    if summary:
                        url_summaries.append(f"[é“¾æ¥å†…å®¹æ‘˜è¦] {summary}")
                except Exception as e:
                    print(f"[Supervisor] URL fetch failed: {url}, error: {e}")

        # åˆå¹¶ä¸Šä¸‹æ–‡
        if url_summaries:
            context_parts.extend(url_summaries)

        context_summary = "\n".join(context_parts) if context_parts else None
        context_ticker = found_tickers[-1] if found_tickers else None  # å–æœ€è¿‘æåˆ°çš„

        return context_summary, context_ticker

    def _fetch_and_summarize_url(self, url: str) -> str:
        """
        æŠ“å– URL å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        """
        try:
            # ä½¿ç”¨ tools_module ä¸­çš„æœç´¢åŠŸèƒ½æ¥è·å–å†…å®¹
            search_func = getattr(self.tools_module, 'fetch_url_content', None)
            if search_func:
                content = search_func(url)
                if content and len(content) > 100:
                    # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
                    from langchain_core.messages import HumanMessage
                    prompt = f"è¯·ç”¨2-3å¥è¯æ€»ç»“ä»¥ä¸‹å†…å®¹çš„è¦ç‚¹ï¼š\n\n{content[:2000]}"
                    response = self.llm.invoke([HumanMessage(content=prompt)])
                    return response.content[:300] if hasattr(response, 'content') else str(response)[:300]

            # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„ fetch å‡½æ•°ï¼Œå°è¯•ç”¨æœç´¢
            search = getattr(self.tools_module, 'search', None)
            if search:
                result = search(f"site:{url}")
                if result:
                    return str(result)[:300]
        except Exception as e:
            print(f"[Supervisor] URL summarize failed: {e}")

        return None

    async def process_stream(self, query: str, tickers: List[str] = None, user_profile: Any = None, conversation_context: List[Dict] = None):
        """
        Streaming process - real-time progress reporting
        æ ¼å¼ä¸å‰ç«¯ sendMessageStream æœŸæœ›çš„æ ¼å¼å…¼å®¹
        æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            tickers: æ£€æµ‹åˆ°çš„è‚¡ç¥¨ä»£ç 
            user_profile: ç”¨æˆ·é…ç½®
            conversation_context: å¯¹è¯å†å² [{"role": "user/assistant", "content": "..."}]

        Yields:
            JSON formatted events (type: thinking/token/done/error)
        """
        import json
        from datetime import datetime

        thinking_steps = []  # æ”¶é›†æ€è€ƒæ­¥éª¤

        try:
            # 0. å¦‚æœæœ‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå°è¯•ä»ä¸­æå–ç›¸å…³ä¿¡æ¯
            context_summary = None
            context_ticker = None
            if conversation_context:
                context_summary, context_ticker = self._extract_context_info(conversation_context)
                if context_ticker and not tickers:
                    tickers = [context_ticker]

            # 1. å‘é€æ„å›¾åˆ†ç±»å¼€å§‹äº‹ä»¶
            step1 = {
                "stage": "classifying",
                "message": "æ­£åœ¨åˆ†æé—®é¢˜æ„å›¾...",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step1)
            yield json.dumps({"type": "thinking", **step1}, ensure_ascii=False)

            classification = self.classifier.classify(query, tickers, context_summary=context_summary)

            # 2. å‘é€æ„å›¾åˆ†ç±»å®Œæˆäº‹ä»¶
            step2 = {
                "stage": "classified",
                "message": f"æ„å›¾: {classification.intent.value}",
                "result": {
                    "intent": classification.intent.value,
                    "method": classification.method,
                    "confidence": classification.confidence,
                    "reasoning": classification.reasoning
                },
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step2)
            yield json.dumps({"type": "thinking", **step2}, ensure_ascii=False)

            # 3. æ‰§è¡Œå¯¹åº”å¤„ç†å™¨
            step3 = {
                "stage": "processing",
                "message": "æ­£åœ¨å¤„ç†è¯·æ±‚...",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step3)
            yield json.dumps({"type": "thinking", **step3}, ensure_ascii=False)

            # ä¼ é€’ä¸Šä¸‹æ–‡ä¿¡æ¯ç»™ process æ–¹æ³•
            result = await self.process(query, tickers, user_profile, context_summary=context_summary, context_ticker=context_ticker)

            # 4. å‘é€å“åº”å†…å®¹ï¼ˆä½œä¸º token æµå¼è¾“å‡ºï¼‰
            if result.response:
                response_text = result.response
                chunk_size = 20  # æ¯æ¬¡å‘é€çš„å­—ç¬¦æ•°
                for i in range(0, len(response_text), chunk_size):
                    chunk = response_text[i:i + chunk_size]
                    yield json.dumps({
                        "type": "token",
                        "content": chunk
                    }, ensure_ascii=False)

            # 5. å‘é€å®Œæˆäº‹ä»¶
            first_ticker = None
            if classification.tickers:
                if isinstance(classification.tickers, list) and len(classification.tickers) > 0:
                    first_ticker = classification.tickers[0]
                elif isinstance(classification.tickers, dict):
                    first_ticker = list(classification.tickers.values())[0] if classification.tickers else None

            # æ·»åŠ å®Œæˆæ­¥éª¤
            step_done = {
                "stage": "complete",
                "message": "å¤„ç†å®Œæˆ",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step_done)

            # æ„å»º report æ•°æ®ï¼ˆå¦‚æœæ˜¯ REPORT æ„å›¾ä¸”æœ‰ forum_outputï¼‰
            report_data = None
            if result.intent == Intent.REPORT and result.forum_output:
                # ä» forum_output æ„å»º ReportIR æ ¼å¼
                report_data = self._build_report_ir(result, first_ticker, classification)

            yield json.dumps({
                "type": "done",
                "success": result.success,
                "intent": result.intent.value,
                "current_focus": first_ticker,
                "thinking": thinking_steps,  # å‰ç«¯æœŸæœ›åœ¨ done äº‹ä»¶ä¸­æ”¶åˆ° thinking æ•°ç»„
                "errors": result.errors,
                "report": report_data  # Phase 2: æ·±åº¦ç ”æŠ¥æ•°æ®
            }, ensure_ascii=False)

        except Exception as e:
            # æ•è·å¼‚å¸¸ï¼Œå‘é€ error äº‹ä»¶ï¼Œç¡®ä¿å‰ç«¯èƒ½æ”¶åˆ°é”™è¯¯ä¿¡æ¯
            import traceback
            traceback.print_exc()
            yield json.dumps({
                "type": "error",
                "message": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            }, ensure_ascii=False)

    def _build_report_ir(self, result: SupervisorResult, ticker: str, classification: ClassificationResult) -> dict:
        """
        å°† Supervisor ç»“æœè½¬æ¢ä¸º ReportIR æ ¼å¼ï¼ˆå‰ç«¯å¡ç‰‡å±•ç¤ºï¼‰

        é‡è¦ï¼šä¼˜å…ˆä½¿ç”¨ Forum çš„å®Œæ•´ 8 èŠ‚åˆ†æä½œä¸ºä¸»è¦å†…å®¹

        Args:
            result: SupervisorResult
            ticker: è‚¡ç¥¨ä»£ç 
            classification: æ„å›¾åˆ†ç±»ç»“æœ

        Returns:
            dict: ReportIR æ ¼å¼çš„æŠ¥å‘Šæ•°æ®
        """
        from datetime import datetime
        import uuid
        import re

        def safe_str(value):
            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç† Timestamp ç­‰ç‰¹æ®Šç±»å‹"""
            if value is None:
                return None
            if isinstance(value, str):
                return value
            # å¤„ç† pandas Timestamp æˆ–å…¶ä»–æ—¶é—´ç±»å‹
            if hasattr(value, 'isoformat'):
                return value.isoformat()
            if hasattr(value, 'strftime'):
                return value.strftime('%Y-%m-%d %H:%M:%S')
            return str(value)

        forum_output = result.forum_output
        agent_outputs = result.agent_outputs or {}
        errors_list = result.errors or []

        # æ„å»º sections - ä¼˜å…ˆä» Forum å®Œæ•´åˆ†æè§£æ
        sections = []
        section_order = 1

        # å°è¯•è§£æ Forum çš„ 8 èŠ‚åˆ†æ
        forum_sections = self._parse_forum_sections(result.response) if result.response else []

        if forum_sections:
            # ä½¿ç”¨ Forum è§£æå‡ºçš„ç« èŠ‚
            for fs in forum_sections:
                sections.append({
                    "title": fs["title"],
                    "order": section_order,
                    "agent_name": "ForumHost",
                    "confidence": getattr(forum_output, 'confidence', 0.7) if forum_output else 0.7,
                    "data_sources": ["multi-agent-synthesis"],
                    "contents": [{
                        "type": "text",
                        "content": fs["content"]
                    }]
                })
                section_order += 1
        else:
            # Fallback: ä»å„ Agent è¾“å‡ºæ„å»ºç« èŠ‚
            agent_sections = {
                "price": {"title": "ä»·æ ¼åˆ†æ", "agent": "PriceAgent"},
                "news": {"title": "æ–°é—»åˆ†æ", "agent": "NewsAgent"},
                "technical": {"title": "æŠ€æœ¯åˆ†æ", "agent": "TechnicalAgent"},
                "fundamental": {"title": "åŸºæœ¬é¢åˆ†æ", "agent": "FundamentalAgent"},
                "macro": {"title": "å®è§‚åˆ†æ", "agent": "MacroAgent"},
                "deep_search": {"title": "æ·±åº¦æœç´¢", "agent": "DeepSearchAgent"}
            }

            for agent_key, section_info in agent_sections.items():
                section_title = section_info["title"]
                agent_display_name = section_info["agent"]

                # æ£€æŸ¥æ˜¯å¦æœ‰è¿™ä¸ª agent çš„é”™è¯¯
                agent_error = None
                for err in errors_list:
                    if err.startswith(f"{agent_key}:"):
                        agent_error = err.split(":", 1)[1].strip() if ":" in err else err
                        break

                if agent_key in agent_outputs and agent_outputs[agent_key]:
                    agent_output = agent_outputs[agent_key]
                    if hasattr(agent_output, 'summary') and agent_output.summary:
                        confidence = getattr(agent_output, 'confidence', 0.5)
                        data_sources = getattr(agent_output, 'data_sources', [])

                        sections.append({
                            "title": section_title,
                            "order": section_order,
                            "agent_name": agent_display_name,
                            "confidence": confidence,
                            "data_sources": data_sources,
                            "contents": [{
                                "type": "text",
                                "content": safe_str(agent_output.summary)
                            }]
                        })
                        section_order += 1
                elif agent_error:
                    sections.append({
                        "title": section_title,
                        "order": section_order,
                        "agent_name": agent_display_name,
                        "confidence": 0,
                        "error": True,
                        "contents": [{
                            "type": "text",
                            "content": f"âš ï¸ {agent_display_name} æ•°æ®è·å–å¤±è´¥: {agent_error}"
                        }]
                    })
                    section_order += 1

        # æ„å»º agent çŠ¶æ€è¿½è¸ª
        agent_status = {}
        for agent_key in ["price", "news", "technical", "fundamental", "macro", "deep_search"]:
            if agent_key in agent_outputs and agent_outputs[agent_key]:
                agent_output = agent_outputs[agent_key]
                confidence = getattr(agent_output, 'confidence', 0.5)
                agent_status[agent_key] = {"status": "success", "confidence": confidence}
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                agent_error = None
                for err in errors_list:
                    if err.startswith(f"{agent_key}:"):
                        agent_error = err.split(":", 1)[1].strip() if ":" in err else err
                        break
                if agent_error:
                    agent_status[agent_key] = {"status": "error", "error": agent_error}

        # æ„å»º citations
        citations = []
        citation_id = 1
        for agent_name, agent_output in agent_outputs.items():
            if hasattr(agent_output, 'evidence') and agent_output.evidence:
                for evidence in agent_output.evidence[:3]:
                    title = getattr(evidence, 'title', None) or getattr(evidence, 'source', f"{agent_name} æ¥æº")
                    url = getattr(evidence, 'url', '') or "#"
                    text = getattr(evidence, 'text', '')
                    timestamp = getattr(evidence, 'timestamp', None)

                    citations.append({
                        "source_id": f"src_{citation_id}",
                        "title": safe_str(title),
                        "url": safe_str(url),
                        "snippet": safe_str(text)[:200] if text else "",
                        "published_date": safe_str(timestamp)
                    })
                    citation_id += 1

        # ç¡®å®šæƒ…ç»ª
        sentiment = "neutral"
        if forum_output:
            rec = getattr(forum_output, 'recommendation', 'HOLD')
            if rec == "BUY":
                sentiment = "bullish"
            elif rec == "SELL":
                sentiment = "bearish"

        # è·å–é£é™©åˆ—è¡¨
        risks = ["å¸‚åœºæ³¢åŠ¨é£é™©", "æ•°æ®å»¶è¿Ÿé£é™©"]
        if forum_output and hasattr(forum_output, 'risks') and forum_output.risks:
            risks = [safe_str(r) for r in forum_output.risks]

        # ç”Ÿæˆæ‘˜è¦ - ä» Forum åˆ†æä¸­æå–æ‰§è¡Œæ‘˜è¦
        summary = "æŠ¥å‘Šç”Ÿæˆå®Œæˆ"
        if result.response:
            # å°è¯•æå–æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†
            exec_summary = self._extract_executive_summary(result.response)
            if exec_summary:
                summary = exec_summary
            else:
                summary = safe_str(result.response)[:500]

        # æ„å»º ReportIR
        report_ir = {
            "report_id": f"report_{uuid.uuid4().hex[:8]}",
            "ticker": safe_str(ticker) or "UNKNOWN",
            "company_name": safe_str(ticker) or "æœªçŸ¥å…¬å¸",
            "title": f"{ticker} æ·±åº¦åˆ†ææŠ¥å‘Š" if ticker else "æ·±åº¦åˆ†ææŠ¥å‘Š",
            "summary": summary,
            "sentiment": sentiment,
            "confidence_score": float(getattr(forum_output, 'confidence', 0.7)) if forum_output else 0.7,
            "generated_at": datetime.now().isoformat(),
            "sections": sections,
            "citations": citations,
            "risks": risks,
            "recommendation": safe_str(getattr(forum_output, 'recommendation', 'HOLD')) if forum_output else "HOLD",
            "agent_status": agent_status,
            "errors": errors_list if errors_list else None
        }

        return report_ir

    def _parse_forum_sections(self, forum_text: str) -> list:
        """
        è§£æ Forum çš„ 8 èŠ‚åˆ†ææ–‡æœ¬ä¸ºç»“æ„åŒ–ç« èŠ‚

        Args:
            forum_text: Forum ç”Ÿæˆçš„å®Œæ•´åˆ†ææ–‡æœ¬

        Returns:
            list: ç« èŠ‚åˆ—è¡¨ [{"title": "...", "content": "..."}]
        """
        import re

        if not forum_text:
            return []

        sections = []

        # åŒ¹é…æ ‡é¢˜æ¨¡å¼: ### 1. ğŸ“Š æ‰§è¡Œæ‘˜è¦ æˆ– ### 1. æ‰§è¡Œæ‘˜è¦
        section_pattern = r'###\s*(\d+)\.\s*([^\n]+)\n([\s\S]*?)(?=###\s*\d+\.|$)'
        matches = re.findall(section_pattern, forum_text)

        for match in matches:
            order, title, content = match
            # æ¸…ç†æ ‡é¢˜ä¸­çš„ emoji å’Œå¤šä½™ç©ºæ ¼
            clean_title = re.sub(r'[ğŸ“ŠğŸ“ˆğŸ’°ğŸŒâš ï¸ğŸ¯ğŸ“ğŸ“…]\s*', '', title).strip()
            # æ¸…ç†å†…å®¹
            clean_content = content.strip()

            if clean_title and clean_content:
                sections.append({
                    "title": clean_title,
                    "content": clean_content
                })

        return sections

    def _extract_executive_summary(self, forum_text: str) -> str:
        """
        ä» Forum åˆ†æä¸­æå–æ‰§è¡Œæ‘˜è¦

        Args:
            forum_text: Forum ç”Ÿæˆçš„å®Œæ•´åˆ†ææ–‡æœ¬

        Returns:
            str: æ‰§è¡Œæ‘˜è¦æ–‡æœ¬ï¼ˆæœ€å¤š 500 å­—ç¬¦ï¼‰
        """
        import re

        if not forum_text:
            return ""

        # å°è¯•åŒ¹é…æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†
        patterns = [
            r'###\s*1\.\s*[ğŸ“Š]?\s*æ‰§è¡Œæ‘˜è¦[^\n]*\n([\s\S]*?)(?=###\s*2\.|$)',
            r'###\s*1\.\s*[ğŸ“Š]?\s*EXECUTIVE SUMMARY[^\n]*\n([\s\S]*?)(?=###\s*2\.|$)',
            r'\*\*æŠ•èµ„è¯„çº§\*\*[ï¼š:]\s*([^\n]+)',
            r'\*\*æ ¸å¿ƒè§‚ç‚¹\*\*[ï¼š:]\s*([^\n]+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, forum_text, re.IGNORECASE)
            if match:
                content = match.group(1).strip()
                # æˆªå–å‰ 500 å­—ç¬¦
                return content[:500] if len(content) > 500 else content

        # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šæ ¼å¼ï¼Œè¿”å›å‰ 500 å­—ç¬¦
        return forum_text[:500]
