# -*- coding: utf-8 -*-
"""
SupervisorAgent - Supervisor Pattern
Mature multi-Agent architecture: Intent Classification â†’ Supervisor Coordination â†’ Worker Agents â†’ Forum Synthesis
"""

import logging
import asyncio
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass

from backend.orchestration.intent_classifier import IntentClassifier, Intent, ClassificationResult
from backend.orchestration.budget import BudgetManager, BudgetedTools, BudgetExceededError
from backend.orchestration.forum import ForumHost
from backend.agents.base_agent import AgentOutput

logger = logging.getLogger(__name__)



@dataclass
class SupervisorResult:
    """Supervisor execution result"""
    success: bool
    intent: Intent
    response: str
    agent_outputs: Dict[str, Any] = None
    forum_output: Any = None
    classification: ClassificationResult = None
    errors: List[str] = None
    budget: Optional[Dict[str, Any]] = None


# Greeting response templates (Chinese output for users)
GREETING_RESPONSES = {
    "default": "æ‚¨å¥½ï¼æˆ‘æ˜¯ FinSight AI é‡‘èåŠ©æ‰‹ã€‚æˆ‘å¯ä»¥å¸®æ‚¨æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼ã€åˆ†ææ–°é—»ã€ç”ŸæˆæŠ•èµ„æŠ¥å‘Šç­‰ã€‚è¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ",
    "help": "æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\nâ€¢ æŸ¥è¯¢è‚¡ç¥¨å®æ—¶ä»·æ ¼ï¼ˆå¦‚ï¼šAAPL ä»·æ ¼ï¼‰\nâ€¢ è·å–å…¬å¸æ–°é—»ï¼ˆå¦‚ï¼šç‰¹æ–¯æ‹‰æ–°é—»ï¼‰\nâ€¢ åˆ†æå¸‚åœºæƒ…ç»ª\nâ€¢ ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Šï¼ˆå¦‚ï¼šè¯¦ç»†åˆ†æè‹¹æœï¼‰\nâ€¢ å¯¹æ¯”å¤šä¸ªè‚¡ç¥¨ï¼ˆå¦‚ï¼šå¯¹æ¯” AAPL å’Œ MSFTï¼‰",
}


class SupervisorAgent:
    """
    Supervisor Agent - Industry-standard multi-Agent architecture

    Flow:
    1. IntentClassifier classifies intent (rule-first, LLM fallback)
    2. Route based on intent
    3. Call corresponding Worker Agent(s)
    4. Forum synthesizes results (complex queries)
    """

    def __init__(self, llm, tools_module, cache, circuit_breaker=None):
        self.llm = llm
        self.tools_module = tools_module

        # é˜²æŠ¤ï¼šç¡®ä¿ cache å’Œ circuit_breaker ä¸ä¸º None
        if cache is None:
            from backend.orchestration.cache import DataCache
            cache = DataCache()
        self.cache = cache

        if circuit_breaker is None:
            from backend.services.circuit_breaker import CircuitBreaker
            circuit_breaker = CircuitBreaker()
        self.circuit_breaker = circuit_breaker

        # Intent classifier
        self.classifier = IntentClassifier(llm)

        # Forum host
        self.forum = ForumHost(llm)

        # Budget per request (set during process/process_stream)
        self._budget: Optional[BudgetManager] = None

        # Worker Agents (lazy initialization)
        self._agents = None

    @property
    def agents(self):
        """Lazy initialize Agents"""
        if self._agents is None:
            from backend.agents.price_agent import PriceAgent
            from backend.agents.news_agent import NewsAgent
            from backend.agents.deep_search_agent import DeepSearchAgent
            from backend.agents.macro_agent import MacroAgent
            from backend.agents.technical_agent import TechnicalAgent
            from backend.agents.fundamental_agent import FundamentalAgent

            self._agents = {
                "price": PriceAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "news": NewsAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "deep_search": DeepSearchAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "macro": MacroAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "technical": TechnicalAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
                "fundamental": FundamentalAgent(self.llm, self.cache, self.tools_module, self.circuit_breaker),
            }
        return self._agents

    def _set_budget(self, budget: Optional[BudgetManager]) -> None:
        self._budget = budget

    def _consume_round(self, label: str) -> None:
        if not self._budget:
            return
        self._budget.consume_round(label)

    def _select_agents_for_query(self, query: str) -> List[str]:
        """Select relevant agents based on query signals."""
        query_lower = query.lower()
        selected: List[str] = []

        if any(kw in query_lower for kw in ["æ–°é—»", "å¿«è®¯", "æ¶ˆæ¯", "news", "headline", "èˆ†æƒ…"]):
            selected.append("news")
        if any(kw in query_lower for kw in ["æŠ€æœ¯", "èµ°åŠ¿", "å½¢æ€", "macd", "rsi", "kdj", "technical", "indicator"]):
            selected.append("technical")
        if any(kw in query_lower for kw in ["è´¢æŠ¥", "è¥æ”¶", "åˆ©æ¶¦", "ä¼°å€¼", "å¸‚ç›ˆç‡", "pe", "eps", "roe", "fundamental", "valuation"]):
            selected.append("fundamental")
        if any(kw in query_lower for kw in ["å®è§‚", "cpi", "gdp", "åˆ©ç‡", "é€šèƒ€", "macro", "fomc"]):
            selected.append("macro")
        if any(kw in query_lower for kw in ["ä»·æ ¼", "è‚¡ä»·", "è¡Œæƒ…", "price", "quote", "è¡¨ç°"]):
            selected.append("price")

        if not selected:
            selected = ["price", "fundamental", "technical", "news"]

        # Ensure unique order preservation
        seen = set()
        ordered = []
        for name in selected:
            if name not in seen:
                ordered.append(name)
                seen.add(name)
        return ordered

    def _collect_evidence_pool(self, agent_outputs: Optional[Dict[str, Any]]) -> List[Dict[str, Any]]:
        pool: List[Dict[str, Any]] = []
        if not isinstance(agent_outputs, dict):
            return pool
        seen = set()
        for agent_name, output in agent_outputs.items():
            if isinstance(output, dict):
                evidence_list = output.get("evidence") or []
            else:
                evidence_list = getattr(output, "evidence", []) or []
            for ev in evidence_list:
                if isinstance(ev, dict):
                    title = ev.get("title") or ev.get("headline") or ev.get("source") or agent_name
                    snippet = ev.get("snippet") or ev.get("text") or ev.get("content") or ""
                    url = ev.get("url") or ""
                    source = ev.get("source") or agent_name
                    timestamp = ev.get("timestamp") or ev.get("published_at") or ev.get("datetime")
                    confidence = ev.get("confidence")
                else:
                    title = getattr(ev, "title", None) or getattr(ev, "source", None) or agent_name
                    snippet = getattr(ev, "text", None) or ""
                    url = getattr(ev, "url", "") or ""
                    source = getattr(ev, "source", None) or agent_name
                    timestamp = getattr(ev, "timestamp", None)
                    confidence = getattr(ev, "confidence", None)
                if isinstance(snippet, str):
                    snippet = snippet.strip()
                else:
                    snippet = str(snippet)
                if snippet and len(snippet) > 240:
                    snippet = snippet[:240] + "..."
                key = f"{url}|{title}|{snippet[:80]}"
                if key in seen:
                    continue
                seen.add(key)
                pool.append({
                    "title": title,
                    "url": url,
                    "snippet": snippet,
                    "source": source,
                    "published_date": timestamp,
                    "confidence": confidence,
                    "agent": agent_name,
                })
        return pool

    def _result(self, *args, **kwargs) -> SupervisorResult:
        result = SupervisorResult(*args, **kwargs)
        if self._budget:
            result.budget = self._budget.snapshot()
        return result

    async def process(self, query: str, tickers: List[str] = None, user_profile: Any = None, context_summary: str = None, context_ticker: str = None, on_event: Callable = None) -> SupervisorResult:
        """
        Process user query

        Args:
            query: User query
            tickers: Detected stock tickers
            user_profile: User profile
            context_summary: å¯¹è¯ä¸Šä¸‹æ–‡æ‘˜è¦
            context_ticker: ä¸Šä¸‹æ–‡ä¸­æå–çš„è‚¡ç¥¨ä»£ç 

        Returns:
            SupervisorResult
        """
        # å¦‚æœä¸Šä¸‹æ–‡ä¸­æœ‰ ticker ä½†å½“å‰æ²¡æœ‰ï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡çš„
        if context_ticker and not tickers:
            tickers = [context_ticker]

        budget = BudgetManager.from_env()
        self._set_budget(budget)
        if self.tools_module and not isinstance(self.tools_module, BudgetedTools):
            self.tools_module = BudgetedTools(self.tools_module, budget)
        self._agents = None

        # 1. Intent classification (å¸¦ä¸Šä¸‹æ–‡)
        classification = self.classifier.classify(query, tickers, context_summary=context_summary)
        logger.info(f"[Supervisor] Intent: {classification.intent.value} (method: {classification.method}, confidence: {classification.confidence})")

        # 2. Route based on intent
        intent = classification.intent

        # Simple intents - rule-based direct handling (cost-free)
        if intent == Intent.GREETING:
            return self._handle_greeting(query, classification)

        if intent == Intent.OFF_TOPIC:
            return self._result(
                success=True,
                intent=intent,
                response="æŠ±æ­‰ï¼Œæˆ‘æ˜¯é‡‘èåŠ©æ‰‹ï¼Œåªèƒ½å›ç­”é‡‘èç›¸å…³çš„é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆè‚¡ç¥¨æˆ–å¸‚åœºæ–¹é¢çš„é—®é¢˜å—ï¼Ÿ",
                classification=classification
            )

        if intent == Intent.CLARIFY:
            return self._result(
                success=True,
                intent=intent,
                response="è¯·é—®æ‚¨æƒ³äº†è§£å“ªåªè‚¡ç¥¨ï¼Ÿå¯ä»¥å‘Šè¯‰æˆ‘è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°ã€‚",
                classification=classification
            )

        # Intents requiring Agent calls
        tickers_list = classification.tickers if isinstance(classification.tickers, list) else list(classification.tickers) if classification.tickers else []
        ticker = tickers_list[0] if tickers_list else None

        # Lightweight intents - single tool/agent
        # æ‰€æœ‰ handler éƒ½ä¼ é€’ context_summaryï¼Œè®©å®ƒä»¬å¯ä»¥æ ¹æ®ä¸Šä¸‹æ–‡ä¼˜åŒ–å“åº”
        if intent == Intent.PRICE:
            return await self._handle_price(query, ticker, classification, context_summary)

        # NEWS æ„å›¾ï¼šå­æ„å›¾åˆ†ç±» - åŒºåˆ†"æŸ¥è¯¢æ–°é—»"å’Œ"åˆ†ææ–°é—»"
        if intent == Intent.NEWS:
            news_subintent = self._classify_news_subintent(query)
            if news_subintent == "analyze":
                # åˆ†æç±»è¯·æ±‚ï¼šèµ° NewsAgent + Forum æ·±åº¦åˆ†æ
                return await self._handle_news_analysis(query, ticker, classification, context_summary)
            else:
                # æŸ¥è¯¢ç±»è¯·æ±‚ï¼šè¿”å›åŸå§‹æ–°é—»åˆ—è¡¨ï¼ˆå¸¦é“¾æ¥ï¼‰
                return await self._handle_news(query, ticker, classification, context_summary)

        if intent == Intent.SENTIMENT:
            return await self._handle_sentiment(query, ticker, classification, context_summary)

        if intent == Intent.TECHNICAL:
            return await self._handle_single_agent("technical", query, ticker, classification, context_summary)

        if intent == Intent.FUNDAMENTAL:
            return await self._handle_single_agent("fundamental", query, ticker, classification, context_summary)

        if intent == Intent.MACRO:
            return await self._handle_single_agent("macro", query, ticker, classification, context_summary)

        # Complex intents - multi-Agent collaboration
        if intent == Intent.REPORT:
            return await self._handle_report(query, ticker, user_profile, classification, context_summary, on_event=on_event)

        if intent == Intent.COMPARISON:
            return await self._handle_comparison(query, tickers_list, classification, context_summary)

        # Fallback - search
        return await self._handle_search(query, ticker, classification, context_summary)

    def _handle_greeting(self, query: str, classification: ClassificationResult) -> SupervisorResult:
        """Handle greeting - rule-based direct response, free"""
        query_lower = query.lower()
        if any(kw in query_lower for kw in ["help", "support", "what can you do", "who are you", "å¸®åŠ©", "ä½ æ˜¯è°", "ä½ èƒ½åšä»€ä¹ˆ"]):
            response = GREETING_RESPONSES["help"]
        else:
            response = GREETING_RESPONSES["default"]

        return self._result(
            success=True,
            intent=Intent.GREETING,
            response=response,
            classification=classification
        )

    async def _handle_price(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle price query - lightweight tool, with context awareness"""
        if not ticker:
            return self._result(
                success=False,
                intent=Intent.PRICE,
                response="è¯·æä¾›è‚¡ç¥¨ä»£ç ï¼Œä¾‹å¦‚ï¼šAAPL ä»·æ ¼",
                classification=classification
            )

        try:
            self._consume_round("tool:price")
            # Direct tool call, no Agent
            price_data = self.tools_module.get_stock_price(ticker)

            if isinstance(price_data, dict) and price_data.get("error"):
                return self._result(
                    success=False,
                    intent=Intent.PRICE,
                    response=f"è·å– {ticker} ä»·æ ¼å¤±è´¥ï¼š{price_data.get('error')}",
                    classification=classification
                )

            # Format response
            if isinstance(price_data, dict):
                price = price_data.get("price", "N/A")
                change = price_data.get("change_percent", 0)
                change_str = f"+{change:.2f}%" if change >= 0 else f"{change:.2f}%"
                base_response = f"**{ticker}** å½“å‰ä»·æ ¼: ${price} ({change_str})"
            else:
                base_response = f"**{ticker}** ä»·æ ¼æ•°æ®: {price_data}"

            # If there's context, enhance response with LLM
            if context_summary:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""<role>é‡‘èæ•°æ®åˆ†æå¸ˆ</role>
<task>ç»“åˆä¸Šä¸‹æ–‡è§£è¯»è‚¡ç¥¨ä»·æ ¼</task>

<data>
ä»·æ ¼: {base_response}
ä¸Šä¸‹æ–‡: {context_summary}
é—®é¢˜: {query}
</data>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼ˆä¸è¦è¯´"å¥½çš„"ã€"å½“ç„¶"ã€"æˆ‘æ¥"ç­‰ï¼‰
- ç›´æ¥è¾“å‡ºåˆ†æå†…å®¹
- 1-2å¥è¯ï¼Œç®€æ´ä¸“ä¸š
- ä¸Šä¸‹æ–‡æ— å…³æ—¶ä»…è¿”å›ä»·æ ¼æ•°æ®
</rules>"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    return self._result(
                        success=True,
                        intent=Intent.PRICE,
                        response=response.content if hasattr(response, 'content') else str(response),
                        classification=classification
                    )
                except Exception as e:
                    logger.info(f"[Supervisor] Price context enhancement failed: {e}")

            return self._result(
                success=True,
                intent=Intent.PRICE,
                response=base_response,
                classification=classification
            )
        except BudgetExceededError as e:
            return self._result(
                success=False,
                intent=Intent.PRICE,
                response=f"budget exceeded: {e}",
                classification=classification,
                errors=[str(e)]
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.PRICE,
                response=f"è·å–ä»·æ ¼æ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    def _classify_news_subintent(self, query: str) -> str:
        """
        NEWS æ„å›¾çš„å­åˆ†ç±»ï¼šåŒºåˆ†"æŸ¥è¯¢æ–°é—»"å’Œ"åˆ†ææ–°é—»"

        ä¸šç•Œæœ€ä½³å®è·µï¼šSub-intent Classification
        - åˆ†æç±»ï¼šç”¨æˆ·æƒ³è¦å¯¹æ–°é—»è¿›è¡Œè§£è¯»ã€åˆ†æå½±å“
        - æŸ¥è¯¢ç±»ï¼šç”¨æˆ·åªæ˜¯æƒ³çœ‹æœ€æ–°æ–°é—»åˆ—è¡¨

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢

        Returns:
            str: "analyze" æˆ– "fetch"
        """
        query_lower = query.lower()

        # åˆ†æç±»å…³é”®è¯ï¼ˆä¸­è‹±æ–‡ï¼‰
        analyze_keywords = [
            # ä¸­æ–‡åˆ†æè¯
            "åˆ†æ", "å½±å“", "è§£è¯»", "æ„å‘³", "è¯„ä¼°", "çœ‹æ³•", "è§‚ç‚¹",
            "èµ°åŠ¿", "é¢„æµ‹", "è§£æ", "æ·±åº¦", "è¯¦ç»†", "æ€ä¹ˆçœ‹", "ä¼šæ€æ ·",
            "å¸¦æ¥", "å¯¼è‡´", "é€ æˆ", "å¼•å‘", "è¯´æ˜", "åæ˜ ", "è¡¨æ˜",
            "åˆ©å¥½", "åˆ©ç©º", "æœºä¼š", "é£é™©", "è¶‹åŠ¿", "å‰æ™¯", "å±•æœ›",
            # è‹±æ–‡åˆ†æè¯
            "analyze", "analysis", "impact", "effect", "implication",
            "interpret", "predict", "forecast", "outlook", "assess"
        ]

        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ†æç±»å…³é”®è¯
        for keyword in analyze_keywords:
            if keyword in query_lower:
                return "analyze"

        # é»˜è®¤è¿”å›æŸ¥è¯¢ç±»
        return "fetch"

    async def _handle_news(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle news query - æ˜¾ç¤ºåŸå§‹æ–°é—»ï¼Œæœ‰ä¸Šä¸‹æ–‡æ—¶è¡¥å……åˆ†æ"""
        try:
            # Prefer NewsAgent for reliability when ticker is available
            if ticker:
                news_agent = self.agents.get("news")
                if news_agent:
                    try:
                        self._consume_round("agent:news")
                        output = await news_agent.research(query, ticker)
                        if output and output.summary:
                            return self._result(
                                success=True,
                                intent=Intent.NEWS,
                                response=output.summary,
                                agent_outputs={"news": output},
                                classification=classification
                            )
                    except Exception as e:
                        logger.info(f"[Supervisor] NewsAgent failed: {e}")

            self._consume_round("tool:news")
            if ticker:
                news_data = self.tools_module.get_company_news(ticker)
            else:
                news_data = self.tools_module.search(query)

            if isinstance(news_data, dict) and news_data.get("error"):
                return self._result(
                    success=False,
                    intent=Intent.NEWS,
                    response=f"è·å–æ–°é—»å¤±è´¥ï¼š{news_data.get('error')}",
                    classification=classification
                )

            # æ ¼å¼åŒ–åŸå§‹æ–°é—»æ•°æ®
            if isinstance(news_data, list):
                formatter = getattr(self.tools_module, "format_news_items", None) if self.tools_module else None
                if formatter:
                    title = f"Latest News ({ticker})" if ticker else "Latest News"
                    base_response = formatter(news_data, title=title)
                else:
                    base_response = "\n".join(
                        f"- {(item.get('headline') or item.get('title') or 'No title')}"
                        for item in news_data
                        if isinstance(item, dict)
                    )
            else:
                base_response = str(news_data) if news_data else "æš‚æ— ç›¸å…³æ–°é—»"

            if isinstance(base_response, str) and ("Connection error" in base_response or "Search error" in base_response):
                base_response = "æ–°é—»æºè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚"

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œåœ¨åŸå§‹æ–°é—»åè¡¥å……ç®€çŸ­åˆ†æ
            if context_summary and news_data:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""<role>é‡‘èæ–°é—»åˆ†æå¸ˆ</role>
<task>åˆ†ææ–°é—»ä¸å¯¹è¯ä¸Šä¸‹æ–‡çš„å…³è”æ€§</task>

<news>{base_response[:1500]}</news>
<context>{context_summary}</context>

<output_format>
ğŸ’¡ **ä¸Šä¸‹æ–‡å…³è”**: [1-2å¥å…³è”åˆ†æ]
</output_format>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼Œç›´æ¥è¾“å‡ºæ ¼å¼å†…å®¹
- ä¸é‡å¤æ–°é—»å†…å®¹
- ä»…åˆ†æå…³è”æ€§
</rules>"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    context_analysis = response.content if hasattr(response, 'content') else str(response)
                    # å…ˆæ˜¾ç¤ºæ–°é—»ï¼Œå†æ˜¾ç¤ºä¸Šä¸‹æ–‡åˆ†æ
                    base_response = f"{base_response}\n\n{context_analysis}"
                except Exception as e:
                    logger.info(f"[Supervisor] News context enhancement failed: {e}")

            return self._result(
                success=True,
                intent=Intent.NEWS,
                response=base_response,
                classification=classification
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.NEWS,
                response="æ–°é—»æºè¿æ¥å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_general_news(self, query: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        Handle general news query without ticker (e.g., "ä»Šå¤©æœ‰ä»€ä¹ˆè´¢ç»æ–°é—»")
        ä½¿ç”¨é€šç”¨æœç´¢è·å–æ–°é—»ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡åˆ†æ
        """
        return await self._handle_news(query, None, classification, context_summary)

    async def _handle_news_analysis(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        å¤„ç†æ–°é—»åˆ†æè¯·æ±‚ - æ·±åº¦åˆ†ææ–°é—»å½±å“

        å½“ç”¨æˆ·è¯·æ±‚"åˆ†ææ–°é—»å½±å“"ã€"æ–°é—»è§£è¯»"ç­‰æ—¶è°ƒç”¨æ­¤æ–¹æ³•ã€‚
        ä½¿ç”¨ NewsAgent çš„åæ€å¾ªç¯ + Forum ç»¼åˆåˆ†æã€‚

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            ticker: è‚¡ç¥¨ä»£ç 
            classification: æ„å›¾åˆ†ç±»ç»“æœ
            context_summary: ä¸Šä¸‹æ–‡æ‘˜è¦

        Returns:
            SupervisorResult: åŒ…å«æ·±åº¦æ–°é—»åˆ†æçš„ç»“æœ
        """
        try:
            self._consume_round("tool:news_analysis")
            from langchain_core.messages import HumanMessage

            # 1. å…ˆè·å–åŸå§‹æ–°é—»æ•°æ®
            if ticker:
                news_data = self.tools_module.get_company_news(ticker)
            else:
                news_data = self.tools_module.search(query)

            if isinstance(news_data, dict) and news_data.get("error"):
                return self._result(
                    success=False,
                    intent=Intent.NEWS,
                    response=f"è·å–æ–°é—»å¤±è´¥ï¼š{news_data.get('error')}",
                    classification=classification
                )

            news_text = str(news_data) if news_data else ""

            if not news_text or news_text == "æš‚æ— ç›¸å…³æ–°é—»":
                return self._result(
                    success=True,
                    intent=Intent.NEWS,
                    response="æš‚æ— ç›¸å…³æ–°é—»å¯ä¾›åˆ†æ",
                    classification=classification
                )

            # 2. ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦æ–°é—»åˆ†æ
            analysis_prompt = f"""<role>èµ„æ·±é‡‘èæ–°é—»åˆ†æå¸ˆ</role>
<task>æ·±åº¦åˆ†ææ–°é—»å½±å“</task>

<news>{news_text[:3000]}</news>
<query>{query}</query>
{f"<context>{context_summary}</context>" if context_summary else ""}

<output_structure>
### ğŸ“° æ–°é—»æ‘˜è¦
[2-3å¥æ ¸å¿ƒäº‹ä»¶æ€»ç»“]

### ğŸ“Š å¸‚åœºå½±å“
- **çŸ­æœŸ**: [å³æ—¶å½±å“é¢„åˆ¤]
- **ä¸­é•¿æœŸ**: [æŒç»­æ€§å½±å“]

### ğŸ¯ æŠ•èµ„å¯ç¤º
- [å¯¹æŠ•èµ„è€…çš„æ„ä¹‰]
- [åç»­å…³æ³¨ç‚¹]

### âš ï¸ é£é™©æç¤º
- [éšå«é£é™©å› ç´ ]
- [ä¸ç¡®å®šæ€§è­¦ç¤º]
</output_structure>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼ˆä¸è¦è¯´"å¥½çš„"ã€"æˆ‘æ¥åˆ†æ"ç­‰ï¼‰
- ç›´æ¥æŒ‰ç»“æ„è¾“å‡ºåˆ†æ
- è§‚ç‚¹å…·ä½“ï¼Œé¿å…ç©ºæ³›è¡¨è¿°
- æ•°æ®æ”¯æ’‘ï¼Œä¸“ä¸šå®¢è§‚
</rules>"""

            response = await self.llm.ainvoke([HumanMessage(content=analysis_prompt)])
            analysis_content = response.content if hasattr(response, 'content') else str(response)

            # 3. ç»„åˆåŸå§‹æ–°é—» + åˆ†æç»“æœ
            final_response = f"""## ğŸ“° ç›¸å…³æ–°é—»

{news_text}

---

## ğŸ” æ·±åº¦åˆ†æ

{analysis_content}"""

            return self._result(
                success=True,
                intent=Intent.NEWS,
                response=final_response,
                classification=classification
            )

        except Exception as e:
            logger.info(f"[Supervisor] News analysis failed: {e}")
            # Fallback: è¿”å›åŸå§‹æ–°é—»
            return await self._handle_news(query, ticker, classification, context_summary)

    async def _handle_sentiment(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """
        Handle market sentiment query
        å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼ˆä¹‹å‰è®¨è®ºçš„è‚¡ç¥¨/æ–°é—»ï¼‰ï¼Œç»“åˆä¸Šä¸‹æ–‡æ¥åˆ†ææƒ…ç»ª
        """
        try:
            # 1. è·å–åŸºç¡€å¸‚åœºæƒ…ç»ªæ•°æ®
            self._consume_round("tool:sentiment")
            sentiment_data = self.tools_module.get_market_sentiment()
            base_sentiment = str(sentiment_data) if sentiment_data else "æš‚æ— å¸‚åœºæƒ…ç»ªæ•°æ®"

            # 2. å¦‚æœæ²¡æœ‰ä¸Šä¸‹æ–‡ï¼Œç›´æ¥è¿”å›åŸºç¡€æƒ…ç»ª
            if not context_summary and not ticker:
                return self._result(
                    success=True,
                    intent=Intent.SENTIMENT,
                    response=base_sentiment,
                    classification=classification
                )

            # 3. å¦‚æœæœ‰ä¸Šä¸‹æ–‡æˆ– tickerï¼Œä½¿ç”¨ LLM ç»“åˆåˆ†æ
            # è·å–ç›¸å…³æ–°é—»ï¼ˆå¦‚æœæœ‰ tickerï¼‰
            news_content = ""
            if ticker:
                try:
                    news_agent = self.agents.get("news")
                    if news_agent:
                        self._consume_round("agent:news")
                        news_output = await news_agent.research(f"{ticker} news sentiment", ticker)
                        if news_output and news_output.summary:
                            news_content = f"\n\nã€{ticker} ç›¸å…³æ–°é—»ã€‘\n{news_output.summary}"
                except Exception as e:
                    logger.info(f"[Supervisor] News fetch for sentiment failed: {e}")

            # 4. æ„å»º Prompt è®© LLM ç»¼åˆåˆ†æ
            prompt = f"""<role>å¸‚åœºæƒ…ç»ªåˆ†æå¸ˆ</role>
<task>ç»¼åˆåˆ†æå¸‚åœºæƒ…ç»ª</task>

<sentiment_data>{base_sentiment}</sentiment_data>
{f"<news>{news_content}</news>" if news_content else ""}
<context>{context_summary or 'æ— '}</context>
<query>{query}</query>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼Œç›´æ¥è¾“å‡ºåˆ†æ
- 2-3å¥è¯ï¼Œç®€æ´ä¸“ä¸š
- ä¼˜å…ˆåˆ†æä¸Šä¸‹æ–‡ä¸­æåˆ°çš„è‚¡ç¥¨/è¡Œä¸š
- æ˜ç¡®æƒ…ç»ªå€¾å‘ï¼ˆçœ‹æ¶¨/çœ‹è·Œ/ä¸­æ€§ï¼‰
</rules>"""

            from langchain_core.messages import HumanMessage
            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            analysis = response.content if hasattr(response, 'content') else str(response)

            return self._result(
                success=True,
                intent=Intent.SENTIMENT,
                response=analysis,
                classification=classification
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.SENTIMENT,
                response=f"è·å–å¸‚åœºæƒ…ç»ªæ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_single_agent(self, agent_name: str, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle single Agent query with context awareness"""
        if not ticker:
            return self._result(
                success=False,
                intent=classification.intent,
                response=f"è¯·æä¾›è‚¡ç¥¨ä»£ç è¿›è¡Œ{agent_name}åˆ†æ",
                classification=classification
            )

        try:
            agent = self.agents.get(agent_name)
            if not agent:
                return self._result(
                    success=False,
                    intent=classification.intent,
                    response=f"Agent {agent_name} ä¸å¯ç”¨",
                    classification=classification
                )

            # Enhance query with context if available
            enhanced_query = query
            if context_summary:
                enhanced_query = f"{query}\n\nã€å‚è€ƒä¸Šä¸‹æ–‡ã€‘\n{context_summary}"

            self._consume_round(f"agent:{agent_name}")
            output = await agent.research(enhanced_query, ticker)
            base_response = output.summary if output else "åˆ†æå®Œæˆï¼Œä½†æ— ç»“æœ"

            # If context exists and agent returns result, optionally enhance with LLM
            if context_summary and output and output.summary:
                try:
                    from langchain_core.messages import HumanMessage
                    prompt = f"""<role>{agent_name}åˆ†æä¸“å®¶</role>
<task>ç»“åˆä¸Šä¸‹æ–‡ä¼˜åŒ–åˆ†æå›å¤</task>

<analysis>{output.summary[:1500]}</analysis>
<context>{context_summary}</context>
<query>{query}</query>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼ˆä¸è¦è¯´"å¥½çš„"ã€"æ ¹æ®åˆ†æ"ç­‰ï¼‰
- ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„åˆ†æå†…å®¹
- èå…¥ä¸Šä¸‹æ–‡ç›¸å…³è¯é¢˜
- ä¿æŒä¸“ä¸šç®€æ´
</rules>"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    base_response = response.content if hasattr(response, 'content') else str(response)
                except Exception as e:
                    logger.info(f"[Supervisor] {agent_name} context enhancement failed: {e}")

            return self._result(
                success=True,
                intent=classification.intent,
                response=base_response,
                agent_outputs={agent_name: output},
                classification=classification
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=classification.intent,
                response=f"{agent_name} åˆ†æå‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_report(self, query: str, ticker: str, user_profile: Any, classification: ClassificationResult, context_summary: str = None, on_event: Callable = None) -> SupervisorResult:
        """Handle deep report - multi-Agent collaboration with context awareness"""
        if not ticker:
            return self._result(
                success=False,
                intent=Intent.REPORT,
                response="è¯·æä¾›è‚¡ç¥¨ä»£ç è¿›è¡Œæ·±åº¦åˆ†æï¼Œä¾‹å¦‚ï¼šè¯¦ç»†åˆ†æ AAPL",
                classification=classification
            )

        try:
            # æ™ºèƒ½åˆ¤æ–­ä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­çš„ ticker ä¸å½“å‰ä¸åŒï¼Œå¿½ç•¥ä¸Šä¸‹æ–‡
            relevant_context = None
            if context_summary:
                import re
                # ä»ä¸Šä¸‹æ–‡ä¸­æå–å¯èƒ½çš„ ticker
                context_tickers = re.findall(r'\b([A-Z]{2,5})\b', context_summary)
                stopwords = {'A', 'I', 'AM', 'PM', 'US', 'UK', 'AI', 'CEO', 'IPO', 'ETF', 'VS', 'PE', 'EPS', 'GDP', 'CPI', 'API', 'OK', 'THE', 'FOR', 'AND', 'NOT'}
                context_tickers = [t for t in context_tickers if t not in stopwords]

                # åˆ¤æ–­ä¸Šä¸‹æ–‡æ˜¯å¦ä¸å½“å‰ ticker ç›¸å…³
                if context_tickers and ticker.upper() not in [t.upper() for t in context_tickers]:
                    # ä¸Šä¸‹æ–‡ä¸­æœ‰å…¶ä»– tickerï¼Œä½†æ²¡æœ‰å½“å‰ ticker - å¿½ç•¥ä¸Šä¸‹æ–‡
                    logger.info(f"[Supervisor] å¿½ç•¥ä¸ç›¸å…³ä¸Šä¸‹æ–‡ (context tickers: {context_tickers}, current: {ticker})")
                    relevant_context = None
                else:
                    relevant_context = context_summary

            # Enhance query with context only if relevant
            enhanced_query = query
            if relevant_context:
                enhanced_query = f"{query}\n\nã€å‚è€ƒä¸Šä¸‹æ–‡ã€‘\n{relevant_context}"

            # Plan-driven execution with retries/dependencies
            from backend.orchestration.plan import PlanBuilder, PlanExecutor

            agent_names = list(self.agents.keys())
            plan = PlanBuilder.build_report_plan(enhanced_query, ticker, agent_names)
            executor = PlanExecutor(self.agents, self.forum, budget=self._budget)
            execution = await executor.execute(
                plan,
                enhanced_query,
                ticker,
                user_profile=user_profile,
                context_summary=relevant_context,
                on_event=on_event,
            )

            valid_outputs = execution.get("agent_outputs", {})
            errors = execution.get("errors", [])
            forum_result = execution.get("forum_output")

            if forum_result is None:
                # Forum å¤±è´¥æ—¶æ„é€ å…œåº•ç»¼åˆæŠ¥å‘Šï¼Œé¿å…å‰ç«¯ç¼ºå¤±æ•´åˆæŠ¥å‘Š/è¯æ®æ± 
                try:
                    from backend.orchestration.forum import ForumOutput
                    context_parts = {}
                    for name, output in valid_outputs.items():
                        key = str(name).lower().replace("agent", "")
                        if output and hasattr(output, "summary"):
                            summary_info = f"æ‘˜è¦: {output.summary}\nç½®ä¿¡åº¦: {getattr(output, 'confidence', 0.6):.0%}"
                            ev_list = getattr(output, "evidence", []) or []
                            if ev_list:
                                summary_info += f"\nè¯æ®æ•°é‡: {len(ev_list)}"
                        else:
                            summary_info = "æ— æ•°æ®"
                        context_parts[key] = summary_info

                    for key in ["price", "news", "technical", "fundamental", "deep_search", "macro"]:
                        context_parts.setdefault(key, "æ— æ•°æ®")

                    if hasattr(self.forum, "_fallback_synthesis"):
                        fallback_consensus = self.forum._fallback_synthesis(context_parts)
                    else:
                        summaries = []
                        for name, output in valid_outputs.items():
                            if output and hasattr(output, "summary") and output.summary:
                                summaries.append(f"**{name}**: {str(output.summary)[:400]}")
                        fallback_consensus = "\n\n".join(summaries) if summaries else "ç»¼åˆåˆ†ææš‚æ—¶ä¸å¯ç”¨ã€‚"

                    conf_values = [getattr(out, "confidence", 0.6) for out in valid_outputs.values() if out]
                    avg_conf = sum(conf_values) / len(conf_values) if conf_values else 0.6

                    forum_result = ForumOutput(
                        consensus=fallback_consensus,
                        disagreement="",
                        confidence=avg_conf,
                        recommendation="HOLD",
                        risks=["ç»¼åˆåˆ†ææš‚æ—¶ä¸å¯ç”¨", "å·²ä½¿ç”¨ç®€åŒ–åˆæˆ"]
                    )
                    errors = list(errors) if errors else []
                    errors.append("forum: fallback_synthesis_used")
                    logger.warning("[Supervisor] forum_output is None, using fallback synthesis")
                except Exception as exc:
                    logger.warning(f"[Supervisor] fallback synthesis failed: {exc}")

            return self._result(
                success=True,
                intent=Intent.REPORT,
                response=forum_result.consensus if forum_result else "æŠ¥å‘Šç”Ÿæˆå®Œæˆ",
                agent_outputs=valid_outputs,
                forum_output=forum_result,
                classification=classification,
                errors=errors if errors else None
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.REPORT,
                response=f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_comparison(self, query: str, tickers: List[str], classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Handle comparison analysis with context awareness"""
        if len(tickers) < 2:
            return self._result(
                success=False,
                intent=Intent.COMPARISON,
                response="è¯·æä¾›è‡³å°‘ä¸¤ä¸ªè‚¡ç¥¨ä»£ç è¿›è¡Œå¯¹æ¯”ï¼Œä¾‹å¦‚ï¼šå¯¹æ¯” AAPL å’Œ MSFT",
                classification=classification
            )

        try:
            self._consume_round("tool:comparison")
            comparison_data = self.tools_module.get_performance_comparison(tickers)
            base_response = str(comparison_data) if comparison_data else "å¯¹æ¯”å®Œæˆï¼Œä½†æ— æ•°æ®"

            selected_agents = self._select_agents_for_query(query)
            agent_outputs: Dict[str, Any] = {}
            errors: List[str] = []

            async def run_agent(agent_name: str, ticker: str):
                agent = self.agents.get(agent_name)
                if not agent:
                    return agent_name, ticker, None, f"Agent {agent_name} ä¸å¯ç”¨"
                enhanced_query = query
                if context_summary:
                    enhanced_query = f"{query}\n\nã€å‚è€ƒä¸Šä¸‹æ–‡ã€‘\n{context_summary}"
                try:
                    self._consume_round(f"agent:{agent_name}")
                    output = await agent.research(enhanced_query, ticker)
                    return agent_name, ticker, output, None
                except Exception as exc:
                    return agent_name, ticker, None, str(exc)

            tasks = []
            for ticker in tickers:
                for agent_name in selected_agents:
                    tasks.append(run_agent(agent_name, ticker))
            if tasks:
                results = await asyncio.gather(*tasks)
                for agent_name, ticker, output, err in results:
                    key = f"{agent_name}_{ticker}"
                    if output:
                        agent_outputs[key] = output
                    if err:
                        errors.append(f"{key}: {err}")

            # If context exists, enhance with LLM
            if self.llm and (comparison_data or agent_outputs):
                try:
                    from langchain_core.messages import HumanMessage
                    summaries = []
                    for ticker in tickers:
                        ticker_summaries = []
                        for agent_name in selected_agents:
                            key = f"{agent_name}_{ticker}"
                            output = agent_outputs.get(key)
                            if output and getattr(output, "summary", None):
                                ticker_summaries.append(f"{agent_name}: {str(output.summary)[:400]}")
                        if ticker_summaries:
                            summaries.append(f"{ticker}:\n- " + "\n- ".join(ticker_summaries))
                    summaries_text = "\n\n".join(summaries) if summaries else "æ— é¢å¤– Agent åˆ†ææ‘˜è¦"

                    prompt = f"""<role>è‚¡ç¥¨å¯¹æ¯”åˆ†æå¸ˆ</role>
<task>è§£è¯»è‚¡ç¥¨å¯¹æ¯”ç»“æœ</task>

<comparison>{base_response[:2000]}</comparison>
<agent_summaries>{summaries_text[:2500]}</agent_summaries>
<context>{context_summary or 'æ— '}</context>
<query>{query}</query>

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼Œç›´æ¥è¾“å‡ºå¯¹æ¯”è§£è¯»
- 3-5å¥è¯æ€»ç»“æ ¸å¿ƒå·®å¼‚
- èå…¥ä¸Šä¸‹æ–‡ï¼ˆæŠ•èµ„åå¥½ã€å†å²è®¨è®ºï¼‰
- ç»™å‡ºæ˜ç¡®çš„å¯¹æ¯”ç»“è®º
- å¦‚æŸç»´åº¦æ— æ•°æ®ï¼Œæ˜ç¡®è¯´æ˜
</rules>"""
                    response = await self.llm.ainvoke([HumanMessage(content=prompt)])
                    return self._result(
                        success=True,
                        intent=Intent.COMPARISON,
                        response=response.content if hasattr(response, 'content') else str(response),
                        agent_outputs=agent_outputs or None,
                        classification=classification,
                        errors=errors if errors else None
                    )
                except Exception as e:
                    logger.info(f"[Supervisor] Comparison context enhancement failed: {e}")

            return self._result(
                success=True,
                intent=Intent.COMPARISON,
                response=base_response,
                agent_outputs=agent_outputs or None,
                classification=classification,
                errors=errors if errors else None
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.COMPARISON,
                response=f"å¯¹æ¯”åˆ†æå‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    async def _handle_search(self, query: str, ticker: str, classification: ClassificationResult, context_summary: str = None) -> SupervisorResult:
        """Fallback search with context awareness"""
        try:
            self._consume_round("tool:search")
            search_result = self.tools_module.search(query)

            # Use LLM to synthesize search results with context
            from langchain_core.messages import HumanMessage

            prompt = f"""<role>é‡‘èä¿¡æ¯æ£€ç´¢ä¸“å®¶</role>
<task>ç»¼åˆæœç´¢ç»“æœå›ç­”é—®é¢˜</task>

<query>{query}</query>
<search_results>{search_result}</search_results>
{f"<context>{context_summary}</context>" if context_summary else ""}

<rules>
- ç¦æ­¢å¼€åœºç™½ï¼Œç›´æ¥å›ç­”é—®é¢˜
- 2-4å¥è¯ï¼Œç®€æ´å‡†ç¡®
- åŸºäºæœç´¢ç»“æœï¼Œä¸ç¼–é€ ä¿¡æ¯
- ä¸­æ–‡å›å¤
{f"- ç»“åˆä¸Šä¸‹æ–‡è¯é¢˜" if context_summary else ""}
</rules>"""

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])

            return self._result(
                success=True,
                intent=Intent.SEARCH,
                response=response.content if hasattr(response, 'content') else str(response),
                classification=classification
            )
        except Exception as e:
            return self._result(
                success=False,
                intent=Intent.SEARCH,
                response=f"æœç´¢å‡ºé”™: {e}",
                classification=classification,
                errors=[str(e)]
            )

    def _extract_context_info(self, conversation_context: List[Dict]) -> tuple:
        """
        ä»å¯¹è¯å†å²ä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯
        å¦‚æœå‘ç°é“¾æ¥ï¼Œä¼šå°è¯•æŠ“å–å¹¶æ€»ç»“å†…å®¹

        Returns:
            (context_summary, context_ticker): ä¸Šä¸‹æ–‡æ‘˜è¦å’Œå½“å‰å…³æ³¨çš„è‚¡ç¥¨
        """
        import re

        if not conversation_context:
            return None, None

        # æå–æœ€è¿‘å¯¹è¯ä¸­çš„è‚¡ç¥¨ä»£ç 
        ticker_pattern = r'\b([A-Z]{1,5})\b'
        url_pattern = r'https?://[^\s\)\]<>\"\']+'
        found_tickers = []
        found_urls = []

        # æ„å»ºä¸Šä¸‹æ–‡æ‘˜è¦
        context_parts = []
        for msg in conversation_context[-4:]:  # æœ€è¿‘ 4 æ¡æ¶ˆæ¯
            role = msg.get("role", "")
            content = msg.get("content", "")

            if not content:
                continue

            # æå–è‚¡ç¥¨ä»£ç 
            matches = re.findall(ticker_pattern, content)
            # è¿‡æ»¤å¸¸è§éè‚¡ç¥¨è¯
            stopwords = {'A', 'I', 'AM', 'PM', 'US', 'UK', 'AI', 'CEO', 'IPO', 'ETF', 'VS', 'PE', 'EPS', 'GDP', 'CPI', 'API', 'OK', 'CNN', 'HTTP', 'HTTPS', 'WWW', 'COM', 'ORG', 'NET'}
            for m in matches:
                if m not in stopwords and len(m) >= 2:
                    found_tickers.append(m)

            # æå– URL
            urls = re.findall(url_pattern, content)
            found_urls.extend(urls)

            # æˆªæ–­é•¿å†…å®¹
            preview = content[:150] + "..." if len(content) > 150 else content
            context_parts.append(f"{role}: {preview}")

        # å¦‚æœæœ‰ URLï¼Œå°è¯•æŠ“å–å¹¶æ€»ç»“ï¼ˆæœ€å¤š 2 ä¸ªï¼‰
        url_summaries = []
        if found_urls and self.tools_module:
            for url in found_urls[:2]:  # æœ€å¤šå¤„ç† 2 ä¸ªé“¾æ¥
                try:
                    summary = self._fetch_and_summarize_url(url)
                    if summary:
                        url_summaries.append(f"[é“¾æ¥å†…å®¹æ‘˜è¦] {summary}")
                except Exception as e:
                    logger.info(f"[Supervisor] URL fetch failed: {url}, error: {e}")

        # åˆå¹¶ä¸Šä¸‹æ–‡
        if url_summaries:
            context_parts.extend(url_summaries)

        context_summary = "\n".join(context_parts) if context_parts else None
        context_ticker = found_tickers[-1] if found_tickers else None  # å–æœ€è¿‘æåˆ°çš„

        return context_summary, context_ticker

    def _fetch_and_summarize_url(self, url: str) -> str:
        """
        æŠ“å– URL å†…å®¹å¹¶ç”Ÿæˆæ‘˜è¦
        """
        try:
            # ä½¿ç”¨ tools_module ä¸­çš„æœç´¢åŠŸèƒ½æ¥è·å–å†…å®¹
            search_func = getattr(self.tools_module, 'fetch_url_content', None)
            if search_func:
                content = search_func(url)
                if content and len(content) > 100:
                    # ä½¿ç”¨ LLM ç”Ÿæˆæ‘˜è¦
                    from langchain_core.messages import HumanMessage
                    prompt = f"è¯·ç”¨2-3å¥è¯æ€»ç»“ä»¥ä¸‹å†…å®¹çš„è¦ç‚¹ï¼š\n\n{content[:2000]}"
                    response = self.llm.invoke([HumanMessage(content=prompt)])
                    return response.content[:300] if hasattr(response, 'content') else str(response)[:300]

            # å¦‚æœæ²¡æœ‰ä¸“é—¨çš„ fetch å‡½æ•°ï¼Œå°è¯•ç”¨æœç´¢
            search = getattr(self.tools_module, 'search', None)
            if search:
                result = search(f"site:{url}")
                if result:
                    return str(result)[:300]
        except Exception as e:
            logger.info(f"[Supervisor] URL summarize failed: {e}")

        return None

    async def process_stream(
        self,
        query: str,
        tickers: List[str] = None,
        user_profile: Any = None,
        conversation_context: List[Dict] = None,
        agent_gate: Optional[Dict[str, Any]] = None,
    ):
        """
        Streaming process - real-time progress reporting
        æ ¼å¼ä¸å‰ç«¯ sendMessageStream æœŸæœ›çš„æ ¼å¼å…¼å®¹
        æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            tickers: æ£€æµ‹åˆ°çš„è‚¡ç¥¨ä»£ç 
            user_profile: ç”¨æˆ·é…ç½®
            conversation_context: å¯¹è¯å†å² [{"role": "user/assistant", "content": "..."}]

        Yields:
            JSON formatted events (type: thinking/token/done/error)
        """
        import json
        from datetime import datetime
        budget = BudgetManager.from_env()
        self._set_budget(budget)
        if self.tools_module and not isinstance(self.tools_module, BudgetedTools):
            self.tools_module = BudgetedTools(self.tools_module, budget)
        self._agents = None

        thinking_steps = []  # æ”¶é›†æ€è€ƒæ­¥éª¤

        try:
            # 0. å¦‚æœæœ‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå°è¯•ä»ä¸­æå–ç›¸å…³ä¿¡æ¯
            context_summary = None
            context_ticker = None
            if conversation_context:
                context_summary, context_ticker = self._extract_context_info(conversation_context)
                if context_ticker and not tickers:
                    tickers = [context_ticker]

            # 1. å‘é€æ„å›¾åˆ†ç±»å¼€å§‹äº‹ä»¶
            step1 = {
                "stage": "classifying",
                "message": "æ­£åœ¨åˆ†æé—®é¢˜æ„å›¾...",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step1)
            yield json.dumps({"type": "thinking", **step1}, ensure_ascii=False)

            classification = self.classifier.classify(query, tickers, context_summary=context_summary)

            # 2. å‘é€æ„å›¾åˆ†ç±»å®Œæˆäº‹ä»¶
            step2 = {
                "stage": "classified",
                "message": f"æ„å›¾: {classification.intent.value}",
                "result": {
                    "intent": classification.intent.value,
                    "method": classification.method,
                    "confidence": classification.confidence,
                    "reasoning": classification.reasoning
                },
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step2)
            yield json.dumps({"type": "thinking", **step2}, ensure_ascii=False)

            if agent_gate:
                step_gate = {
                    "stage": "agent_gate",
                    "message": "è¯„ä¼°æ˜¯å¦éœ€è¦è°ƒç”¨å¤šAgent",
                    "result": agent_gate,
                    "timestamp": datetime.now().isoformat()
                }
                thinking_steps.append(step_gate)
                yield json.dumps({"type": "thinking", **step_gate}, ensure_ascii=False)

            # 3. æ‰§è¡Œå¯¹åº”å¤„ç†å™¨
            step3 = {
                "stage": "processing",
                "message": "æ­£åœ¨å¤„ç†è¯·æ±‚...",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step3)
            yield json.dumps({"type": "thinking", **step3}, ensure_ascii=False)

            # ä½¿ç”¨ asyncio.Queue å®ç°æµå¼äº‹ä»¶ç›‘å¬
            event_queue = asyncio.Queue()
            
            def event_listener(event):
                try:
                    event_queue.put_nowait(event)
                except Exception:
                    pass

            # å¼‚æ­¥æ‰§è¡Œ processï¼ŒåŒæ—¶ç›‘å¬äº‹ä»¶
            process_task = asyncio.create_task(
                self.process(query, tickers, user_profile, context_summary=context_summary, context_ticker=context_ticker, on_event=event_listener)
            )
            
            # å¾ªç¯ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ŒåŒæ—¶å¤„ç†äº‹ä»¶
            while not process_task.done():
                try:
                    # ç­‰å¾…äº‹ä»¶ï¼Œ0.05ç§’è¶…æ—¶æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                    event = await asyncio.wait_for(event_queue.get(), timeout=0.05)
                    
                    # å°†å†…éƒ¨äº‹ä»¶è½¬æ¢ä¸ºå‰ç«¯ thinking æ ¼å¼
                    evt_type = event.get("event")
                    agent_name = event.get("agent", "System")
                    step_id = event.get("step_id", "unknown")
                    timestamp = event.get("timestamp")
                    
                    msg = None
                    if evt_type == "step_start":
                        msg = f"æ­£åœ¨æ‰§è¡Œ: {agent_name or step_id}..."
                    elif evt_type == "step_done":
                        msg = f"å®Œæˆ: {agent_name or step_id}"
                    elif evt_type == "step_error":
                        msg = f"å‡ºé”™: {agent_name or step_id} ({event.get('details', {}).get('error')})"
                    elif evt_type == "step_retry":
                         msg = f"é‡è¯•: {agent_name or step_id} (æ¬¡æ•°: {event.get('details', {}).get('attempt')})"
                    elif evt_type == "agent_action":
                        msg = event.get('details', {}).get('message')
                    elif evt_type == "agent_execution":
                        details = event.get('details', {})
                        sub_type = details.get('type')
                        if sub_type == 'search_result':
                             msg = f"{agent_name}: æœç´¢åˆ° {details.get('result_count')} æ¡ç»“æœ"
                        elif sub_type == 'reflection_gap':
                             msg = f"{agent_name}: å‘ç°ä¿¡æ¯ç¼ºå¤±ï¼Œè¡¥å……æœç´¢..."
                        elif sub_type == 'convergence_final':
                             # Too detailed, skip
                             pass

                    if msg:
                        t_step = {
                            "stage": f"{step_id}_{evt_type}",
                            "message": msg,
                            "timestamp": timestamp
                        }
                        thinking_steps.append(t_step)
                        yield json.dumps({"type": "thinking", **t_step}, ensure_ascii=False)
                        
                except asyncio.TimeoutError:
                    continue
                except Exception as e:
                    logger.error(f"[process_stream] Event loop error: {e}")
            
            # è·å–ç»“æœ
            result = await process_task

            # 4. å‘é€å“åº”å†…å®¹ï¼ˆä½œä¸º token æµå¼è¾“å‡ºï¼‰
            if result.response:
                response_text = result.response
                chunk_size = 12  # ä¼˜åŒ–åˆ†å—å¤§å°ï¼Œå¹³è¡¡æµå¼æ•ˆæœå’Œæ€§èƒ½
                for i in range(0, len(response_text), chunk_size):
                    chunk = response_text[i:i + chunk_size]
                    yield json.dumps({
                        "type": "token",
                        "content": chunk
                    }, ensure_ascii=False)
                    # æ·»åŠ å°å»¶è¿Ÿï¼Œè®©å‰ç«¯æœ‰æ—¶é—´æ¸²æŸ“æ¯ä¸ª chunk
                    await asyncio.sleep(0.015)

            # 5. å‘é€å®Œæˆäº‹ä»¶
            first_ticker = None
            if classification.tickers:
                if isinstance(classification.tickers, list) and len(classification.tickers) > 0:
                    first_ticker = classification.tickers[0]
                elif isinstance(classification.tickers, dict):
                    first_ticker = list(classification.tickers.values())[0] if classification.tickers else None

            # æ·»åŠ å®Œæˆæ­¥éª¤
            step_done = {
                "stage": "complete",
                "message": "å¤„ç†å®Œæˆ",
                "timestamp": datetime.now().isoformat()
            }
            thinking_steps.append(step_done)

            # æ„å»º report æ•°æ®ï¼ˆå¦‚æœæ˜¯ REPORT æ„å›¾ï¼‰
            report_data = None
            if result.intent == Intent.REPORT:
                if result.forum_output:
                    # ä» forum_output æ„å»ºå®Œæ•´çš„ ReportIR æ ¼å¼
                    report_data = self._build_report_ir(result, first_ticker, classification)
                elif result.response and first_ticker:
                    # forum_output ä¸ºç©ºä½†æœ‰å“åº”æ–‡æœ¬ï¼Œç”Ÿæˆç®€åŒ–æŠ¥å‘Š
                    logger.warning(f"[process_stream] forum_output is None, building fallback report from response")
                    report_data = self._build_fallback_report(result, first_ticker, classification)

            # æ„å»º agent_traces ç”¨äºå‰ç«¯å±•ç¤ºè¯¦ç»†çš„ Agent æ€è€ƒæµç¨‹
            agent_traces = {}
            if result.agent_outputs:
                for agent_name, agent_output in result.agent_outputs.items():
                    trace = getattr(agent_output, 'trace', None)
                    if trace:
                        agent_traces[agent_name] = trace
                    # æ·»åŠ  Agent æ‰§è¡Œæ­¥éª¤åˆ° thinking_steps
                    agent_step = {
                        "stage": f"agent_{agent_name}",
                        "message": f"{agent_name} åˆ†æå®Œæˆ",
                        "timestamp": datetime.now().isoformat(),
                        "result": {
                            "agent": agent_name,
                            "confidence": getattr(agent_output, 'confidence', 0),
                            "summary": (getattr(agent_output, 'summary', '') or '')[:200],
                            "trace": trace or []
                        }
                    }
                    thinking_steps.insert(-1, agent_step)  # æ’å…¥åˆ° complete æ­¥éª¤ä¹‹å‰
                if agent_traces:
                    base_agents = []
                    for name in agent_traces.keys():
                        base = str(name).split("_")[0]
                        if base not in base_agents:
                            base_agents.append(base)
                    select_step = {
                        "stage": "agent_selected",
                        "message": "å·²é€‰æ‹©ä¸“å®¶Agent",
                        "timestamp": datetime.now().isoformat(),
                        "result": {"agents": base_agents, "agent_keys": list(agent_traces.keys())}
                    }
                    thinking_steps.insert(-1, select_step)

            yield json.dumps({
                "type": "done",
                "success": result.success,
                "intent": result.intent.value,
                "current_focus": first_ticker,
                "response": str(result.response) if result.response is not None else "",
                "thinking": thinking_steps,  # å‰ç«¯æœŸæœ›åœ¨ done äº‹ä»¶ä¸­æ”¶åˆ° thinking æ•°ç»„
                "agent_traces": agent_traces,  # æ–°å¢ï¼šå®Œæ•´çš„ Agent trace
                "errors": result.errors,
                "budget": result.budget,
                "report": report_data  # Phase 2: æ·±åº¦ç ”æŠ¥æ•°æ®
            }, ensure_ascii=False)

        except Exception as e:
            # æ•è·å¼‚å¸¸ï¼Œå‘é€ error äº‹ä»¶ï¼Œç¡®ä¿å‰ç«¯èƒ½æ”¶åˆ°é”™è¯¯ä¿¡æ¯
            import traceback
            traceback.print_exc()
            yield json.dumps({
                "type": "error",
                "message": f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}"
            }, ensure_ascii=False)

    def _build_report_ir(self, result: SupervisorResult, ticker: str, classification: ClassificationResult) -> dict:
        """
        å°† Supervisor ç»“æœè½¬æ¢ä¸º ReportIR æ ¼å¼ï¼ˆå‰ç«¯å¡ç‰‡å±•ç¤ºï¼‰

        é‡è¦ï¼šä¼˜å…ˆä½¿ç”¨ Forum çš„å®Œæ•´ 8 èŠ‚åˆ†æä½œä¸ºä¸»è¦å†…å®¹

        Args:
            result: SupervisorResult
            ticker: è‚¡ç¥¨ä»£ç 
            classification: æ„å›¾åˆ†ç±»ç»“æœ

        Returns:
            dict: ReportIR æ ¼å¼çš„æŠ¥å‘Šæ•°æ®
        """
        from datetime import datetime
        from backend.orchestration.data_context import DataContextCollector
        from backend.report.disclaimer import build_disclaimer_section, DISCLAIMER_TEXT
        import uuid
        import re

        def safe_str(value):
            """å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç† Timestamp ç­‰ç‰¹æ®Šç±»å‹"""
            if value is None:
                return None
            if isinstance(value, str):
                return value
            # å¤„ç† pandas Timestamp æˆ–å…¶ä»–æ—¶é—´ç±»å‹
            if hasattr(value, 'isoformat'):
                return value.isoformat()
            if hasattr(value, 'strftime'):
                return value.strftime('%Y-%m-%d %H:%M:%S')
            return str(value)

        forum_output = result.forum_output
        agent_outputs = result.agent_outputs or {}
        errors_list = result.errors or []
        agent_sections = {
            "price": {"title": "ä»·æ ¼åˆ†æ", "agent": "PriceAgent"},
            "news": {"title": "æ–°é—»åˆ†æ", "agent": "NewsAgent"},
            "technical": {"title": "æŠ€æœ¯åˆ†æ", "agent": "TechnicalAgent"},
            "fundamental": {"title": "åŸºæœ¬é¢åˆ†æ", "agent": "FundamentalAgent"},
            "macro": {"title": "å®è§‚åˆ†æ", "agent": "MacroAgent"},
            "deep_search": {"title": "æ·±åº¦æœç´¢", "agent": "DeepSearchAgent"},
        }

        def _agent_error(agent_key: str) -> Optional[str]:
            for err in errors_list:
                if isinstance(err, str) and err.startswith(f"{agent_key}:"):
                    return err.split(":", 1)[1].strip() if ":" in err else err
            return None

        context_collector = DataContextCollector()
        for agent_name, agent_output in agent_outputs.items():
            context_collector.add(
                str(agent_name),
                as_of=getattr(agent_output, 'as_of', None),
                currency=getattr(agent_output, 'currency', None),
                adjustment=getattr(agent_output, 'adjustment', None),
                ticker=ticker,
            )
        data_context = context_collector.summarize().to_dict()

        # æ„å»º sections - ä¼˜å…ˆä» Forum å®Œæ•´åˆ†æè§£æ
        sections = []
        section_order = 1

        # ä¼˜å…ˆä½¿ç”¨ forum_output.consensusï¼ˆåŸå§‹ Forum è¾“å‡ºï¼‰ï¼Œè€Œéå¯èƒ½è¢«ä¿®æ”¹çš„ result.response
        forum_text = getattr(forum_output, 'consensus', None) or result.response
        forum_sections = self._parse_forum_sections(forum_text) if forum_text else []

        if forum_sections:
            # ä½¿ç”¨ Forum è§£æå‡ºçš„ç« èŠ‚
            for fs in forum_sections:
                sections.append({
                    "title": fs["title"],
                    "order": section_order,
                    "agent_name": "ForumHost",
                    "confidence": getattr(forum_output, 'confidence', 0.7) if forum_output else 0.7,
                    "data_sources": ["multi-agent-synthesis"],
                    "contents": [{
                        "type": "text",
                        "content": fs["content"]
                    }]
                })
                section_order += 1
        else:
            # Fallback: ä»å„ Agent è¾“å‡ºæ„å»ºç« èŠ‚
            for agent_key, section_info in agent_sections.items():
                section_title = section_info["title"]
                agent_display_name = section_info["agent"]

                # æ£€æŸ¥æ˜¯å¦æœ‰è¿™ä¸ª agent çš„é”™è¯¯
                agent_error = _agent_error(agent_key)

                if agent_key in agent_outputs and agent_outputs[agent_key]:
                    agent_output = agent_outputs[agent_key]
                    if hasattr(agent_output, 'summary') and agent_output.summary:
                        confidence = getattr(agent_output, 'confidence', 0.5)
                        data_sources = getattr(agent_output, 'data_sources', [])

                        sections.append({
                            "title": section_title,
                            "order": section_order,
                            "agent_name": agent_display_name,
                            "confidence": confidence,
                            "data_sources": data_sources,
                            "contents": [{
                                "type": "text",
                                "content": safe_str(agent_output.summary)
                            }]
                        })
                        section_order += 1
                elif agent_error:
                    sections.append({
                        "title": section_title,
                        "order": section_order,
                        "agent_name": agent_display_name,
                        "confidence": 0,
                        "error": True,
                        "contents": [{
                            "type": "text",
                            "content": f"âš ï¸ {agent_display_name} æ•°æ®è·å–å¤±è´¥: {agent_error}"
                        }]
                    })
                    section_order += 1

        # æ„å»º agent çŠ¶æ€è¿½è¸ª
        disclaimer_section = build_disclaimer_section(section_order)
        sections.append(disclaimer_section)
        section_order += 1

        agent_status = {}
        for agent_key in ["price", "news", "technical", "fundamental", "macro", "deep_search"]:
            if agent_key in agent_outputs and agent_outputs[agent_key]:
                agent_output = agent_outputs[agent_key]
                confidence = getattr(agent_output, 'confidence', 0.5)
                agent_status[agent_key] = {"status": "success", "confidence": confidence}
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                agent_error = _agent_error(agent_key)
                if agent_error:
                    agent_status[agent_key] = {"status": "error", "error": agent_error}

        agent_summaries = []
        for agent_key, section_info in agent_sections.items():
            agent_output = agent_outputs.get(agent_key)
            agent_error = _agent_error(agent_key)
            if agent_output:
                status = "success"
            elif agent_error:
                status = "error"
            else:
                status = "not_run"
            summary = None
            if agent_output and getattr(agent_output, "summary", None):
                summary = safe_str(agent_output.summary)
            elif status == "not_run":
                summary = "æœªè¿è¡Œï¼ˆæœ¬è½®æœªè§¦å‘æˆ–æ— åŒ¹é…æ„å›¾ï¼‰"
            agent_summaries.append({
                "agent": agent_key,
                "agent_name": section_info["agent"],
                "title": section_info["title"],
                "summary": summary,
                "confidence": float(getattr(agent_output, "confidence", 0.0)) if agent_output else 0.0,
                "data_sources": getattr(agent_output, "data_sources", []) if agent_output else [],
                "status": status,
                "error": bool(agent_error),
                "error_message": agent_error,
            })

        # æ„å»º citations
        def _calc_freshness_hours(published_date: str) -> float:
            if not published_date:
                return 24.0
            try:
                pub_dt = datetime.fromisoformat(published_date.replace("Z", "+00:00"))
                now = datetime.now(pub_dt.tzinfo) if pub_dt.tzinfo else datetime.now()
                delta = now - pub_dt
                return max(0.0, delta.total_seconds() / 3600)
            except Exception:
                return 24.0

        citations = []
        citation_id = 1

        # Debug: è®°å½•æ¯ä¸ª Agent çš„ evidence æ•°é‡
        for agent_name, agent_output in agent_outputs.items():
            evidence_list = getattr(agent_output, 'evidence', None)
            logger.info(f"[_build_report_ir] {agent_name}: evidence_list type={type(evidence_list)}, length={len(evidence_list) if evidence_list else 0}")
            if evidence_list:
                # å¢åŠ æ¯ä¸ª Agent çš„ evidence æ•°é‡é™åˆ¶åˆ° 5 æ¡
                for evidence in evidence_list[:5]:
                    # æ›´å¥å£®çš„å±æ€§æå–
                    if isinstance(evidence, dict):
                        title = evidence.get('title') or evidence.get('source', f"{agent_name} æ¥æº")
                        url = evidence.get('url', '') or "#"
                        text = evidence.get('text', '')
                        timestamp = evidence.get('timestamp')
                        confidence = evidence.get('confidence', 0.7)
                    else:
                        title = getattr(evidence, 'title', None) or getattr(evidence, 'source', f"{agent_name} æ¥æº")
                        url = getattr(evidence, 'url', '') or "#"
                        text = getattr(evidence, 'text', '')
                        timestamp = getattr(evidence, 'timestamp', None)
                        confidence = getattr(evidence, "confidence", 0.7)

                    published_date = safe_str(timestamp)
                    try:
                        confidence = float(confidence)
                    except (TypeError, ValueError):
                        confidence = 0.7
                    confidence = max(0.0, min(1.0, confidence))
                    freshness_hours = _calc_freshness_hours(published_date)

                    # ç¡®ä¿ title å’Œ text ä¸ä¸ºç©º
                    if not title or title == "#":
                        title = f"{agent_name} Evidence {citation_id}"
                    if not text:
                        text = "No description available"

                    citation = {
                        "source_id": f"src_{citation_id}",
                        "title": safe_str(title),
                        "url": safe_str(url),
                        "snippet": safe_str(text)[:200] if text else "",
                        "published_date": published_date,
                        "confidence": confidence,
                        "freshness_hours": freshness_hours,
                    }
                    citations.append(citation)
                    logger.info(f"[_build_report_ir] Added citation {citation_id} from {agent_name}: {citation['title'][:50]}")
                    citation_id += 1

        # Debug log
        logger.info(f"[_build_report_ir] Built {len(citations)} citations from {len(agent_outputs)} agents")

        # ç¡®å®šæƒ…ç»ª
        sentiment = "neutral"
        if forum_output:
            rec = getattr(forum_output, 'recommendation', 'HOLD')
            if rec == "BUY":
                sentiment = "bullish"
            elif rec == "SELL":
                sentiment = "bearish"

        # è·å–é£é™©åˆ—è¡¨
        risks = ["å¸‚åœºæ³¢åŠ¨é£é™©", "æ•°æ®å»¶è¿Ÿé£é™©"]
        if forum_output and hasattr(forum_output, 'risks') and forum_output.risks:
            risks = [safe_str(r) for r in forum_output.risks]

        # ç”Ÿæˆæ‘˜è¦ - ä» Forum åˆ†æä¸­æå–æ‰§è¡Œæ‘˜è¦
        summary = "æŠ¥å‘Šç”Ÿæˆå®Œæˆ"
        if result.response:
            # å°è¯•æå–æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†
            exec_summary = self._extract_executive_summary(result.response)
            if exec_summary:
                summary = exec_summary
            else:
                summary = safe_str(result.response)[:500]

        # æ„å»º ReportIR
        report_ir = {
            "report_id": f"report_{uuid.uuid4().hex[:8]}",
            "ticker": safe_str(ticker) or "UNKNOWN",
            "company_name": safe_str(ticker) or "æœªçŸ¥å…¬å¸",
            "title": f"{ticker} åˆ†ææŠ¥å‘Š" if ticker else "æ·±åº¦åˆ†ææŠ¥å‘Š",
            "summary": summary,
            "sentiment": sentiment,
            "confidence_score": float(getattr(forum_output, 'confidence', 0.7)) if forum_output else 0.7,
            "generated_at": datetime.now().isoformat(),
            # ä¿å­˜ Forum çš„å®Œæ•´åŸå§‹æ–‡æœ¬ï¼ˆæ•´åˆæŠ¥å‘Šï¼‰
            "synthesis_report": forum_text if forum_text else None,
            "sections": sections,
            "citations": citations,
            "risks": risks,
            "recommendation": safe_str(getattr(forum_output, 'recommendation', 'HOLD')) if forum_output else "HOLD",
            "agent_status": agent_status,
            "errors": errors_list if errors_list else None,
            "meta": {
                "data_context": data_context,
                "disclaimer": DISCLAIMER_TEXT,
                "agent_summaries": agent_summaries,
            },
        }

        return report_ir

    def _parse_forum_sections(self, forum_text: str) -> list:
        """
        è§£æ Forum çš„ 8 èŠ‚åˆ†ææ–‡æœ¬ä¸ºç»“æ„åŒ–ç« èŠ‚
        æ”¯æŒå¤šç§æ ‡é¢˜æ ¼å¼ï¼š### 1. / ## 1. / **1.** ç­‰
        """
        import re

        if not forum_text:
            return []

        sections = []

        # å°è¯•å¤šç§æ ‡é¢˜æ¨¡å¼
        patterns = [
            r'###\s*(\d+)\.\s*([^\n]+)\n([\s\S]*?)(?=###\s*\d+\.|$)',  # ### 1. æ ‡é¢˜
            r'##\s*(\d+)\.\s*([^\n]+)\n([\s\S]*?)(?=##\s*\d+\.|$)',    # ## 1. æ ‡é¢˜
            r'\*\*(\d+)\.\s*([^\*]+)\*\*\s*\n([\s\S]*?)(?=\*\*\d+\.|$)',  # **1. æ ‡é¢˜**
        ]

        for pattern in patterns:
            matches = re.findall(pattern, forum_text)
            if matches:
                for match in matches:
                    order, title, content = match
                    # æ¸…ç†æ ‡é¢˜ä¸­çš„ emoji å’Œå¤šä½™ç©ºæ ¼
                    clean_title = re.sub(r'[ğŸ“ŠğŸ“ˆğŸ’°ğŸŒâš ï¸ğŸ¯ğŸ“ğŸ“…ğŸ”ğŸ’¡ğŸ“‰ğŸ¢]\s*', '', title).strip()
                    clean_content = content.strip()

                    if clean_title and clean_content:
                        sections.append({
                            "title": clean_title,
                            "content": clean_content
                        })
                break  # æ‰¾åˆ°åŒ¹é…çš„æ¨¡å¼ååœæ­¢

        return sections

    def _extract_executive_summary(self, forum_text: str) -> str:
        """
        ä» Forum åˆ†æä¸­æå–æ‰§è¡Œæ‘˜è¦

        Args:
            forum_text: Forum ç”Ÿæˆçš„å®Œæ•´åˆ†ææ–‡æœ¬

        Returns:
            str: æ‰§è¡Œæ‘˜è¦æ–‡æœ¬ï¼ˆæœ€å¤š 500 å­—ç¬¦ï¼‰
        """
        import re

        if not forum_text:
            return ""

        # å°è¯•åŒ¹é…æ‰§è¡Œæ‘˜è¦éƒ¨åˆ†
        patterns = [
            r'###\s*1\.\s*[ğŸ“Š]?\s*æ‰§è¡Œæ‘˜è¦[^\n]*\n([\s\S]*?)(?=###\s*2\.|$)',
            r'###\s*1\.\s*[ğŸ“Š]?\s*EXECUTIVE SUMMARY[^\n]*\n([\s\S]*?)(?=###\s*2\.|$)',
            r'\*\*æŠ•èµ„è¯„çº§\*\*[ï¼š:]\s*([^\n]+)',
            r'\*\*æ ¸å¿ƒè§‚ç‚¹\*\*[ï¼š:]\s*([^\n]+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, forum_text, re.IGNORECASE)
            if match:
                content = match.group(1).strip()
                # æˆªå–å‰ 500 å­—ç¬¦
                return content[:500] if len(content) > 500 else content

        # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šæ ¼å¼ï¼Œè¿”å›å‰ 500 å­—ç¬¦
        return forum_text[:500]

    async def analyze(self, query: str, ticker: str, user_profile: Optional[Any] = None) -> Dict[str, Any]:
        """
        å…¼å®¹æ—§ç‰ˆ AgentSupervisor çš„ analyze() æ–¹æ³•

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå•ä¸ªï¼‰
            user_profile: ç”¨æˆ·ç”»åƒ

        Returns:
            Dict with keys: forum_output, agent_outputs, errors, plan, trace, budget
        """
        # è°ƒç”¨æ–°ç‰ˆ process æ–¹æ³•
        result = await self.process(
            query=query,
            tickers=[ticker] if ticker else None,
            user_profile=user_profile
        )

        # è½¬æ¢ä¸ºæ—§æ ¼å¼
        return {
            "forum_output": result.forum_output,
            "agent_outputs": result.agent_outputs or {},
            "errors": result.errors or [],
            "plan": None,  # æ—§ç‰ˆæœ‰ planï¼Œæ–°ç‰ˆæ²¡æœ‰ï¼Œè¿”å› None
            "trace": [],   # æ—§ç‰ˆæœ‰ traceï¼Œæ–°ç‰ˆæ²¡æœ‰ï¼Œè¿”å›ç©ºåˆ—è¡¨
            "budget": result.budget,
        }

    def _build_fallback_report(self, result: SupervisorResult, ticker: str, classification: ClassificationResult) -> dict:
        """
        æ„å»ºåå¤‡æŠ¥å‘Šï¼ˆå½“ forum_output ä¸ºç©ºæ—¶ï¼‰
        
        Args:
            result: SupervisorResult
            ticker: è‚¡ç¥¨ä»£ç 
            classification: æ„å›¾åˆ†ç±»ç»“æœ
            
        Returns:
            dict: ç®€åŒ–çš„ ReportIR æ ¼å¼æŠ¥å‘Š
        """
        from datetime import datetime
        import uuid
        
        response_text = str(result.response) if result.response else "æŠ¥å‘Šç”Ÿæˆä¸­..."
        
        # ä» agent_outputs æ„å»º sections
        sections = []
        section_order = 1
        agent_outputs = result.agent_outputs or {}
        agent_sections = {
            "price": {"title": "ä»·æ ¼åˆ†æ", "agent": "PriceAgent"},
            "news": {"title": "æ–°é—»åˆ†æ", "agent": "NewsAgent"},
            "technical": {"title": "æŠ€æœ¯åˆ†æ", "agent": "TechnicalAgent"},
            "fundamental": {"title": "åŸºæœ¬é¢åˆ†æ", "agent": "FundamentalAgent"},
            "macro": {"title": "å®è§‚åˆ†æ", "agent": "MacroAgent"},
            "deep_search": {"title": "æ·±åº¦æœç´¢", "agent": "DeepSearchAgent"},
        }

        def _agent_error(agent_key: str) -> Optional[str]:
            for err in result.errors or []:
                if isinstance(err, str) and err.startswith(f"{agent_key}:"):
                    return err.split(":", 1)[1].strip() if ":" in err else err
            return None
        
        for agent_name, agent_output in agent_outputs.items():
            if hasattr(agent_output, 'summary') and agent_output.summary:
                sections.append({
                    "title": f"{agent_name.capitalize()} åˆ†æ",
                    "order": section_order,
                    "agent_name": agent_name,
                    "confidence": getattr(agent_output, 'confidence', 0.5),
                    "contents": [{
                        "type": "text",
                        "content": str(agent_output.summary)[:1000]
                    }]
                })
                section_order += 1
        
        # å¦‚æœæ²¡æœ‰ agent è¾“å‡ºï¼Œä½¿ç”¨ response ä½œä¸ºå†…å®¹
        if not sections and response_text:
            sections.append({
                "title": "åˆ†ææ‘˜è¦",
                "order": 1,
                "agent_name": "Supervisor",
                "confidence": 0.7,
                "contents": [{
                    "type": "text",
                    "content": response_text
                }]
            })

        agent_summaries = []
        for agent_key, section_info in agent_sections.items():
            agent_output = agent_outputs.get(agent_key)
            agent_error = _agent_error(agent_key)
            if agent_output:
                status = "success"
            elif agent_error:
                status = "error"
            else:
                status = "not_run"
            summary = None
            if agent_output and getattr(agent_output, 'summary', None):
                summary = str(agent_output.summary)
            elif status == "not_run":
                summary = "æœªè¿è¡Œï¼ˆæœ¬è½®æœªè§¦å‘æˆ–æ— åŒ¹é…æ„å›¾ï¼‰"
            agent_summaries.append({
                "agent": agent_key,
                "agent_name": section_info["agent"],
                "title": section_info["title"],
                "summary": summary,
                "confidence": float(getattr(agent_output, "confidence", 0.0)) if agent_output else 0.0,
                "data_sources": getattr(agent_output, "data_sources", []) if agent_output else [],
                "status": status,
                "error": bool(agent_error),
                "error_message": agent_error,
            })
        
        # æ„å»º citationsï¼ˆè¯æ®æ± ï¼‰
        citations = []
        citation_id = 1
        for agent_name, agent_output in agent_outputs.items():
            evidence_list = getattr(agent_output, 'evidence', None) if agent_output else None
            if not evidence_list:
                continue
            for evidence in evidence_list[:5]:
                if isinstance(evidence, dict):
                    title = evidence.get('title') or evidence.get('source', f"{agent_name} æ¥æº")
                    url = evidence.get('url', '') or "#"
                    text = evidence.get('text', '')
                    timestamp = evidence.get('timestamp')
                    confidence = evidence.get('confidence', 0.7)
                else:
                    title = getattr(evidence, 'title', None) or getattr(evidence, 'source', f"{agent_name} æ¥æº")
                    url = getattr(evidence, 'url', '') or "#"
                    text = getattr(evidence, 'text', '')
                    timestamp = getattr(evidence, 'timestamp', None)
                    confidence = getattr(evidence, 'confidence', 0.7)

                if not title:
                    title = f"{agent_name} Evidence {citation_id}"
                citation = {
                    "source_id": f"src_{citation_id}",
                    "title": str(title),
                    "url": str(url),
                    "snippet": str(text)[:200] if text else "",
                    "published_date": str(timestamp) if timestamp else "",
                    "confidence": float(confidence) if confidence is not None else 0.7,
                    "freshness_hours": 24.0,
                }
                citations.append(citation)
                citation_id += 1

        # æ„å»º agent_status
        agent_status = {}
        for agent_name in ["price", "news", "technical", "fundamental", "macro", "deep_search"]:
            if agent_name in agent_outputs:
                agent_output = agent_outputs[agent_name]
                agent_status[agent_name] = {
                    "status": "success",
                    "confidence": getattr(agent_output, 'confidence', 0.5)
                }
            else:
                agent_error = _agent_error(agent_name)
                if agent_error:
                    agent_status[agent_name] = {"status": "error", "error": agent_error}
        
        return {
            "report_id": f"fallback_{uuid.uuid4().hex[:8]}",
            "ticker": ticker or "UNKNOWN",
            "company_name": ticker or "æœªçŸ¥å…¬å¸",
            "title": f"{ticker} åˆ†ææŠ¥å‘Š" if ticker else "åˆ†ææŠ¥å‘Š",
            "summary": response_text[:500] if response_text else "åˆ†æå®Œæˆ",
            "sentiment": "neutral",
            "confidence_score": 0.6,
            "generated_at": datetime.now().isoformat(),
            "synthesis_report": response_text,
            "sections": sections,
            "citations": citations,
            "risks": ["æ•°æ®å¯èƒ½ä¸å®Œæ•´"],
            "recommendation": "HOLD",
            "agent_status": agent_status,
            "meta": {
                "is_fallback": True,
                "errors": result.errors,
                "agent_summaries": agent_summaries
            }
        }
