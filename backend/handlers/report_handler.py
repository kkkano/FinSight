# -*- coding: utf-8 -*-
"""
ReportHandler - æ·±åº¦æŠ¥å‘Šå¤„ç†å™¨
ç”Ÿæˆä¸“ä¸šçš„æŠ•èµ„åˆ†æžæŠ¥å‘Š
"""

import sys
import os
import logging
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime
from backend.orchestration.data_context import DataContextCollector

logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)


class ReportHandler:
    """
    æ·±åº¦æŠ¥å‘Šå¤„ç†å™¨
    
    ç”¨äºŽç”Ÿæˆä¸“ä¸šæŠ•èµ„æŠ¥å‘Šï¼š
    - å®Œæ•´çš„æ•°æ®æ”¶é›†æµç¨‹
    - ç»“æž„åŒ–çš„æŠ¥å‘Šæ ¼å¼
    - 800+ å­—çš„è¯¦ç»†åˆ†æž
    
    å“åº”æ—¶é—´ç›®æ ‡: 30-60 ç§’
    """
    
    def __init__(self, agent=None, orchestrator=None, llm=None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            agent: LangChain Agent å®žä¾‹ï¼ˆç”¨äºŽå®Œæ•´åˆ†æžæµç¨‹ï¼‰
            orchestrator: ToolOrchestrator å®žä¾‹
            llm: LLM å®žä¾‹
        """
        self.agent = agent
        self.orchestrator = orchestrator
        self.llm = llm
        self._init_tools()
    
    def _init_tools(self):
        """åˆå§‹åŒ–å·¥å…·å‡½æ•°"""
        # ä¼˜å…ˆä»Ž orchestrator èŽ·å– tools_module
        if self.orchestrator and self.orchestrator.tools_module:
            self.tools_module = self.orchestrator.tools_module
            logger.info("[ReportHandler] ä»Ž orchestrator èŽ·å– tools æ¨¡å—")
            return
        
        # å›žé€€ï¼šç›´æŽ¥å¯¼å…¥
        try:
            from backend import tools
            self.tools_module = tools
            logger.info("[ReportHandler] æˆåŠŸä»Ž backend.tools å¯¼å…¥")
        except ImportError:
            try:
                import tools
                self.tools_module = tools
                logger.info("[ReportHandler] æˆåŠŸä»Ž tools å¯¼å…¥")
            except ImportError as e:
                self.tools_module = None
                logger.info(f"[ReportHandler] è­¦å‘Š: æ— æ³•å¯¼å…¥ tools æ¨¡å—: {e}")
    
    def _run_deepsearch(self, query: str, ticker: str):
        """Run DeepSearchAgent synchronously and return AgentOutput (or None)."""
        if not self.llm or not self.tools_module or not self.orchestrator:
            return None
        try:
            from backend.agents.deep_search_agent import DeepSearchAgent

            cache = getattr(self.orchestrator, "cache", None)
            circuit_breaker = getattr(self.orchestrator, "circuit_breaker", None)
            agent = DeepSearchAgent(self.llm, cache, self.tools_module, circuit_breaker)
            logger.info(f"[ReportHandler] DeepSearch start: {ticker}")
            result = asyncio.run(agent.research(query, ticker))
            logger.info(f"[ReportHandler] DeepSearch done: evidence={len(getattr(result, 'evidence', []))}")
            return result
        except Exception as e:
            logger.info(f"[ReportHandler] DeepSearch failed: {e}")
            return None

    def _serialize_evidence(self, evidence: List[Any]) -> List[Dict[str, Any]]:
        items: List[Dict[str, Any]] = []
        for ev in evidence or []:
            try:
                items.append({
                    "title": getattr(ev, "title", None),
                    "text": getattr(ev, "text", ""),
                    "source": getattr(ev, "source", ""),
                    "url": getattr(ev, "url", None),
                    "timestamp": getattr(ev, "timestamp", None),
                    "confidence": getattr(ev, "confidence", None),
                    "meta": getattr(ev, "meta", {}) or {},
                })
            except Exception:
                continue
        return items

    def _serialize_agent_output(self, output: Any) -> Dict[str, Any]:
        if not output:
            return {}
        return {
            "agent_name": getattr(output, "agent_name", ""),
            "summary": getattr(output, "summary", ""),
            "confidence": getattr(output, "confidence", None),
            "data_sources": getattr(output, "data_sources", []),
            "as_of": getattr(output, "as_of", None),
            "fallback_used": getattr(output, "fallback_used", False),
            "risks": getattr(output, "risks", []),
            "evidence": self._serialize_evidence(getattr(output, "evidence", [])),
            "trace": getattr(output, "trace", []),
        }

    def _format_news_payload(self, news_data: Any, ticker: str) -> str:
        if not news_data:
            return ""
        if isinstance(news_data, list):
            formatter = getattr(self.tools_module, "format_news_items", None) if self.tools_module else None
            if formatter:
                return formatter(news_data, title=f"Latest News ({ticker})")
            lines = []
            for item in news_data:
                if isinstance(item, dict):
                    title = item.get("headline") or item.get("title") or "No title"
                    lines.append(f"- {title}")
            return "\n".join(lines)
        return str(news_data)

    def _build_citations_from_evidence(self, evidence: List[Any], prefix: str) -> List[Dict[str, Any]]:
        citations: List[Dict[str, Any]] = []
        seen = set()
        idx = 1
        for ev in evidence or []:
            if isinstance(ev, dict):
                url = ev.get("url") or ""
                title = ev.get("title") or ev.get("text") or "Source"
                snippet = ev.get("text") or ""
                published_date = ev.get("timestamp") or ""
                confidence = ev.get("confidence", 0.7)
            else:
                url = getattr(ev, "url", None) or ""
                title = getattr(ev, "title", None) or getattr(ev, "text", "") or "Source"
                snippet = getattr(ev, "text", "") or ""
                published_date = getattr(ev, "timestamp", "") or ""
                confidence = getattr(ev, "confidence", 0.7)
            if not url or url in seen:
                continue
            seen.add(url)
            # Calculate freshness_hours from published_date
            freshness_hours = 24.0  # default
            if published_date:
                try:
                    from datetime import datetime
                    pub_dt = datetime.fromisoformat(published_date.replace("Z", "+00:00"))
                    delta = datetime.now(pub_dt.tzinfo) - pub_dt if pub_dt.tzinfo else datetime.now() - pub_dt
                    freshness_hours = max(0.0, delta.total_seconds() / 3600)
                except Exception:
                    pass
            citations.append({
                "source_id": f"{prefix}-{idx}",
                "title": title[:160],
                "url": url,
                "snippet": snippet[:260],
                "published_date": published_date,
                "confidence": float(confidence) if confidence else 0.7,
                "freshness_hours": freshness_hours,
            })
            idx += 1
        return citations

    def handle(
        self, 
        query: str, 
        metadata: Dict[str, Any],
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†æŠ¥å‘Šç”Ÿæˆè¯·æ±‚
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            metadata: æå–çš„å…ƒæ•°æ®
            context: å¯¹è¯ä¸Šä¸‹æ–‡
            
        Returns:
            å“åº”å­—å…¸ï¼ŒåŒ…å«å®Œæ•´çš„åˆ†æžæŠ¥å‘Š
        """
        tickers = metadata.get('tickers', [])
        explicit_company = bool(metadata.get('company_names') or metadata.get('company_mentions'))
        company_hint = None
        if explicit_company:
            if metadata.get('company_names'):
                company_hint = metadata.get('company_names')[0]
            elif metadata.get('company_mentions'):
                company_hint = metadata.get('company_mentions')[0]

        if explicit_company and not tickers and company_hint:
            if self.tools_module and hasattr(self.tools_module, 'resolve_company_ticker'):
                try:
                    resolution = self.tools_module.resolve_company_ticker(company_hint)
                    matches = resolution.get('matches') if isinstance(resolution, dict) else []
                    if matches:
                        if len(matches) == 1 and matches[0].get('symbol'):
                            tickers = [matches[0]['symbol']]
                            metadata['tickers'] = tickers
                            metadata['ticker_resolution'] = resolution
                        else:
                            selected = self._select_candidate_by_hint(query, matches, context)
                            if selected and selected.get('symbol'):
                                tickers = [selected['symbol']]
                                metadata['tickers'] = tickers
                                metadata['ticker_resolution'] = resolution
                                matches = []
                            if matches:
                                options = []
                                for item in matches[:5]:
                                    symbol = item.get('symbol') if isinstance(item, dict) else str(item)
                                    desc = item.get('description') if isinstance(item, dict) else ''
                                    line = '- ' + symbol
                                    if desc:
                                        line += ' (' + desc + ')'
                                    options.append(line)
                                return {
                                    'success': True,
                                    'response': 'æˆ‘æ‰¾åˆ°äº†å¤šä¸ªå¯èƒ½çš„è‚¡ç¥¨ä»£ç ï¼Œå’Œâ€œ' + str(company_hint) + 'â€ç›¸å…³ï¼Œè¯·ç¡®è®¤ä¸€ä¸ªï¼š\n' + '\n'.join(options) + '\n\nä½ ä¹Ÿå¯ä»¥ç›´æŽ¥è¯´â€œç¾Žè‚¡/æ³•è‚¡/æ¸¯è‚¡/è‹±è‚¡â€ç­‰å¸‚åœºåå¥½ã€‚',
                                    'needs_clarification': True,
                                    'intent': 'report',
                                }
                except Exception as e:
                    logger.info('[ReportHandler] ticker lookup failed: ' + str(e))

        if not tickers and context and context.current_focus and not explicit_company:
            tickers = [context.current_focus]

        if not tickers:
            return {
                'success': True,
                'response': self._generate_clarification_response(metadata),
                'needs_clarification': True,
                'intent': 'report',
            }
        
        ticker = tickers[0]
        
        # æ³¨æ„ï¼šä¹‹å‰è¿™é‡Œæœ‰ä¸€ä¸ª"ç¡®è®¤æœºåˆ¶"ï¼Œè¯¢é—®ç”¨æˆ·æƒ³åˆ†æžå“ªäº›æ–¹é¢
        # ä½†è¿™ä¸ªæœºåˆ¶æœ‰é—®é¢˜ï¼šç”¨æˆ·è¾“å…¥æ•°å­—ï¼ˆå¦‚"6"ï¼‰åŽï¼Œä¼šè¢« LLM è·¯ç”±å™¨
        # è¯†åˆ«ä¸º FOLLOWUP æ„å›¾è€Œéž REPORTï¼Œå¯¼è‡´èµ°é”™è¯¯çš„å¤„ç†è·¯å¾„
        # å› æ­¤ç›´æŽ¥åˆ é™¤ï¼Œç”Ÿæˆå®Œæ•´çš„ç»¼åˆåˆ†æžæŠ¥å‘Š

        
        # ä¼˜å…ˆä½¿ç”¨çŽ°æœ‰çš„ Agent è¿›è¡Œå®Œæ•´åˆ†æž
        if self.agent:
            try:
                return self._handle_with_agent(ticker, query, context)
            except Exception as e:
                logger.info(f"[ReportHandler] Agent å¤„ç†å¤±è´¥ï¼Œå›žé€€åˆ°æ•°æ®æ”¶é›†æ¨¡å¼: {e}")
                # ç»§ç»­æ‰§è¡Œå›žé€€é€»è¾‘
        
        # å¦‚æžœæ²¡æœ‰ Agent æˆ– Agent å¤±è´¥ï¼Œä½¿ç”¨æ•°æ®æ”¶é›† + LLM ç”Ÿæˆ
        if self.llm and self.tools_module:
            try:
                return self._handle_with_data_collection(ticker, query, context)
            except Exception as e:
                logger.info(f"[ReportHandler] LLM æ•°æ®æ”¶é›†æ¨¡å¼å¤±è´¥: {e}")
                # ç»§ç»­æ‰§è¡Œæœ€ç»ˆå›žé€€é€»è¾‘
        
        # æœ€ç»ˆå›žé€€ï¼šä½¿ç”¨ orchestrator æˆ– tools_module ç›´æŽ¥æ”¶é›†æ•°æ®ï¼Œç”Ÿæˆç®€åŒ–æŠ¥å‘Š
        if self.orchestrator or self.tools_module:
            try:
                return self._handle_with_basic_data_collection(ticker, query, context)
            except Exception as e:
                logger.info(f"[ReportHandler] åŸºç¡€æ•°æ®æ”¶é›†å¤±è´¥: {e}")
        
        return {
            'success': False,
            'response': "æŠ¥å‘Šç”Ÿæˆå™¨æš‚ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚\n\nå¯èƒ½çš„åŽŸå› ï¼š\n1. LLM æœªæ­£ç¡®åˆå§‹åŒ–\n2. å·¥å…·æ¨¡å—æœªåŠ è½½\n3. æ•°æ®æºä¸å¯ç”¨\n\nè¯·æ£€æŸ¥åŽç«¯æ—¥å¿—èŽ·å–è¯¦ç»†ä¿¡æ¯ã€‚",
            'error': 'agent_not_available',
            'intent': 'report',
        }
    
    def _handle_with_agent(
        self,
        ticker: str,
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨çŽ°æœ‰ Agent è¿›è¡Œå®Œæ•´åˆ†æž (Phase 2 Upgrade: Supervisor + Forum + ReportIR)"""
        logger.info(f"[ReportHandler._handle_with_agent] å¼€å§‹å¤„ç† ticker={ticker}")
        try:
            # Phase 2 Supervisor è°ƒç”¨ - æš‚æ—¶ç¦ç”¨
            # åŽŸå› ï¼šasyncio.run() ä¸èƒ½åœ¨ FastAPI çš„äº‹ä»¶å¾ªçŽ¯ä¸­è°ƒç”¨
            # çœŸæ­£çš„è§£å†³æ–¹æ¡ˆéœ€è¦å¼‚æ­¥åŒ–æ•´ä¸ªè°ƒç”¨é“¾ï¼ˆConversationAgent -> ReportHandler -> Supervisorï¼‰
            # è¿™æ˜¯ Phase 2 é‡æž„ä»»åŠ¡ï¼Œç›®å‰ç›´æŽ¥ä½¿ç”¨ Legacy Logicï¼ˆself.agent.analyzeï¼‰
            use_supervisor = False  # æš‚æ—¶ç¦ç”¨
            
            if use_supervisor:
                from backend.orchestration.supervisor import AgentSupervisor
                from backend.services.memory import UserProfile
                from backend.report.ir import ReportIR
                from backend.report.validator import ReportValidator

                # åˆå§‹åŒ– Supervisor
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬é‡ç”¨ self.llm å’Œ self.tools_module
                # å¦‚æžœæ²¡æœ‰ Supervisor å®žä¾‹ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª
                if not hasattr(self, 'supervisor') or not self.supervisor:
                    # èŽ·å–ç¼“å­˜å’Œç†”æ–­å™¨ (å¦‚æžœ orchestrator æœ‰)
                    cache = getattr(self.orchestrator, 'cache', None)
                    circuit_breaker = getattr(self.orchestrator, 'circuit_breaker', None)

                    self.supervisor = AgentSupervisor(
                        llm=self.llm,
                        tools_module=self.tools_module,
                        cache=cache,
                        circuit_breaker=circuit_breaker
                    )

                # å‡†å¤‡ç”¨æˆ·ç”»åƒ (ä»Ž context èŽ·å–ï¼Œæš‚ä¸º Mock)
                user_profile = UserProfile(
                    user_id="current_user",
                    risk_tolerance="medium",
                    investment_style="balanced"
                )

                # æ‰§è¡Œåˆ†æž (Supervisor -> Forum -> Output)
                analysis_result = asyncio.run(self.supervisor.analyze(query, ticker, user_profile))
                forum_output = analysis_result.get("forum_output")

                # æž„å»º ReportIR (ç®€å•è½¬æ¢ï¼Œå®žé™…åº”ç”±ä¸“é—¨çš„ Mapper å®Œæˆ)
                report_ir = self._convert_to_report_ir(
                    ticker,
                    query,
                    forum_output,
                    analysis_result.get("agent_outputs"),
                )

                # æ ¡éªŒ IR
                report_ir_dict = ReportValidator.validate_and_fix(report_ir)

                return {
                    'success': True,
                    'response': forum_output.consensus, # ç®€çŸ­æ–‡æœ¬å›žå¤
                    'data': analysis_result,
                    'report': report_ir_dict, # å…³é”®ï¼šè¿”å›žç»“æž„åŒ–æŠ¥å‘Šæ•°æ®ä¾›å‰ç«¯æ¸²æŸ“
                    'intent': 'report',
                    'method': 'supervisor_v2',
                }

            # Legacy Logic (åŽŸæœ‰çš„ Agent è°ƒç”¨)
            # æž„å»ºåˆ†æžæŸ¥è¯¢
            analysis_query = f"è¯·å¯¹ {ticker} è¿›è¡Œæ·±åº¦æŠ•èµ„åˆ†æž"
            if query != analysis_query:
                analysis_query = query  # ä½¿ç”¨åŽŸå§‹æŸ¥è¯¢

            # è°ƒç”¨ Agent
            result = self.agent.analyze(analysis_query)
            deepsearch_output = self._run_deepsearch(analysis_query, ticker)
            deepsearch_payload = self._serialize_agent_output(deepsearch_output) if deepsearch_output else {}
            citations = (
                self._build_citations_from_evidence(getattr(deepsearch_output, "evidence", []), "DS")
                if deepsearch_output else []
            )

            if isinstance(result, dict):
                output = result.get('output', '')
                success = result.get('success', False)

                # ç¼“å­˜åˆ†æžç»“æžœåˆ°ä¸Šä¸‹æ–‡
                if context and success:
                    context.cache_data(f'report:{ticker}', output)

                # ç”Ÿæˆ ReportIR ä¾›å‰ç«¯æ¸²æŸ“
                report_ir = self._generate_simple_report_ir(
                    ticker,
                    output,
                    citations=citations,
                    meta={"deep_search": deepsearch_payload} if deepsearch_payload else {},
                )
                data_payload = result
                if deepsearch_payload:
                    data_payload = dict(result)
                    data_payload["deep_search"] = deepsearch_payload
                
                return {
                    'success': success,
                    'response': output,
                    'data': data_payload,
                    'report': report_ir,  # å…³é”®ï¼šæ·»åŠ  report å­—æ®µ
                    'intent': 'report',
                    'method': 'agent',
                }
            else:
                output_str = str(result)
                report_ir = self._generate_simple_report_ir(
                    ticker,
                    output_str,
                    citations=citations,
                    meta={"deep_search": deepsearch_payload} if deepsearch_payload else {},
                )
                
                return {
                    'success': True,
                    'response': output_str,
                    'data': {"deep_search": deepsearch_payload} if deepsearch_payload else {},
                    'report': report_ir,  # å…³é”®ï¼šæ·»åŠ  report å­—æ®µ
                    'intent': 'report',
                    'method': 'agent',
                }

        except Exception as e:
            return {
                'success': False,
                'response': f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'report',
            }

    def _convert_to_report_ir(
        self,
        ticker: str,
        query: str,
        forum_output: Any,
        agent_outputs: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """å°† ForumOutput è½¬æ¢ä¸º ReportIR å­—å…¸ (Helper)"""
        from datetime import datetime
        from backend.report.validator import ReportValidator
        from backend.orchestration.data_context import DataContextCollector
        from backend.orchestration.trace import normalize_trace

        # Use os.linesep to avoid syntax errors with literal newlines in strings
        # This is safer than embedding newlines directly in source code
        risk_list_str = os.linesep.join([f"- {r}" for r in forum_output.risks])
        risk_text = f"é£Žé™©å› ç´ :{os.linesep}{risk_list_str}"

        citations: List[Dict[str, Any]] = []
        agent_traces: Dict[str, Any] = {}
        context_collector = DataContextCollector()
        if agent_outputs and isinstance(agent_outputs, dict):
            for name, output in agent_outputs.items():
                prefix = str(name).upper()[:2] if name else "AG"
                citations.extend(self._build_citations_from_evidence(getattr(output, "evidence", []), prefix))
                trace = getattr(output, "trace", None)
                if trace:
                    agent_traces[name] = normalize_trace(trace, name)
                context_collector.add(
                    str(name or "agent"),
                    as_of=getattr(output, "as_of", None),
                    ticker=ticker,
                )

        data_context = context_collector.summarize().to_dict()
        report = {
            "report_id": f"rpt_{ticker}_{int(datetime.now().timestamp())}",
            "ticker": ticker,
            "company_name": ticker, # æš‚ç”¨ Ticker ä»£æ›¿
            "title": f"{ticker} Investment Analysis",
            "summary": forum_output.consensus,
            "sentiment": "bullish" if "BUY" in forum_output.recommendation else "bearish" if "SELL" in forum_output.recommendation else "neutral",
            "confidence_score": forum_output.confidence,
            "generated_at": datetime.now().isoformat(),
            "sections": [
                {
                    "title": "æ ¸å¿ƒè§‚ç‚¹ (Consensus)",
                    "order": 1,
                    "contents": [{"type": "text", "content": forum_output.consensus}]
                },
                {
                    "title": "åˆ†æ­§ä¸Žé£Žé™© (Disagreement & Risks)",
                    "order": 2,
                    "contents": [
                        {"type": "text", "content": forum_output.disagreement},
                        {"type": "text", "content": risk_text}
                    ]
                },
                {
                    "title": "æŠ•èµ„å»ºè®® (Recommendation)",
                    "order": 3,
                    "contents": [{"type": "text", "content": f"å»ºè®®: {forum_output.recommendation}"}]
                }
            ],
            "citations": citations,
            "risks": forum_output.risks,
            "recommendation": forum_output.recommendation,
            "meta": {
                "agent_traces": agent_traces,
                "data_context": data_context,
            } if (agent_traces or agent_outputs) else {"data_context": data_context},
        }
        return ReportValidator.validate_and_fix(report, as_dict=True)
    
    def _handle_with_data_collection(
        self,
        ticker: str,
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨æ•°æ®æ”¶é›† + LLM ç”ŸæˆæŠ¥å‘Š"""
        try:
            # 1. æ”¶é›†æ•°æ®
            collected_data = self._collect_data(ticker, context)
            
            if not collected_data.get('price'):
                return {
                    'success': False,
                    'response': f"æ— æ³•èŽ·å– {ticker} çš„åŸºæœ¬æ•°æ®ï¼ŒæŠ¥å‘Šç”Ÿæˆå¤±è´¥ã€‚",
                    'error': 'data_collection_failed',
                    'intent': 'report',
                }
            
            # 2. ä½¿ç”¨ LLM ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report_with_llm(ticker, collected_data, query)
            
            # 3. ç¼“å­˜æŠ¥å‘Š
            if context:
                context.cache_data(f'report:{ticker}', report)
            
            # 4. ç”Ÿæˆ ReportIR ä¾›å‰ç«¯æ¸²æŸ“
            report_ir = self._generate_simple_report_ir(
                ticker,
                report,
                meta={"data_context": collected_data.get("data_context")},
            )
            
            return {
                'success': True,
                'response': report,
                'data': collected_data,
                'report': report_ir,  # å…³é”®ï¼šæ·»åŠ  report å­—æ®µ
                'intent': 'report',
                'method': 'data_collection_llm',
            }
        
        except Exception as e:
            return {
                'success': False,
                'response': f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'report',
            }
    
    def _handle_with_basic_data_collection(
        self,
        ticker: str,
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨åŸºç¡€æ•°æ®æ”¶é›†ç”Ÿæˆç®€åŒ–æŠ¥å‘Šï¼ˆæ—  LLMï¼‰
        è¿™æ˜¯æœ€ç»ˆå›žé€€æ–¹æ¡ˆ
        """
        try:
            # 1. æ”¶é›†æ•°æ®
            collected_data = self._collect_data(ticker, context)
            
            if not collected_data.get('price'):
                return {
                    'success': False,
                    'response': f"æ— æ³•èŽ·å– {ticker} çš„åŸºæœ¬æ•°æ®ï¼ŒæŠ¥å‘Šç”Ÿæˆå¤±è´¥ã€‚",
                    'error': 'data_collection_failed',
                    'intent': 'report',
                }
            
            # 2. ç”Ÿæˆç®€åŒ–æŠ¥å‘Šï¼ˆä¸ä½¿ç”¨ LLMï¼‰
            report = self._generate_fallback_report(ticker, collected_data)
            
            # 3. ç¼“å­˜æŠ¥å‘Š
            if context:
                context.cache_data(f'report:{ticker}', report)
            
            # 4. ç”Ÿæˆ ReportIR ä¾›å‰ç«¯æ¸²æŸ“
            report_ir = self._generate_simple_report_ir(
                ticker,
                report,
                meta={"data_context": collected_data.get("data_context")},
            )
            
            return {
                'success': True,
                'response': report,
                'data': collected_data,
                'report': report_ir,  # å…³é”®ï¼šæ·»åŠ  report å­—æ®µ
                'intent': 'report',
                'method': 'basic_data_collection',
            }
        
        except Exception as e:
            return {
                'success': False,
                'response': f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'report',
            }
    
    def _collect_data(self, ticker: str, context: Optional[Any] = None) -> Dict[str, Any]:
        """æ”¶é›†åˆ†æžæ‰€éœ€çš„æ•°æ®"""
        data = {
            'ticker': ticker,
            'timestamp': datetime.now().isoformat(),
        }
        context_collector = DataContextCollector()
        
        # 1. èŽ·å–ä»·æ ¼
        try:
            if self.orchestrator:
                result = self.orchestrator.fetch('price', ticker)
                if result.success:
                    data['price'] = result.data
                    data['price_source'] = result.source
                    context_collector.add(
                        "price",
                        data=result.data,
                        as_of=getattr(result, "as_of", None),
                        ticker=ticker,
                    )
            elif self.tools_module:
                price_payload = self.tools_module.get_stock_price(ticker)
                data['price'] = price_payload
                context_collector.add("price", data=price_payload, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] èŽ·å–ä»·æ ¼å¤±è´¥: {e}")
        
        # 2. èŽ·å–å…¬å¸ä¿¡æ¯
        try:
            if self.tools_module:
                data['company_info'] = self.tools_module.get_company_info(ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] èŽ·å–å…¬å¸ä¿¡æ¯å¤±è´¥: {e}")
        
        # 3. èŽ·å–æ–°é—»
        try:
            if self.tools_module:
                raw_news = self.tools_module.get_company_news(ticker)
                data['news_raw'] = raw_news
                data['news'] = self._format_news_payload(raw_news, ticker)
                context_collector.add("news", data=raw_news, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] èŽ·å–æ–°é—»å¤±è´¥: {e}")
        
        # 4. èŽ·å–å¸‚åœºæƒ…ç»ª
        try:
            if self.tools_module:
                sentiment_payload = self.tools_module.get_market_sentiment()
                data['sentiment'] = sentiment_payload
                context_collector.add("sentiment", data=sentiment_payload, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] èŽ·å–æƒ…ç»ªå¤±è´¥: {e}")
        
        # 5. èŽ·å–è¡¨çŽ°å¯¹æ¯” (YTD/1Y)
        try:
            if self.tools_module and hasattr(self.tools_module, "get_performance_comparison"):
                benchmark = os.getenv("DEFAULT_BENCHMARK_TICKER", "").strip()
                benchmark_label = os.getenv("DEFAULT_BENCHMARK_LABEL", "").strip() or benchmark
                tickers_map = {ticker: ticker}
                if benchmark and benchmark.lower() not in ("none", "off", "false", "0"):
                    tickers_map[benchmark_label] = benchmark
                perf_payload = self.tools_module.get_performance_comparison(tickers_map)
                data["performance_comparison"] = perf_payload
                context_collector.add("performance", data=perf_payload, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] èŽ·å–è¡¨çŽ°å¯¹æ¯”å¤±è´¥: {e}")

        # 6. åŽ†å²å›žæ’¤åˆ†æž
        try:
            if self.tools_module and hasattr(self.tools_module, "analyze_historical_drawdowns"):
                drawdown_payload = self.tools_module.analyze_historical_drawdowns(ticker)
                data["drawdown_analysis"] = drawdown_payload
                context_collector.add("drawdown", data=drawdown_payload, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] åŽ†å²å›žæ’¤åˆ†æžå¤±è´¥: {e}")

        # 7. æœç´¢ä¸Šä¸‹æ–‡è¡¥å……
        try:
            if self.tools_module:
                search_payload = self.tools_module.search(
                    f"{ticker} stock analysis latest news {datetime.now().strftime('%B %Y')}"
                )

                data['search_context'] = search_payload

                context_collector.add("search", data=search_payload, ticker=ticker)
        except Exception as e:
            logger.info(f"[ReportHandler] æœç´¢å¤±è´¥: {e}")
        
        data["data_context"] = context_collector.summarize().to_dict()
        return data
    
    def _generate_report_with_llm(
        self, 
        ticker: str, 
        data: Dict[str, Any],
        original_query: str
    ) -> str:
        """ä½¿ç”¨ LLM ç”ŸæˆæŠ¥å‘Š"""
        from langchain_core.messages import HumanMessage
        from backend.prompts.system_prompts import REPORT_SYSTEM_PROMPT
        
        # æž„å»ºæ•°æ®æ‘˜è¦
        data_summary = self._format_data_for_llm(data)
        
        # å¡«å……æç¤ºè¯
        current_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        prompt = REPORT_SYSTEM_PROMPT.format(
            current_date=current_date,
            query=original_query,
            accumulated_data=data_summary,
            tools="(æ•°æ®å·²é¢„å…ˆæ”¶é›†)"
        )
        
        # æ·»åŠ ç”ŸæˆæŒ‡ä»¤
        prompt += f"""

Based on the collected data above, generate a comprehensive investment analysis report for {ticker}.

The report MUST:
1. Be at least 800 words
2. Include all mandatory sections
3. Reference specific data points
4. Provide actionable recommendations

BEGIN REPORT:"""

        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            return response.content
        except Exception as e:
            # ç”Ÿæˆç®€åŒ–æŠ¥å‘Š
            return self._generate_fallback_report(ticker, data)
    
    def _format_data_for_llm(self, data: Dict[str, Any]) -> str:
        """Format collected data for the LLM prompt."""
        sections = []

        if data.get('price'):
            sections.append(f"## Price Data\n{data['price']}")

        if data.get('company_info'):
            sections.append(f"## Company Information\n{data['company_info']}")

        if data.get('news'):
            sections.append(f"## Recent News\n{data['news']}")

        if data.get('sentiment'):
            sections.append(f"## Market Sentiment\n{data['sentiment']}")

        if data.get('performance_comparison'):
            sections.append(f"## Performance Comparison\n{data['performance_comparison']}")

        if data.get('drawdown_analysis'):
            sections.append(f"## Drawdown Analysis\n{data['drawdown_analysis']}")

        if data.get('search_context'):
            # Limit search preview to 500 chars.
            search_preview = data['search_context'][:500] + "..." if len(data['search_context']) > 500 else data['search_context']
            sections.append(f"## Additional Context\n{search_preview}")

        return "\n\n".join(sections)

    def _generate_fallback_report(self, ticker: str, data: Dict[str, Any]) -> str:
        """Generate a simplified fallback report."""
        from backend.report.disclaimer import DISCLAIMER_TITLE, DISCLAIMER_TEXT
        current_date = datetime.now().strftime("%Y-%m-%d")

        report = f"""# {ticker} - Investment Analysis Report
*Report Date: {current_date}*

## EXECUTIVE SUMMARY

This is a simplified analysis report for {ticker}. Due to technical limitations, a full AI-generated analysis could not be completed.

## CURRENT MARKET POSITION

"""
        if data.get('price'):
            report += f"{data['price']}\n\n"
        else:
            report += "Price data unavailable.\n\n"

        if data.get('company_info'):
            report += f"## COMPANY PROFILE\n\n{data['company_info']}\n\n"

        if data.get('news'):
            report += f"## RECENT NEWS\n\n{data['news']}\n\n"

        if data.get('sentiment'):
            report += f"## MARKET SENTIMENT\n\n{data['sentiment']}\n\n"

        report += f"""## {DISCLAIMER_TITLE}

{DISCLAIMER_TEXT}

---
*Generated by FinSight AI*
"""
        return report

    def _generate_simple_report_ir(
        self,
        ticker: str,
        content: str,
        citations: Optional[List[Dict[str, Any]]] = None,
        meta: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        Build a minimal ReportIR from legacy markdown report content.
        """
        import re
        from backend.report.validator import ReportValidator
        from backend.report.disclaimer import build_disclaimer_section, DISCLAIMER_TEXT

        # Collect sections from markdown.
        sections = []

        # Split Markdown headings (## / ###).
        section_pattern = r'^#{2,3}\s+(.+?)$'
        parts = re.split(section_pattern, content, flags=re.MULTILINE)

        order = 1
        for i in range(1, len(parts), 2):
            if i + 1 < len(parts):
                title = parts[i].strip()
                body = parts[i + 1].strip()
                if title and body:
                    sections.append({
                        "title": title,
                        "order": order,
                        "contents": [{"type": "text", "content": body}]
                    })
                    order += 1

        # If no sections detected, fallback to a single section.
        if not sections:
            sections = [{
                "title": "Overview",
                "order": 1,
                "contents": [{"type": "text", "content": content[:2000]}]
            }]
            order = 2

        disclaimer_section = build_disclaimer_section(order)
        sections.append(disclaimer_section)

        # Extract summary from the first paragraph (200 chars).
        first_para = content.split('\n\n')[0] if '\n\n' in content else content[:200]
        summary = first_para[:300] + "..." if len(first_para) > 300 else first_para

        # Infer sentiment from content.
        content_lower = content.lower()
        if any(kw in content_lower for kw in ['bullish', 'çœ‹æ¶¨', 'åˆ©å¥½', 'buy', 'ä¹°å…¥', 'å¢žæŒ', 'ä¸Šæ¶¨', 'å¼ºåŠ¿']):
            sentiment = 'bullish'
        elif any(kw in content_lower for kw in ['bearish', 'çœ‹è·Œ', 'åˆ©ç©º', 'sell', 'å–å‡º', 'å‡æŒ', 'ä¸‹è·Œ', 'å¼±åŠ¿']):
            sentiment = 'bearish'
        else:
            sentiment = 'neutral'

        report = {
            "report_id": f"rpt_{ticker}_{int(datetime.now().timestamp())}",
            "ticker": ticker,
            "company_name": ticker,
            "title": f"{ticker} æŠ•èµ„åˆ†æžæŠ¥å‘Š",
            "summary": summary,
            "sentiment": sentiment,
            "confidence_score": 0.75,  # Default confidence
            "generated_at": datetime.now().isoformat(),
            "sections": sections,
            "citations": citations or [],
            "risks": [],
            "recommendation": "HOLD",
            "meta": {**(meta or {}), "disclaimer": DISCLAIMER_TEXT},
        }
        return ReportValidator.validate_and_fix(report, as_dict=True)

    def _generate_pre_analysis_question(self, ticker: str, original_query: str) -> str:
        """
        ç”Ÿæˆåˆ†æžå‰çš„ç¡®è®¤é—®é¢˜ï¼Œæ”¹è¿›å¯¹è¯ä½“éªŒ
        """
        return f"""å¥½çš„ï¼Œæˆ‘å‡†å¤‡ä¸ºæ‚¨ç”Ÿæˆ **{ticker}** çš„æ·±åº¦åˆ†æžæŠ¥å‘Šã€‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹æ‚¨æœ€å…³å¿ƒçš„æ–¹é¢ï¼Œè¿™æ ·æˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›æ›´æœ‰é’ˆå¯¹æ€§çš„åˆ†æžï¼š

**æ‚¨å¸Œæœ›æˆ‘é‡ç‚¹å…³æ³¨å“ªäº›æ–¹é¢ï¼Ÿ**

1. ðŸ“ˆ **ä»·æ ¼èµ°åŠ¿å’ŒæŠ€æœ¯åˆ†æž** - Kçº¿å›¾ã€æŠ€æœ¯æŒ‡æ ‡ã€æ”¯æ’‘é˜»åŠ›ä½
2. ðŸ’¼ **åŸºæœ¬é¢åˆ†æž** - è´¢åŠ¡æ•°æ®ã€ç›ˆåˆ©èƒ½åŠ›ã€ä¼°å€¼æ°´å¹³
3. ðŸ“° **æ–°é—»å’Œäº‹ä»¶** - æœ€æ–°åŠ¨æ€ã€å¸‚åœºæƒ…ç»ªã€å‚¬åŒ–å‰‚
4. âš ï¸ **é£Žé™©è¯„ä¼°** - æ½œåœ¨é£Žé™©ã€æ³¢åŠ¨æ€§åˆ†æž
5. ðŸ’¡ **æŠ•èµ„ç­–ç•¥** - è¿›å‡ºåœºå»ºè®®ã€ç›®æ ‡ä»·ä½
6. ðŸ“Š **ç»¼åˆå…¨é¢åˆ†æž** - ä»¥ä¸Šæ‰€æœ‰æ–¹é¢ï¼ˆå®Œæ•´æŠ¥å‘Šï¼‰

æ‚¨å¯ä»¥ç›´æŽ¥è¯´æ•°å­—ï¼ˆå¦‚"1"æˆ–"1å’Œ3"ï¼‰ï¼Œæˆ–è€…æè¿°æ‚¨çš„éœ€æ±‚ï¼ˆå¦‚"é‡ç‚¹å…³æ³¨ä»·æ ¼èµ°åŠ¿å’Œé£Žé™©"ï¼‰ã€‚

å¦‚æžœä¸éœ€è¦ç‰¹åˆ«æŒ‡å®šï¼Œæˆ‘ä¹Ÿå¯ä»¥ç›´æŽ¥ç”Ÿæˆ**ç»¼åˆå…¨é¢åˆ†æžæŠ¥å‘Š**ã€‚æ‚¨å¸Œæœ›å¦‚ä½•ç»§ç»­ï¼Ÿ"""
    
    def _generate_clarification_response(self, metadata: Optional[Dict[str, Any]] = None) -> str:
        """ç”Ÿæˆæ¾„æ¸…è¯·æ±‚"""
        metadata = metadata or {}
        company_names = metadata.get('company_names') or []
        hint_line = ""
        if company_names:
            hint_line = f"æˆ‘è¯†åˆ«åˆ°å¯èƒ½çš„å…¬å¸åï¼š{company_names[0]}ã€‚å¦‚æžœæ˜¯å®ƒï¼Œè¯·ç¡®è®¤å¹¶ç»™å‡ºè‚¡ç¥¨ä»£ç ã€‚\n\n"

        return f"""ä¸ºäº†ç”Ÿæˆæ·±åº¦æŠ¥å‘Šï¼Œè¯·å‘Šè¯‰æˆ‘å…·ä½“æ ‡çš„ã€‚

{hint_line}ä½ å¯ä»¥æä¾›ï¼š
1. è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ AAPL, TSLA, NVDAï¼‰
2. å…¬å¸åç§°ï¼ˆå¦‚ è‹¹æžœ/ç‰¹æ–¯æ‹‰/è‹±ä¼Ÿè¾¾ï¼‰
3. æŒ‡æ•°æˆ– ETFï¼ˆå¦‚ æ ‡æ™®500/çº³æ–¯è¾¾å…‹100/SPYï¼‰

ç¤ºä¾‹ï¼š
- "åˆ†æž AAPL"
- "åšä¸€ä»½ç‰¹æ–¯æ‹‰ç ”æŠ¥"
- "æ ‡æ™®500 æ·±åº¦åˆ†æž"

è¯·å‘Šè¯‰æˆ‘è¦åˆ†æžçš„ç›®æ ‡ã€‚"""

    def _select_candidate_by_hint(
        self,
        query: str,
        candidates: List[Dict[str, Any]],
        context: Optional[Any] = None
    ) -> Optional[Dict[str, Any]]:
        market_hint = self._extract_market_hint(query)
        if not market_hint and context is not None:
            market_hint = getattr(context, "market_preference", None)
        if not market_hint:
            return None
        for item in candidates:
            if self._candidate_matches_market(item, market_hint):
                return item
        return None

    def _extract_market_hint(self, query: str) -> Optional[str]:
        lowered = query.lower()
        hint_map = {
            "US": ["ç¾Žå›½", "ç¾Žè‚¡", "nyse", "nasdaq", "otc", "adr", "us", "u.s"],
            "FR": ["æ³•å›½", "æ³•è‚¡", "å·´é»Ž", "euronext", "paris", ".pa"],
            "UK": ["è‹±å›½", "è‹±è‚¡", "ä¼¦æ•¦", "lse", "london", ".l"],
            "HK": ["é¦™æ¸¯", "æ¸¯è‚¡", "hkex", ".hk"],
            "CN": ["ä¸­å›½", "aè‚¡", "æ²ª", "æ·±", "ä¸Šè¯", "æ·±è¯", "sse", "szse", ".ss", ".sz"],
            "JP": ["æ—¥æœ¬", "æ—¥è‚¡", "ä¸œäº¬", "tse", ".t"],
            "EU": ["æ¬§æ´²", "æ¬§è‚¡", "eu", "euronext"],
        }
        for market, keys in hint_map.items():
            for key in keys:
                if key.isascii():
                    if key in lowered:
                        return market
                else:
                    if key in query:
                        return market
        return None

    def _candidate_matches_market(self, candidate: Dict[str, Any], market: str) -> bool:
        symbol = (candidate.get("symbol") or "").upper()
        exchange = (candidate.get("primaryExchange") or "").upper()
        description = (candidate.get("description") or "").upper()
        blob = f"{symbol} {exchange} {description}"

        if market == "US":
            return any(tag in blob for tag in ["NYSE", "NASDAQ", "OTC", "US", "ADR"]) or symbol.endswith(".US")
        if market == "FR":
            return any(tag in blob for tag in ["PAR", "EURONEXT", "PARIS"]) or symbol.endswith(".PA")
        if market == "UK":
            return any(tag in blob for tag in ["LSE", "LONDON"]) or symbol.endswith(".L")
        if market == "HK":
            return any(tag in blob for tag in ["HK", "HKEX"]) or symbol.endswith(".HK")
        if market == "CN":
            return any(tag in blob for tag in ["SSE", "SZSE", "SHANGHAI", "SHENZHEN"]) or symbol.endswith((".SS", ".SZ"))
        if market == "JP":
            return any(tag in blob for tag in ["TSE", "TOKYO"]) or symbol.endswith(".T")
        if market == "EU":
            return "EURONEXT" in blob or symbol.endswith(".PA")
        return False
