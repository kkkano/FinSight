# -*- coding: utf-8 -*-
"""
ChatHandler - å¿«é€Ÿå¯¹è¯å¤„ç†å™¨
å¤„ç†ç®€å•é—®é¢˜ï¼Œæä¾›å¿«é€Ÿç®€æ´çš„å›ç­”

æ ¸å¿ƒä¿®å¤ç‚¹:
1. ä¿®å¤äº† _handle_chat_query çš„ AttributeErrorã€‚
2. ç§»é™¤äº† _is_chat_query ä¸­çš„é‡å¤é€»è¾‘ã€‚
3. ä¼˜åŒ–äº† handle æ–¹æ³•ä¸­ query_lower çš„å®šä¹‰ï¼Œé¿å…å†—ä½™ã€‚
"""

import sys
import os
import random
import traceback
from typing import Dict, Any, Optional, List
from datetime import datetime

# å°è¯•å¯¼å…¥ LangChain æ ¸å¿ƒæ¨¡å—ï¼ˆå‡è®¾å·²å®‰è£…ï¼‰
try:
    from langchain_core.messages import HumanMessage
    LANGCHAIN_AVAILABLE = True
except ImportError:
    LANGCHAIN_AVAILABLE = False
    print("[ChatHandler] Warning: langchain_core not found. LLM features disabled.")


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)


class ChatHandler:
    """
    å¿«é€Ÿå¯¹è¯å¤„ç†å™¨
    
    ç”¨äºå¤„ç†ç®€å•é—®é¢˜å¦‚ï¼šè‚¡ä»·æŸ¥è¯¢ã€ç®€å•çš„å¸‚åœºçŠ¶å†µã€å¿«é€Ÿé—®ç­”
    å“åº”æ—¶é—´ç›®æ ‡: < 10 ç§’
    å“åº”é•¿åº¦: 2-5 å¥è¯
    """
    
    def __init__(self, llm=None, orchestrator=None):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            llm: LLM å®ä¾‹ (ä¾‹å¦‚ LangChain Runnable)
            orchestrator: ToolOrchestrator å®ä¾‹
        """
        self.llm = llm
        self.orchestrator = orchestrator
        self.tools_module = None
        self._init_tools()
    
    def _init_tools(self):
        """åˆå§‹åŒ–å·¥å…·å‡½æ•°"""
        # ä¼˜å…ˆä» orchestrator è·å– tools_module
        if self.orchestrator and hasattr(self.orchestrator, 'tools_module') and self.orchestrator.tools_module:
            self.tools_module = self.orchestrator.tools_module
            print("[ChatHandler] ä» orchestrator è·å– tools æ¨¡å—")
            return
        
        # å›é€€ï¼šç›´æ¥å¯¼å…¥
        try:
            # å‡è®¾ tools æ¨¡å—åœ¨ backend/tools.py æˆ–é¡¹ç›®æ ¹ç›®å½•
            from backend import tools
            self.tools_module = tools
            print("[ChatHandler] æˆåŠŸä» backend.tools å¯¼å…¥")
        except ImportError:
            try:
                import tools
                self.tools_module = tools
                print("[ChatHandler] æˆåŠŸä» tools å¯¼å…¥")
            except ImportError as e:
                self.tools_module = None
                print(f"[ChatHandler] è­¦å‘Š: æ— æ³•å¯¼å…¥ tools æ¨¡å—: {e}")
    
    def handle(
        self, 
        query: str, 
        metadata: Dict[str, Any],
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†æŸ¥è¯¢
        """
        query_lower = query.lower() # ç¡®ä¿åœ¨ handle å¼€å§‹å¤„ç»Ÿä¸€å®šä¹‰
        
        try:
            tickers = metadata.get('tickers', [])
            if not tickers and context and hasattr(context, 'current_focus') and context.current_focus:
                tickers = [context.current_focus]
            primary_ticker = tickers[0] if tickers else None

            # ä¼˜å…ˆå¤„ç†æ–°é—»æ„å›¾ï¼šæœ‰ ticker ç›´æ¥æ‹‰æ–°é—»ï¼›æ—  ticker å…ˆç”¨å¸‚åœºæ³›åŒ–æ–°é—»ï¼Œå†å…œåº•é»˜è®¤æŒ‡æ•°
            if self._is_news_query(query_lower):
                if primary_ticker:
                    return self._handle_news_query(primary_ticker, query, context)
                if self.tools_module and hasattr(self.tools_module, "get_market_news_headlines"):
                    try:
                        news_text = self.tools_module.get_market_news_headlines()
                        return {
                            'success': True,
                            'response': news_text,
                            'intent': 'market_news',
                            'data': {'raw_news': news_text}
                        }
                    except Exception as e:
                        print(f"[ChatHandler] market news fallback failed: {e}")
                default_news_ticker = os.getenv("DEFAULT_NEWS_TICKER", "^GSPC")
                return self._handle_news_query(default_news_ticker, query, context)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¯¹æ¯”æŸ¥è¯¢
            if metadata.get('is_comparison') and len(tickers) >= 2:
                return self._handle_comparison_query(tickers, query, metadata, context)
            
            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨ä»£ç ï¼Œå°è¯•ä»ä¸Šä¸‹æ–‡è·å–
            if not tickers and context and hasattr(context, 'current_focus') and context.current_focus:
                tickers = [context.current_focus]
            
            if not tickers:
                print(f"[ChatHandler] æ£€æŸ¥é—²èŠ/å»ºè®®æ„å›¾: Query='{query_lower}'")
                
                # æ–°é—»ç±»æ—  ticker æŸ¥è¯¢ï¼šé»˜è®¤ç”¨å¤§ç›˜æŒ‡æ•°
                if self._is_news_query(query_lower):
                    default_news_ticker = os.getenv("DEFAULT_NEWS_TICKER", "^GSPC")
                    return self._handle_news_query(default_news_ticker, query, context)
                
                if self._is_advice_query(query_lower):
                    print("[ChatHandler] âœ… å‘½ä¸­æ³›åŒ–å»ºè®®æ„å›¾ï¼ˆæ—  tickerï¼‰")
                    return self._handle_generic_recommendation(query)
                
                if self._is_chat_query(query_lower):
                    print("[ChatHandler] ğŸš€ æ„å›¾å‘½ä¸­: é—²èŠ/é—®å€™ã€‚")
                    return self._handle_chat_query(query)
                
                print("[ChatHandler] âš ï¸ æ„å›¾æœªå‘½ä¸­: é—²èŠã€‚å›é€€åˆ°é€šç”¨æœç´¢ã€‚")
                return self._handle_with_search(query, context)
            
            # è·å–ç¬¬ä¸€ä¸ªè‚¡ç¥¨çš„ä¿¡æ¯ (å¦‚æœ tickers æœ‰å†…å®¹)
            ticker = primary_ticker or (tickers[0] if tickers else None)
            if not ticker and context and hasattr(context, 'current_focus') and context.current_focus:
                ticker = context.current_focus
            
            # åˆ¤æ–­æŸ¥è¯¢ç±»å‹å¹¶è·å–ç›¸åº”æ•°æ®
            if self._is_composition_query(query_lower):
                # æˆåˆ†è‚¡/æŒä»“æŸ¥è¯¢
                return self._handle_composition_query(ticker, query, context)
            elif self._is_advice_query(query_lower):
                # æŠ•èµ„å»ºè®®æŸ¥è¯¢
                return self._handle_advice_query(ticker, query, context)
            elif self._is_price_query(query_lower):
                return self._handle_price_query(ticker, query, context)
            elif self._is_news_query(query_lower):
                return self._handle_news_query(ticker, query, context)
            elif self._is_info_query(query_lower):
                return self._handle_info_query(ticker, query, context)
            else:
                # é»˜è®¤ï¼šå¦‚æœæœ‰ä¸Šä¸‹æ–‡ç„¦ç‚¹ï¼Œå°è¯•è·å–ä»·æ ¼ï¼›å¦åˆ™ä½¿ç”¨LLMå›ç­”ï¼ˆé€šå¸¸æ˜¯å»ºè®®ï¼‰
                if context and hasattr(context, 'current_focus') and context.current_focus:
                    return self._handle_price_query(ticker, query, context)
                else:
                    return self._handle_advice_query(ticker, query, context)
            
        except Exception as e:
            traceback.print_exc()
            return {
                'success': False,
                'response': f"ç³»ç»Ÿå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'error',
                'thinking': f"Critical Error in ChatHandler: {str(e)}"
            }
    
    # --- æ„å›¾åˆ¤æ–­ ---
    
    def _is_price_query(self, query: str) -> bool:
        keywords = ['ä»·æ ¼', 'è‚¡ä»·', 'å¤šå°‘é’±', 'ç°ä»·', 'price', 'how much', 'æ¶¨', 'è·Œ', 'è¡Œæƒ…', 'èµ°åŠ¿', 'è¡¨ç°']
        return any(kw in query for kw in keywords)
    
    def _is_news_query(self, query: str) -> bool:
        keywords = ['æ–°é—»', 'æ¶ˆæ¯', 'news', 'æœ€æ–°', 'å‘ç”Ÿ', 'äº‹ä»¶', 'è¿‘å‡ å¤©', 'æœ€è¿‘', 'å¤´æ¡', 'headline']
        return any(kw in query for kw in keywords)
    
    def _is_info_query(self, query: str) -> bool:
        keywords = ['å…¬å¸', 'ç®€ä»‹', 'company', 'info', 'ä¿¡æ¯', 'ä»‹ç»', 'æ˜¯ä»€ä¹ˆ']
        return any(kw in query for kw in keywords)
    
    def _is_composition_query(self, query: str) -> bool:
        keywords = ['åŒ…æ‹¬å“ªäº›', 'åŒ…å«å“ªäº›', 'æˆåˆ†è‚¡', 'æˆåˆ†', 'æŒä»“', 'æœ‰å“ªäº›', 'å“ªäº›è‚¡ç¥¨', 'å“ªäº›å…¬å¸', 
                     'constituent', 'holdings', 'components', 'includes', 'contains']
        return any(kw in query for kw in keywords)
    
    def _is_advice_query(self, query: str) -> bool:
        keywords = ['æ¨è', 'å»ºè®®', 'æ€ä¹ˆåš', 'å¦‚ä½•', 'åº”è¯¥', 'æŠ•èµ„', 'ä¹°å…¥', 'å–å‡º', 'æŒæœ‰', 'advice', 'recommend', 'should', 
                     'å®šæŠ•', 'ç­–ç•¥', 'æ“ä½œ', 'æ¥ä¸‹æ¥', 'è¿™å‡ å¤©', 'è¿™å‡ ä¸ªæœˆ', 'æ€ä¹ˆåŠ', 'æ€ä¹ˆ', 'ä¿æŒ', 'æœ€è¿‘', 'ç°åœ¨']
        return any(kw in query for kw in keywords)
        
    def _is_chat_query(self, query_lower: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•çš„é—²èŠæˆ–é—®å€™è¯­"""
        greeting_keywords = ['ä½ å¥½', 'æ‚¨å¥½', 'å–‚', 'å—¨', 'hello', 'hi']
        identity_keywords = ['ä½ æ˜¯è°', 'ä½ å«ä»€ä¹ˆ', 'ä»‹ç»è‡ªå·±', 'è‡ªæˆ‘ä»‹ç»']
        
        # å®½æ¾åŒ¹é…ï¼Œç§»é™¤æ‰€æœ‰ç©ºæ ¼åè¿›è¡ŒåŒ¹é…
        cleaned_query = query_lower.replace(' ', '').replace('...', '').replace('ï¼Ÿ', '').replace('?', '')
        
        # 1. æ£€æŸ¥é—®å€™è¯­
        if any(kw in query_lower for kw in greeting_keywords):
            return True
            
        # 2. æ£€æŸ¥èº«ä»½æŸ¥è¯¢ (ä½¿ç”¨æ¸…ç†åçš„è¾“å…¥æé«˜å‡†ç¡®æ€§)
        if any(kw in cleaned_query for kw in identity_keywords):
            return True

        # 3. å¦‚æœæŸ¥è¯¢å¾ˆçŸ­ä¸”æ²¡æœ‰ä»»ä½•è‚¡ç¥¨ä»£ç /æŒ‡æ ‡ï¼Œä¹Ÿå¯èƒ½æ˜¯é—²èŠ
        if len(query_lower) < 15 and any(kw in query_lower for kw in ['è°¢è°¢', 'å†è§', 'å¥½çš„']):
            return True

        return False
        
    # --- æ ¸å¿ƒå¤„ç†æ–¹æ³• ---
    
    def _handle_chat_query(self, query: str) -> Dict[str, Any]:
        """
        å¤„ç†ç®€å•çš„é—²èŠå’Œé—®å€™ï¼ˆä¾‹å¦‚ï¼šä½ å¥½ï¼Œä½ æ˜¯è°ï¼Œè°¢è°¢ï¼‰ã€‚
        """
        if any(kw in query for kw in ['ä½ å¥½', 'æ‚¨å¥½', 'å–‚', 'å—¨', 'hello', 'hi']):
            response = "ä½ å¥½ï¼æˆ‘æ˜¯ä¸€ä¸ªé‡‘èæ™ºèƒ½åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®æ‚¨æŸ¥è¯¢è‚¡ç¥¨ä»·æ ¼ã€åˆ†æèµ°åŠ¿æˆ–ç”Ÿæˆæ·±åº¦æŠ¥å‘Šã€‚è¯·é—®æ‚¨æƒ³äº†è§£å“ªæ”¯è‚¡ç¥¨ï¼Ÿ"
        elif any(kw in query for kw in ['ä½ æ˜¯è°', 'ä½ å«ä»€ä¹ˆ', 'ä»‹ç»è‡ªå·±', 'è‡ªæˆ‘ä»‹ç»']):
            response = "æˆ‘å« FinSight Agentï¼Œæ˜¯ä¸“ä¸ºé‡‘èå¸‚åœºè®¾è®¡çš„äººå·¥æ™ºèƒ½ã€‚æˆ‘å¯ä»¥å®æ—¶è·å–æ•°æ®ï¼Œå¹¶åˆ©ç”¨ LLM å¸®æ‚¨è§£è¯»å¤æ‚çš„å¸‚åœºä¿¡æ¯ã€‚è¯·å¼€å§‹æé—®å§ï¼"
        elif any(kw in query for kw in ['è°¢è°¢', 'å†è§', 'å¥½çš„', 'ok', 'bye']):
            response = "ä¸å®¢æ°”ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼å¦‚æœæ‚¨è¿˜æœ‰å…¶ä»–é‡‘èé—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ã€‚å†è§ï¼"
        else:
            response = "å¾ˆé«˜å…´ä¸æ‚¨äº¤æµï¼è¯·é—®æœ‰ä»€ä¹ˆé‡‘èç›¸å…³çš„é—®é¢˜æˆ‘å¯ä»¥å¸®å¿™çš„å—ï¼Ÿ"

        return {
            'success': True,
            'response': response,
            'intent_detail': 'greeting_chat',
            'metadata': {},
        }
        
    def _handle_price_query(
        self, 
        ticker: str, 
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†ä»·æ ¼æŸ¥è¯¢"""
        # ä¼˜å…ˆä½¿ç”¨ Orchestrator (å‡è®¾ Orchestrator å·²ç»å¤„ç†äº†ç¼“å­˜/å›é€€é€»è¾‘)
        if self.orchestrator and hasattr(self.orchestrator, 'fetch'):
            try:
                result = self.orchestrator.fetch('price', ticker)
                if result and result.success:
                    price_data = result.data
                    response = self._format_price_response(ticker, price_data, result.source)
                    
                    if context and hasattr(context, 'cache_data'):
                        context.cache_data(f'price:{ticker}', price_data)
                    
                    return {
                        'success': True,
                        'response': response,
                        'data': {
                            'ticker': ticker,
                            'raw_price': price_data,
                            'source': result.source,
                            'data_origin': result.source,
                            'fallback_used': getattr(result, 'fallback_used', False),
                            'tried_sources': getattr(result, 'tried_sources', []),
                            'trace': getattr(result, 'trace', {}),
                            'as_of': getattr(result, 'as_of', None),
                        },
                        'intent': 'market_data',
                        'thinking': f"Fetched price via Orchestrator (Source: {result.source}, fallback_used={getattr(result, 'fallback_used', False)})"
                    }
                elif result:
                    return {
                        'success': False,
                        'response': f"æ— æ³•è·å– {ticker} çš„ä»·æ ¼ä¿¡æ¯: {result.error}",
                        'error': result.error,
                        'intent': 'chat',
                        'thinking': f"Orchestrator failed to fetch price: {result.error}"
                    }
            except Exception as e:
                traceback.print_exc()
                print(f"[ChatHandler] Orchestrator price fetch failed: {e}")
        
        # å›é€€åˆ°ç›´æ¥è°ƒç”¨ tools
        if self.tools_module and hasattr(self.tools_module, 'get_stock_price'):
            try:
                # å‡è®¾ get_stock_price è¿”å›å­—ç¬¦ä¸²æˆ–å­—å…¸
                price_info = self.tools_module.get_stock_price(ticker)
                return {
                    'success': True,
                    'response': price_info,
                    'data': {'ticker': ticker, 'raw_price': price_info},
                    'intent': 'market_data',
                    'thinking': "Fetched price via direct tools module."
                }
            except Exception as e:
                traceback.print_exc()
                return {
                    'success': False,
                    'response': f"è·å– {ticker} ä»·æ ¼æ—¶å‡ºé”™: {str(e)}",
                    'error': str(e),
                    'intent': 'chat',
                    'thinking': f"Direct tool call for price failed: {str(e)}"
                }
        
        return {
            'success': False,
            'response': "ä»·æ ¼æŸ¥è¯¢å·¥å…·æš‚ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥åç«¯é…ç½®ã€‚",
            'error': 'tool_not_available',
            'intent': 'chat',
            'thinking': "No price fetching tool available."
        }
    
    def _handle_news_query(
        self, 
        ticker: str, 
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†æ–°é—»æŸ¥è¯¢"""
        if self.tools_module and hasattr(self.tools_module, 'get_company_news'):
            try:
                news_info = self.tools_module.get_company_news(ticker)
                
                if context and hasattr(context, 'cache_data'):
                    context.cache_data(f'news:{ticker}', news_info)
                
                return {
                    'success': True,
                    'response': news_info,
                    'data': {'ticker': ticker, 'raw_news': news_info},
                    'intent': 'company_news',
                    'thinking': "Fetched company news via tools module."
                }
            except Exception as e:
                traceback.print_exc()
                return {
                    'success': False,
                    'response': f"è·å– {ticker} æ–°é—»æ—¶å‡ºé”™: {str(e)}",
                    'error': str(e),
                    'intent': 'chat',
                    'thinking': f"Tool call for news failed: {str(e)}"
                }
        
        return {
            'success': False,
            'response': "æ–°é—»æŸ¥è¯¢å·¥å…·æš‚ä¸å¯ç”¨ã€‚",
            'error': 'tool_not_available',
            'intent': 'chat',
            'thinking': "No news fetching tool available."
        }
    
    def _handle_info_query(
        self, 
        ticker: str, 
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†å…¬å¸ä¿¡æ¯æŸ¥è¯¢"""
        if self.tools_module and hasattr(self.tools_module, 'get_company_info'):
            try:
                info = self.tools_module.get_company_info(ticker)
                
                if context and hasattr(context, 'cache_data'):
                    context.cache_data(f'info:{ticker}', info)
                
                return {
                    'success': True,
                    'response': info,
                    'data': {'ticker': ticker, 'raw_info': info},
                    'intent': 'company_info',
                    'thinking': "Fetched company info via tools module."
                }
            except Exception as e:
                traceback.print_exc()
                return {
                    'success': False,
                    'response': f"è·å– {ticker} å…¬å¸ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}",
                    'error': str(e),
                    'intent': 'chat',
                    'thinking': f"Tool call for company info failed: {str(e)}"
                }
        
        return {
            'success': False,
            'response': "å…¬å¸ä¿¡æ¯æŸ¥è¯¢å·¥å…·æš‚ä¸å¯ç”¨ã€‚",
            'error': 'tool_not_available',
            'intent': 'chat',
            'thinking': "No company info tool available."
        }
    
    def _handle_composition_query(
        self,
        ticker: str,
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†æˆåˆ†è‚¡/æŒä»“æŸ¥è¯¢ï¼ˆä½¿ç”¨æœç´¢å·¥å…·ï¼‰"""
        
        if not self.tools_module or not hasattr(self.tools_module, 'search'):
            return {
                'success': False,
                'response': "æœç´¢å·¥å…·æš‚ä¸å¯ç”¨ï¼Œæ— æ³•æŸ¥è¯¢æˆåˆ†è‚¡ä¿¡æ¯ã€‚",
                'error': 'tool_not_available',
                'intent': 'chat',
                'thinking': "No search tool available for composition query."
            }

        try:
            # ä¼˜åŒ–æœç´¢æŸ¥è¯¢è¯
            query_lower = query.lower()
            if 'çº³æ–¯è¾¾å…‹' in query or 'nasdaq' in query_lower:
                search_query = "çº³æ–¯è¾¾å…‹100æŒ‡æ•° æˆåˆ†è‚¡"
            elif 'æ ‡æ™®' in query or 's&p' in query_lower:
                search_query = "æ ‡æ™®500æŒ‡æ•° æˆåˆ†è‚¡"
            else:
                search_query = f"{ticker} {query}"
            
            search_result = self.tools_module.search(search_query)
            
            # ä½¿ç”¨ LLM æ•´ç†æœç´¢ç»“æœ
            if self.llm and LANGCHAIN_AVAILABLE:
                prompt = f"""You are a professional financial analyst with expertise in stock market indices and their compositions. The user is asking about the composition/holdings of {ticker}.

User Question: {query}
Search Results: {search_result[:3000]}

**CRITICAL REQUIREMENTS - YOU MUST FOLLOW THESE EXACTLY**:
1. Extract EVERY constituent/holding mentioned in the search results.
2. For each constituent, include: Full company name (e.g., "è‹¹æœå…¬å¸"), Stock ticker symbol (e.g., AAPL), and Weight percentage if mentioned (e.g., "çº¦12.5%").
3. Organize: List top holdings first (by weight if available). Use clear numbering or bullet points.
4. DO NOT provide a summary - provide a COMPREHENSIVE LIST.
5. Response must be in Chinese.
"""
                response = self.llm.invoke([HumanMessage(content=prompt)])
                
                return {
                    'success': True,
                    'response': response.content,
                    'data': {'ticker': ticker, 'query_type': 'composition', 'search_result': search_result[:500]},
                    'intent': 'search_composition',
                    'used_search': True,
                    'thinking': "Used search tool and LLM for composition analysis."
                }
            else:
                # æ²¡æœ‰ LLMï¼Œç›´æ¥è¿”å›æœç´¢ç»“æœæ‘˜è¦
                return {
                    'success': True,
                    'response': f"æ ¹æ®æœç´¢ç»“æœï¼Œå…³äº {ticker} çš„æˆåˆ†è‚¡/æŒä»“æƒ…å†µï¼š\n\n{search_result[:800]}...",
                    'data': {'ticker': ticker, 'query_type': 'composition', 'search_result': search_result[:500]},
                    'intent': 'search_composition',
                    'used_search': True,
                    'thinking': "Used search tool; no LLM for summary."
                }
        except Exception as e:
            traceback.print_exc()
            return {
                'success': False,
                'response': f"æœç´¢ {ticker} æˆåˆ†è‚¡ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'chat',
                'thinking': f"Composition search failed: {str(e)}"
            }

    def _handle_comparison_query(
        self,
        tickers: List[str],
        query: str,
        metadata: Dict[str, Any],
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†å¯¹æ¯”æŸ¥è¯¢ (ä¾‹å¦‚ "Nasdaq å’Œ S&P 500 æœ‰ä»€ä¹ˆåŒºåˆ«")"""
        ticker1, ticker2 = tickers[0], tickers[1]
        
        if self.llm and LANGCHAIN_AVAILABLE:
            try:
                # å°è¯•è·å–ä»·æ ¼ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡ (çœç•¥ Orchestrator è°ƒç”¨ç»†èŠ‚)
                price_info1, price_info2 = "N/A", "N/A"
                if self.orchestrator and hasattr(self.orchestrator, 'fetch'):
                    try:
                        result1 = self.orchestrator.fetch('price', ticker1)
                        if result1 and result1.success: price_info1 = result1.data
                        result2 = self.orchestrator.fetch('price', ticker2)
                        if result2 and result2.success: price_info2 = result2.data
                    except:
                        pass # å¿½ç•¥è·å–ä»·æ ¼æ—¶çš„å¼‚å¸¸
                
                context_info = f"\n{ticker1} Current Price: {price_info1}"
                context_info += f"\n{ticker2} Current Price: {price_info2}"
                
                # ä½¿ç”¨ LLM ç”Ÿæˆå¯¹æ¯”åˆ†æ
                prompt = f"""You are a professional financial analyst. The user wants to understand the differences between {ticker1} and {ticker2}.

User Question: {query}
{context_info}

Please provide a detailed comparison analysis, including: Key Differences (composition, sector distribution, risk) and Investment Characteristics.
Requirements: Respond in Chinese, professional but easy to understand.
"""
                response = self.llm.invoke([HumanMessage(content=prompt)])
                
                return {
                    'success': True,
                    'response': response.content,
                    'data': {'ticker1': ticker1, 'ticker2': ticker2, 'query_type': 'comparison'},
                    'intent': 'comparison_analysis',
                    'thinking': "Used LLM for comparison analysis."
                }
            except Exception as e:
                traceback.print_exc()
                print(f"[ChatHandler] LLM comparison analysis failed: {e}")
        
        # LLM æˆ– LangChain ä¸å¯ç”¨æ—¶çš„å›é€€
        return {
            'success': True,
            'response': f"å…³äº {ticker1} å’Œ {ticker2} çš„ç®€å•å¯¹æ¯”ï¼š\n\n1. **{ticker1}**: åå‘æˆé•¿å‹/ç§‘æŠ€è‚¡ã€‚\n2. **{ticker2}**: é€šå¸¸æ›´åŠ å‡è¡¡å’Œåˆ†æ•£ã€‚",
            'data': {'ticker1': ticker1, 'ticker2': ticker2, 'query_type': 'comparison'},
            'intent': 'chat',
            'thinking': "LLM/LangChain unavailable, returned basic comparison."
        }

    def _handle_advice_query(
        self, 
        ticker: str, 
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†æŠ•èµ„å»ºè®®æŸ¥è¯¢"""
        
        if not self.llm or not LANGCHAIN_AVAILABLE:
            return {
                'success': True, 
                'response': f"å…³äº {ticker}ï¼šå»ºè®®é‡‡ç”¨å®šæŠ•ç­–ç•¥ï¼Œåˆ†æ•£é£é™©ã€‚è¯·æ³¨æ„ï¼ŒæŠ•èµ„æœ‰é£é™©ã€‚",
                'intent': 'advice',
                'thinking': "LLM/LangChain unavailable, returned generic advice."
            }

        # å°è¯•è·å–å½“å‰ä»·æ ¼ä½œä¸ºå‚è€ƒï¼ˆå¯é€‰ï¼‰
        current_price_info = "N/A"
        if self.orchestrator and hasattr(self.orchestrator, 'fetch'):
            try:
                price_result = self.orchestrator.fetch('price', ticker)
                if price_result and price_result.success:
                    current_price_info = price_result.data
            except:
                pass 
        
        try:
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_info = f"\nCurrent Price Info: {current_price_info}"
            if context and hasattr(context, 'current_focus') and context.current_focus:
                context_info += f"\nCurrently Focused Asset: {context.current_focus}"
            
            # ä½¿ç”¨ LLM ç”Ÿæˆå»ºè®®
            prompt = f"""You are a professional financial investment advisor. The user is asking for investment advice regarding {ticker}.

User Question: {query}
{context_info}

**CRITICAL REQUIREMENTS - YOU MUST FOLLOW THESE EXACTLY**:
1. Understand User Intent (already invested vs preparing to invest).
2. Provide specific, actionable investment advice (e.g., continue holding, add positions, invest in 3-5 batches). 
3. Include a brief Market Analysis (2-3 sentences).
4. Include a clear Risk Warning at the end.
5. **Response MUST be in Chinese**, friendly and helpful tone.
6. Add the following required text at the end exactly: \n\nâš ï¸ **AIç”Ÿæˆå»ºè®®æç¤º**ï¼šä»¥ä¸Šå»ºè®®ç”±AIç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œè¯·æ ¹æ®è‡ªèº«æƒ…å†µè°¨æ…å†³ç­–ã€‚
"""
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            return {
                'success': True,
                'response': response.content,
                'data': {'ticker': ticker, 'query_type': 'advice', 'price_info': current_price_info},
                'intent': 'advice',
                'thinking': "Used LLM to generate specific investment advice."
            }
        except Exception as e:
            traceback.print_exc()
            return {
                'success': False,
                'response': f"ç”ŸæˆæŠ•èµ„å»ºè®®æ—¶å¤±è´¥: {str(e)}",
                'error': str(e),
                'intent': 'chat',
                'thinking': f"LLM advice generation failed: {str(e)}"
            }

    def _handle_generic_recommendation(self, query: str) -> Dict[str, Any]:
        """
        æ—  ticker çš„æ³›åŒ–æ¨èï¼Œç¡®ä¿â€œæ¨èå‡ åªè‚¡ç¥¨â€ç±»é—®é¢˜å¯ç”¨ã€‚
        """
        picks = [
            {"ticker": "NVDA", "reason": "AI ç¡¬ä»¶é¾™å¤´ï¼Œç›ˆåˆ©é«˜å¢é•¿", "risk": "ä¼°å€¼åé«˜ï¼Œæ³¢åŠ¨è¾ƒå¤§"},
            {"ticker": "MSFT", "reason": "äº‘/AI åŒé©±åŠ¨ï¼Œè®¢é˜…ä¸šåŠ¡ç¨³å®š", "risk": "å®è§‚ä¸ä¼°å€¼å‹åŠ›"},
            {"ticker": "AAPL", "reason": "æ¶ˆè´¹ç”µå­é¾™å¤´ï¼Œç°é‡‘æµç¨³å¥", "risk": "ç¡¬ä»¶å‘¨æœŸä¸ç›‘ç®¡"},
            {"ticker": "VOO", "reason": "S&P500 ETFï¼Œè¢«åŠ¨åˆ†æ•£ä½æˆæœ¬", "risk": "è·Ÿéšç¾è‚¡æ•´ä½“æ³¢åŠ¨"},
        ]
        lines = [f"- {p['ticker']}: {p['reason']}ï¼ˆé£é™©ï¼š{p['risk']}ï¼‰" for p in picks]
        response = (
            "ç¤ºä¾‹å…³æ³¨æ ‡çš„ï¼ˆéæŠ•èµ„å»ºè®®ï¼Œè¯·è‡ªè¯„é£é™©ï¼‰ï¼š\n"
            + "\n".join(lines)
            + "\n\nå»ºè®®ï¼šåˆ†æ‰¹å»ºä»“ï¼Œå•ç¥¨ä¸è¶…è¿‡æ€»ä»“ 5%-10%ï¼Œæ€»ä»“ä½æ§åˆ¶åœ¨ 50% ä»¥ä¸‹ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚"
        )
        return {
            'success': True,
            'response': response,
            'intent': 'advice',
            'thinking': "Generic recommendation fallback (no ticker).",
        }

    def _handle_with_search(
        self,
        query: str,
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """å¤„ç†é€šç”¨æœç´¢æŸ¥è¯¢æˆ–éœ€è¦æ¾„æ¸…çš„æŸ¥è¯¢"""
        
        if not self.tools_module or not hasattr(self.tools_module, 'search'):
            return {
                'success': True, # è§†ä¸ºæˆåŠŸè¿”å›æ¾„æ¸…ä¿¡æ¯
                'response': self._generate_clarification_response(query),
                'needs_clarification': True,
                'intent': 'chat',
                'thinking': "No ticker and no search tool, asked for clarification."
            }

        try:
            search_result = self.tools_module.search(query)

            if self.llm and LANGCHAIN_AVAILABLE:
                prompt = f"""You are a helpful financial assistant. Please answer the user's question based on the provided search results.

User Question: {query}
Search Results: {search_result[:3000]}

**CRITICAL REQUIREMENTS**:
1. Provide a concise and accurate answer based ONLY on the information in the search results.
2. If the search results do not contain an answer, state that you couldn't find the information.
3. Organize the information clearly.
4. Respond in Chinese.
"""
                response = self.llm.invoke([HumanMessage(content=prompt)])
                
                return {
                    'success': True,
                    'response': response.content,
                    'data': {'query_type': 'general_search', 'search_result': search_result[:500]},
                    'intent': 'general_search',
                    'used_search': True,
                    'thinking': "Used search tool and LLM for general query."
                }
            else:
                # æ²¡æœ‰ LLMï¼Œç›´æ¥è¿”å›æœç´¢ç»“æœæ‘˜è¦
                return {
                    'success': True,
                    'response': f"æ ¹æ®æœç´¢ç»“æœï¼Œå…³äº â€œ{query}â€ çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n{search_result[:800]}...",
                    'data': {'query_type': 'general_search', 'search_result': search_result[:500]},
                    'intent': 'general_search',
                    'used_search': True,
                    'thinking': "Used search tool; no LLM for summary."
                }
        except Exception as e:
            traceback.print_exc()
            return {
                'success': False,
                'response': f"æœç´¢ â€œ{query}â€ æ—¶å‡ºé”™: {str(e)}",
                'error': str(e),
                'intent': 'chat',
                'thinking': f"General search failed: {str(e)}"
            }

    # --- è¾…åŠ©æ–¹æ³• ---
    
    def _format_price_response(self, ticker: str, price_data: Any, source: str) -> str:
        """æ ¼å¼åŒ–ä»·æ ¼å“åº”"""
        if isinstance(price_data, str):
            response = price_data
            if source != 'cache':
                response += f"\n\nğŸ“Š æ•°æ®æ¥æº: {source}"
            return response
        
        if isinstance(price_data, dict):
            # å‡è®¾ price_data åŒ…å« price, change, change_percent å­—æ®µ
            price = price_data.get('price', 'N/A')
            change = price_data.get('change', 0)
            change_pct = price_data.get('change_percent', 0)
            
            # å®‰å…¨æ ¼å¼åŒ–
            try:
                price_str = f"${float(price):.2f}"
            except (ValueError, TypeError):
                price_str = str(price)

            try:
                change_str = f"{'+' if change >= 0 else ''}${float(change):.2f}"
                change_pct_str = f"{'+' if change_pct >= 0 else ''}{float(change_pct):.2f}%"
                
                emoji = "ğŸ“ˆ" if change >= 0 else "ğŸ“‰"
                # å‡è®¾éœ€è¦æ¢è¡Œç¬¦æ¥ä¿æŒæ ¼å¼åŒ–
                response = f"{emoji} {ticker} å½“å‰ä»·æ ¼: {price_str}\nå˜åŠ¨: {change_str} ({change_pct_str})"
                
                # æ·»åŠ æ•°æ®æ¥æºï¼Œé™¤éå®ƒæ˜¯ç¼“å­˜æ•°æ®
                if source != 'cache':
                    response += f"\nğŸ“Š æ•°æ®æ¥æº: {source}"
                    
                return response
            except (ValueError, TypeError):
                 return f"ğŸ’° {ticker} å½“å‰ä»·æ ¼: {price_str}"

        return str(price_data)

    def _generate_clarification_response(self, query: str) -> str:
        """Generate clarification request"""
        responses = [
            "è¯·é—®æ‚¨æƒ³äº†è§£å“ªæ”¯è‚¡ç¥¨ï¼Ÿè¯·æä¾›è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ AAPLï¼‰æˆ–å…¬å¸åç§°ã€‚",
            "æˆ‘éœ€è¦çŸ¥é“æ‚¨é—®çš„æ˜¯å“ªæ”¯è‚¡ç¥¨ã€‚è¯·å‘Šè¯‰æˆ‘è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°ï¼Œä¾‹å¦‚ 'AAPL' æˆ– 'è‹¹æœ'ã€‚",
            "æ‚¨æƒ³æŸ¥è¯¢å“ªæ”¯è‚¡ç¥¨çš„ä¿¡æ¯ï¼Ÿè¯·æä¾›è‚¡ç¥¨ä»£ç æˆ–å…¬å¸åç§°ã€‚",
        ]
        return random.choice(responses)
    
    # --- LLM å¢å¼ºæ–¹æ³•ï¼ˆä¿ç•™ï¼Œä½†é€šå¸¸ handle æ–¹æ³•å·²è¦†ç›–ï¼‰ ---

    def handle_with_llm(
        self, 
        query: str, 
        metadata: Dict[str, Any],
        context: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM å¢å¼ºçš„å¤„ç†æ–¹æ³•ï¼Œå…ˆè·å–æ•°æ®ï¼Œç„¶åè®© LLM ç”Ÿæˆè‡ªç„¶çš„å›å¤
        """
        # 1. é¦–å…ˆè·å–åŸºç¡€æ•°æ®
        basic_result = self.handle(query, metadata, context)
        
        # è¡Œæƒ…ç±»ç›´æ¥è¿”å›ï¼Œé¿å… LLM æ”¹å†™ä»·æ ¼ç»†èŠ‚
        if basic_result.get('intent') in {'price'}:
            return basic_result
        
        if not basic_result.get('success') or not self.llm or not LANGCHAIN_AVAILABLE:
            return basic_result
        
        # 2. ä½¿ç”¨ LLM ç”Ÿæˆæ›´è‡ªç„¶çš„å›å¤
        try:
            raw_response = basic_result.get('response', '')
            
            prompt = f"""ä½ æ˜¯è´¢ç»åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹â€œæ£€ç´¢ç»“æœâ€ç”¨ä¸­æ–‡ç®€æ´å›ç­”ç”¨æˆ·ã€‚ä¿æŒ 2-5 å¥æ‘˜è¦ï¼Œå¹¶ä¿ç•™æ‰€æœ‰å¯ç”¨é“¾æ¥ï¼Œæ ¼å¼ä¸º Markdown å¯ç‚¹å‡»é“¾æ¥ã€‚

ç”¨æˆ·é—®é¢˜: {query}
æ£€ç´¢ç»“æœ:
{raw_response}

è¾“å‡ºè¦æ±‚:
1) å…ˆç»™ 2-5 å¥æ‘˜è¦ï¼ŒåŒ…å«å…³é”®æ—¥æœŸã€äº‹ä»¶ã€å½±å“ã€‚
2) åœ¨æ‘˜è¦åè¿½åŠ â€œé“¾æ¥:â€å°èŠ‚ï¼Œé€æ¡åˆ—å‡ºæ£€ç´¢ç»“æœé‡Œå‡ºç°çš„ URLï¼Œä½¿ç”¨ Markdown é“¾æ¥æ ¼å¼ `[æ¥æºæˆ–URL](URL)`ï¼Œä¸ä¸¢å¤±ä»»ä½•é“¾æ¥ã€‚
3) å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆé“¾æ¥ï¼Œæ˜ç¡®è¯´æ˜â€œæš‚æ— å¯ç”¨é“¾æ¥â€ã€‚
4) ä¸è¦æåˆ°â€œæ£€ç´¢ç»“æœ/åŸæ–‡â€ç­‰å­—æ ·ã€‚
"""
            response = self.llm.invoke([HumanMessage(content=prompt)])
            
            # åˆå¹¶ LLM å¢å¼ºåçš„å†…å®¹ï¼Œä¿ç•™åŸæœ‰æ•°æ®å’Œæ„å›¾
            final_result = basic_result.copy()
            final_result['response'] = response.content
            final_result['enhanced_by_llm'] = True
            
            return final_result
        
        except Exception as e:
            traceback.print_exc()
            # LLM å¢å¼ºå¤±è´¥ï¼Œè¿”å›åŸºç¡€ç»“æœ
            return basic_result
