#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¿®å¤æ•ˆæœçš„è„šæœ¬
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

async def test_evidence_extraction():
    """æµ‹è¯•è¯æ®æ± æ•°æ®æå–"""
    print("=" * 60)
    print("æµ‹è¯• 1: è¯æ®æ± æ•°æ®æå–")
    print("=" * 60)

    from backend.agents.news_agent import NewsAgent
    from backend.agents.deep_search_agent import DeepSearchAgent
    from backend.orchestration.cache import DataCache
    from backend.tools import financial as tools_module
    from langchain_openai import ChatOpenAI

    cache = DataCache()
    llm = ChatOpenAI(temperature=0)

    # æµ‹è¯• NewsAgent
    print("\n[NewsAgent] æµ‹è¯•...")
    news_agent = NewsAgent(llm, cache, tools_module)
    news_output = await news_agent.research("AAPL news", "AAPL")

    print(f"  - Summary é•¿åº¦: {len(news_output.summary)}")
    print(f"  - Evidence æ•°é‡: {len(news_output.evidence)}")
    if news_output.evidence:
        print(f"  - ç¬¬ä¸€æ¡ Evidence:")
        ev = news_output.evidence[0]
        print(f"    * Title: {getattr(ev, 'title', 'N/A')}")
        print(f"    * Source: {getattr(ev, 'source', 'N/A')}")
        print(f"    * URL: {getattr(ev, 'url', 'N/A')}")
        print(f"    * Text: {getattr(ev, 'text', 'N/A')[:50]}...")

    # æµ‹è¯• DeepSearchAgent
    print("\n[DeepSearchAgent] æµ‹è¯•...")
    deep_agent = DeepSearchAgent(llm, cache, tools_module)
    deep_output = await deep_agent.research("AAPL investment thesis", "AAPL")

    print(f"  - Summary é•¿åº¦: {len(deep_output.summary)}")
    print(f"  - Evidence æ•°é‡: {len(deep_output.evidence)}")
    if deep_output.evidence:
        print(f"  - ç¬¬ä¸€æ¡ Evidence:")
        ev = deep_output.evidence[0]
        print(f"    * Title: {getattr(ev, 'title', 'N/A')}")
        print(f"    * Source: {getattr(ev, 'source', 'N/A')}")
        print(f"    * URL: {getattr(ev, 'url', 'N/A')}")
        print(f"    * Text: {getattr(ev, 'text', 'N/A')[:50]}...")

    print("\nâœ… è¯æ®æ± æµ‹è¯•å®Œæˆ")
    return True

async def test_streaming():
    """æµ‹è¯•æµå¼è¾“å‡º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æµå¼è¾“å‡º")
    print("=" * 60)

    from backend.orchestration.supervisor_agent import SupervisorAgent
    from backend.orchestration.cache import DataCache
    from backend.tools import financial as tools_module
    from langchain_openai import ChatOpenAI

    cache = DataCache()
    llm = ChatOpenAI(temperature=0)
    supervisor = SupervisorAgent(llm, tools_module, cache)

    print("\n[Streaming] æµ‹è¯•æµå¼è¾“å‡º...")
    token_count = 0
    chunk_sizes = []

    async for event_json in supervisor.process_stream("AAPL ä»·æ ¼", ["AAPL"]):
        import json
        try:
            event = json.loads(event_json)
            if event.get('type') == 'token':
                token_count += 1
                chunk_sizes.append(len(event.get('content', '')))
        except:
            pass

    print(f"  - Token äº‹ä»¶æ•°é‡: {token_count}")
    if chunk_sizes:
        avg_chunk = sum(chunk_sizes) / len(chunk_sizes)
        print(f"  - å¹³å‡åˆ†å—å¤§å°: {avg_chunk:.1f} å­—ç¬¦")
        print(f"  - æœ€å°åˆ†å—: {min(chunk_sizes)} å­—ç¬¦")
        print(f"  - æœ€å¤§åˆ†å—: {max(chunk_sizes)} å­—ç¬¦")

    print("\nâœ… æµå¼è¾“å‡ºæµ‹è¯•å®Œæˆ")
    return True

async def test_report_detail():
    """æµ‹è¯•æŠ¥å‘Šè¯¦ç»†åº¦"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: æŠ¥å‘Šè¯¦ç»†åº¦")
    print("=" * 60)

    from backend.orchestration.forum import ForumHost
    from langchain_openai import ChatOpenAI

    llm = ChatOpenAI(temperature=0)
    forum = ForumHost(llm)

    # æ£€æŸ¥ SYNTHESIS_PROMPT
    prompt = forum.SYNTHESIS_PROMPT

    print("\n[Forum Prompt] åˆ†æ...")
    print(f"  - Prompt æ€»é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"  - åŒ…å« 'â‰¥1500å­—': {'â‰¥1500å­—' in prompt}")
    print(f"  - åŒ…å« 'æ¯ç« èŠ‚â‰¥150å­—': {'æ¯ç« èŠ‚â‰¥150å­—' in prompt}")
    print(f"  - åŒ…å« 'quality_requirements': {'quality_requirements' in prompt}")
    print(f"  - åŒ…å« 'å…·ä½“æ•°æ®': {'å…·ä½“æ•°æ®' in prompt}")

    # æå–ç« èŠ‚è¦æ±‚
    sections = []
    for line in prompt.split('\n'):
        if line.strip().startswith('###'):
            sections.append(line.strip())

    print(f"\n  - è¦æ±‚ç« èŠ‚æ•°: {len(sections)}")
    for i, section in enumerate(sections[:3], 1):
        print(f"    {i}. {section[:50]}...")

    print("\nâœ… æŠ¥å‘Šè¯¦ç»†åº¦æµ‹è¯•å®Œæˆ")
    return True

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("FinSight ä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 60)

    results = []

    try:
        # æµ‹è¯• 1: è¯æ®æ± 
        result1 = await test_evidence_extraction()
        results.append(("è¯æ®æ± æ•°æ®æå–", result1))
    except Exception as e:
        print(f"\nâŒ è¯æ®æ± æµ‹è¯•å¤±è´¥: {e}")
        results.append(("è¯æ®æ± æ•°æ®æå–", False))

    try:
        # æµ‹è¯• 2: æµå¼è¾“å‡º
        result2 = await test_streaming()
        results.append(("æµå¼è¾“å‡º", result2))
    except Exception as e:
        print(f"\nâŒ æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        results.append(("æµå¼è¾“å‡º", False))

    try:
        # æµ‹è¯• 3: æŠ¥å‘Šè¯¦ç»†åº¦
        result3 = await test_report_detail()
        results.append(("æŠ¥å‘Šè¯¦ç»†åº¦", result3))
    except Exception as e:
        print(f"\nâŒ æŠ¥å‘Šè¯¦ç»†åº¦æµ‹è¯•å¤±è´¥: {e}")
        results.append(("æŠ¥å‘Šè¯¦ç»†åº¦", False))

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} - {name}")

    all_passed = all(r[1] for r in results)
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

    return all_passed

if __name__ == "__main__":
    asyncio.run(main())
