"""
æµ‹è¯• Forum LLM è°ƒç”¨
ç”¨äºè¯Šæ–­ Forum åˆæˆæŠ¥å‘Šæ—¶ LLM è°ƒç”¨å¤±è´¥çš„é—®é¢˜
"""
import asyncio
import logging
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from dotenv import load_dotenv
load_dotenv()

logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s"
)

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

async def test_forum_llm():
    """æµ‹è¯• Forum çš„ LLM è°ƒç”¨"""
    print("=" * 60)
    print("Forum LLM è°ƒç”¨è¯Šæ–­æµ‹è¯•")
    print("=" * 60)

    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\n[1] æ£€æŸ¥ç¯å¢ƒå˜é‡...")
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("âŒ æœªæ‰¾åˆ° API Key (OPENAI_API_KEY æˆ– ANTHROPIC_API_KEY)")
        return
    print(f"âœ… API Key å·²é…ç½®: {api_key[:10]}...")

    # 2. åˆå§‹åŒ– LLM
    print("\n[2] åˆå§‹åŒ– LLM...")
    try:
        # ç›´æ¥ä½¿ç”¨ llm_config åˆå§‹åŒ– LLM
        from backend.llm_config import create_llm
        llm = create_llm()

        print(f"âœ… LLM åˆå§‹åŒ–æˆåŠŸ: {type(llm).__name__}")
        print(f"   - ç±»å‹: {type(llm)}")
        print(f"   - æ˜¯å¦æœ‰ ainvoke: {hasattr(llm, 'ainvoke')}")
    except Exception as e:
        print(f"âŒ LLM åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 3. æµ‹è¯•ç®€å•çš„ LLM è°ƒç”¨
    print("\n[3] æµ‹è¯•ç®€å•çš„ LLM è°ƒç”¨...")
    try:
        from langchain_core.messages import HumanMessage
        response = await llm.ainvoke([HumanMessage(content="Hello, respond with 'OK'")])
        print(f"âœ… LLM è°ƒç”¨æˆåŠŸ")
        print(f"   - Response ç±»å‹: {type(response)}")
        print(f"   - æ˜¯å¦æœ‰ content: {hasattr(response, 'content')}")
        if hasattr(response, 'content'):
            print(f"   - Content: {response.content[:100]}")
    except Exception as e:
        print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. æµ‹è¯• Forum åˆå§‹åŒ–
    print("\n[4] æµ‹è¯• ForumHost åˆå§‹åŒ–...")
    try:
        from backend.orchestration.forum import ForumHost
        forum = ForumHost(llm)
        print(f"âœ… ForumHost åˆå§‹åŒ–æˆåŠŸ")
        print(f"   - forum.llm ç±»å‹: {type(forum.llm).__name__}")
        print(f"   - forum.llm æ˜¯å¦ä¸º None: {forum.llm is None}")
    except Exception as e:
        print(f"âŒ ForumHost åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 5. æµ‹è¯• Prompt æ ¼å¼åŒ–
    print("\n[5] æµ‹è¯• FORUM_SYNTHESIS_PROMPT æ ¼å¼åŒ–...")
    try:
        from backend.prompts.system_prompts import FORUM_SYNTHESIS_PROMPT

        # å‡†å¤‡æµ‹è¯•æ•°æ®
        context_parts = {
            "price": "æµ‹è¯•ä»·æ ¼æ•°æ®",
            "news": "æµ‹è¯•æ–°é—»æ•°æ®",
            "technical": "æµ‹è¯•æŠ€æœ¯åˆ†æ",
            "fundamental": "æµ‹è¯•åŸºæœ¬é¢",
            "deep_search": "æµ‹è¯•æ·±åº¦æœç´¢",
            "macro": "æµ‹è¯•å®è§‚æ•°æ®"
        }

        prompt = FORUM_SYNTHESIS_PROMPT.format(
            risk_tolerance="medium",
            investment_style="balanced",
            user_instruction="",
            context_info="æµ‹è¯•ä¸Šä¸‹æ–‡",
            conflict_notes="æ— å†²çª",
            **context_parts
        )

        print(f"âœ… Prompt æ ¼å¼åŒ–æˆåŠŸ")
        print(f"   - Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
        print(f"   - Prompt å‰ 200 å­—ç¬¦: {prompt[:200]}")
    except Exception as e:
        print(f"âŒ Prompt æ ¼å¼åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # 6. æµ‹è¯•å®Œæ•´çš„ Forum synthesize è°ƒç”¨
    print("\n[6] æµ‹è¯• Forum.synthesize() è°ƒç”¨...")
    try:
        from backend.agents.base_agent import AgentOutput

        # æ„é€ æ¨¡æ‹Ÿçš„ Agent è¾“å‡º
        mock_outputs = {
            "price": AgentOutput(
                agent_name="price",
                summary="AAPL å½“å‰ä»·æ ¼ $150.00ï¼Œä¸Šæ¶¨ 2.5%",
                confidence=0.9,
                evidence=[],
                data_sources=["mock"],
                as_of="2024-01-24"
            ),
            "news": AgentOutput(
                agent_name="news",
                summary="è‹¹æœå‘å¸ƒæ–°äº§å“ï¼Œå¸‚åœºååº”ç§¯æ",
                confidence=0.8,
                evidence=[],
                data_sources=["mock"],
                as_of="2024-01-24"
            )
        }

        result = await forum.synthesize(mock_outputs, user_profile=None, context_summary="æµ‹è¯•ä¸Šä¸‹æ–‡")

        print(f"âœ… Forum.synthesize() è°ƒç”¨æˆåŠŸ")
        print(f"   - Consensus é•¿åº¦: {len(result.consensus)} å­—ç¬¦")
        print(f"   - Confidence: {result.confidence}")
        print(f"   - Recommendation: {result.recommendation}")
        print(f"   - Consensus å‰ 500 å­—ç¬¦:\n{result.consensus[:500]}")

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº† fallback
        if "### 1. ğŸ“Š æ‰§è¡Œæ‘˜è¦" in result.consensus and "HOLD (è§‚æœ›)" in result.consensus:
            print("\nâš ï¸  è­¦å‘Š: ä½¿ç”¨äº† fallback_synthesisï¼ŒLLM è°ƒç”¨å¯èƒ½å¤±è´¥äº†")
        else:
            print("\nâœ… ä½¿ç”¨äº† LLM ç”Ÿæˆçš„æŠ¥å‘Šï¼ˆé fallbackï¼‰")

    except Exception as e:
        print(f"âŒ Forum.synthesize() è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(test_forum_llm())
