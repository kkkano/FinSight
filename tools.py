import yfinance as yf
import json
from ddgs import DDGS
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta, date
import time
import re
import finnhub  # æ–°å¢
import pandas as pd # æ–°å¢
import os
from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================
# APIé…ç½®
# ============================================
ALPHA_VANTAGE_API_KEY = os.getenv("ALPHA_VANTAGE_API_KEY", "").strip('"')  # ç§»é™¤å¯èƒ½çš„å¼•å·
FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY", "").strip('"')

# ============================================
# API å®¢æˆ·ç«¯åˆå§‹åŒ–
# ============================================
# åœ¨è„šæœ¬é¡¶éƒ¨åˆå§‹åŒ–ä¸€æ¬¡ï¼Œä»¥æé«˜æ•ˆç‡
try:
    finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)
except Exception as e:
    print(f"Failed to initialize Finnhub client: {e}")
    finnhub_client = None

# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def search(query: str) -> str:
    """
    ä½¿ç”¨ DuckDuckGo æ‰§è¡Œç½‘é¡µæœç´¢å¹¶æ ¼å¼åŒ–ç»“æœã€‚
    å¤±è´¥æ—¶ä¼šé‡è¯•ä¸€æ¬¡ã€‚
    """
    for attempt in range(2):
        try:
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=10))
            
            if not results:
                return "No search results found."
            
            formatted = []
            for i, res in enumerate(results, 1):
                title = res.get('title', 'No title').encode('utf-8', 'ignore').decode('utf-8')
                body = res.get('body', 'No summary').encode('utf-8', 'ignore').decode('utf-8')
                href = res.get('href', 'No link')
                formatted.append(f"{i}. {title}\n   {body[:150]}...\n   {href}")
                
            return "Search Results:\n" + "\n\n".join(formatted)
        except Exception as e:
            print(f"Search attempt {attempt + 1} failed: {e}. Retrying in 2 seconds...")
            time.sleep(2)
            
    return "Search error: Exceeded maximum retries."

# ============================================
# è‚¡ä»·è·å– - å¤šæ•°æ®æºç­–ç•¥
# ============================================

def _fetch_with_alpha_vantage(ticker: str):
    """ä¼˜å…ˆæ–¹æ¡ˆï¼šä½¿ç”¨ Alpha Vantage API è·å–å®æ—¶è‚¡ä»·"""
    print(f"  - Attempting Alpha Vantage API for {ticker}...")
    try:
        url = "https://www.alphavantage.co/query"
        params = {
            'function': 'GLOBAL_QUOTE',
            'symbol': ticker,
            'apikey': ALPHA_VANTAGE_API_KEY
        }
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if 'Global Quote' in data and data['Global Quote']:
            quote = data['Global Quote']
            price = float(quote.get('05. price', 0))
            change = float(quote.get('09. change', 0))
            change_percent_str = quote.get('10. change percent', '0%').replace('%', '')
            
            if price > 0 and change_percent_str:
                change_percent = float(change_percent_str)
                return f"{ticker} Current Price: ${price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
        
        if 'Note' in data or 'Information' in data:
            print(f"  - Alpha Vantage note: {data.get('Note') or data.get('Information')}")
        if 'Error Message' in data:
            print(f"  - Alpha Vantage error: {data['Error Message']}")
            
        return None
    except Exception as e:
        print(f"  - Alpha Vantage exception: {e}")
        return None

def _fetch_with_finnhub(ticker: str):
    """æ–°å¢ï¼šä½¿ç”¨ Finnhub API è·å–å®æ—¶è‚¡ä»·"""
    if not finnhub_client:
        return None
    print(f"  - Attempting Finnhub API for {ticker}...")
    try:
        quote = finnhub_client.quote(ticker)
        if quote and quote.get('c') is not None and quote.get('c') != 0:
            price = quote['c']
            change = quote.get('d', 0.0)
            change_percent = quote.get('dp', 0.0)
            return f"{ticker} Current Price: ${price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
        return None
    except Exception as e:
        print(f"  - Finnhub quote exception: {e}")
        return None

def _fetch_with_yfinance(ticker: str):
    """å°è¯•ä½¿ç”¨ yfinance è·å–ä»·æ ¼"""
    print(f"  - Attempting yfinance for {ticker}...")
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="5d")
        if hist.empty or len(hist) < 2:
            return None
        
        current_price = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2]
        change = current_price - prev_close
        change_percent = (change / prev_close) * 100
        
        return f"{ticker} Current Price: ${current_price:.2f} | Change: ${change:.2f} ({change_percent:+.2f}%)"
    except Exception as e:
        print(f"  - yfinance exception: {e}")
        return None

def _scrape_yahoo_finance(ticker: str):
    """å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥çˆ¬å– Yahoo Finance é¡µé¢"""
    print(f"  - Attempting to scrape Yahoo Finance for {ticker}...")
    try:
        url = f"https://finance.yahoo.com/quote/{ticker}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        price_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketPrice'})
        change_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketChange'})
        change_percent_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketChangePercent'})
        
        if price_elem and change_elem and change_percent_elem:
            price = price_elem.get('value')
            change = change_elem.get('value')
            change_percent = change_percent_elem.get('value')
            
            if price and change and change_percent:
                return f"{ticker} Current Price: ${float(price):.2f} | Change: ${float(change):.2f} ({float(change_percent)*100:+.2f}%)"
        
        return None
    except Exception as e:
        print(f"  - Yahoo scraping exception: {e}")
        return None

def _search_for_price(ticker: str):
    """æœ€åæ‰‹æ®µï¼šä½¿ç”¨æœç´¢å¼•æ“å¹¶ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æä»·æ ¼"""
    print(f"  - Attempting to find price via search for {ticker}...")
    try:
        search_result = search(f"{ticker} stock price today")
        patterns = [
            r'\$(\d{1,5}(?:,\d{3})*\.\d{2})',
            r'(?:Price|price)[:\s]+\$?(\d{1,5}(?:,\d{3})*\.\d{2})',
            r'(\d{1,5}(?:,\d{3})*\.\d{2})\s*USD'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, search_result)
            if match:
                price = match.group(1).replace(',', '')
                return f"{ticker} Current Price (via search): ${price}"
        
        return None
    except Exception as e:
        print(f"  - Search price exception: {e}")
        return None

def get_stock_price(ticker: str) -> str:
    """
    ä½¿ç”¨å¤šæ•°æ®æºç­–ç•¥è·å–è‚¡ç¥¨ä»·æ ¼ï¼Œä»¥æé«˜ç¨³å®šæ€§ã€‚
    ç­–ç•¥é¡ºåº: Alpha Vantage -> Finnhub -> yfinance -> ç½‘é¡µæŠ“å– -> æœç´¢å¼•æ“è§£æ
    """
    print(f"Fetching price for {ticker} with multi-source strategy...")
    sources = [
        _fetch_with_alpha_vantage,
        _fetch_with_finnhub,  # æ–°å¢ Finnhub ä½œä¸ºé«˜ä¼˜å…ˆçº§æº
        _fetch_with_yfinance,
        _scrape_yahoo_finance,
        _search_for_price
    ]
    
    for i, source_func in enumerate(sources, 1):
        try:
            result = source_func(ticker)
            if result:
                print(f"  âœ“ Success with source #{i} ({source_func.__name__})!")
                return result
            time.sleep(0.5)
        except Exception as e:
            print(f"  âœ— Source #{i} ({source_func.__name__}) failed: {e}")
            continue
            
    return f"Error: All data sources failed to retrieve the price for {ticker}. Please try again later."

# ============================================
# å…¬å¸ä¿¡æ¯è·å–
# ============================================

def get_company_info(ticker: str) -> str:
    """
    ä»å¤šä¸ªæ¥æºè·å–å…¬å¸èµ„æ–™ä¿¡æ¯ã€‚
    ä¼˜å…ˆä½¿ç”¨ yfinanceï¼Œå¤±è´¥æ—¶å›é€€åˆ° Finnhub, Alpha Vantage æˆ–ç½‘é¡µæœç´¢ã€‚
    """
    # æ–¹æ³•1: yfinance
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        if info and 'longName' in info:
            summary = info.get('longBusinessSummary', '')
            description = (summary[:200] + '...') if summary else 'No description available'
            return f"""Company Profile ({ticker}):
- Name: {info.get('longName', 'Unknown')}
- Sector: {info.get('sector', 'Unknown')}
- Industry: {info.get('industry', 'Unknown')}
- Market Cap: ${info.get('marketCap', 0):,.0f}
- Website: {info.get('website', 'N/A')}
- Description: {description}"""
    except Exception as e:
        print(f"yfinance info fetch for '{ticker}' failed: {e}")

    # æ–¹æ³•2: Finnhub (æ–°å¢)
    if finnhub_client:
        try:
            print(f"Trying Finnhub for company info: {ticker}")
            profile = finnhub_client.company_profile2(symbol=ticker)
            if profile and 'name' in profile:
                return f"""Company Profile ({ticker}):
- Name: {profile.get('name', 'Unknown')}
- Sector: {profile.get('finnhubIndustry', 'Unknown')}
- Market Cap: ${int(profile.get('marketCapitalization', 0) * 1_000_000):,}
- Website: {profile.get('weburl', 'N/A')}
- Description: Search online for more details.""" # Finnhub profile doesn't include a long description
        except Exception as e:
            print(f"Finnhub profile fetch failed: {e}")
    
    # æ–¹æ³•3: Alpha Vantage
    try:
        print(f"Trying Alpha Vantage for company info: {ticker}")
        url = "https://www.alphavantage.co/query"
        params = {'function': 'OVERVIEW', 'symbol': ticker, 'apikey': ALPHA_VANTAGE_API_KEY}
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        if 'Symbol' in data and data['Symbol']:
            description = data.get('Description', 'No description')[:200] + '...'
            return f"""Company Profile ({ticker}):
- Name: {data.get('Name', 'Unknown')}
- Sector: {data.get('Sector', 'Unknown')}
- Industry: {data.get('Industry', 'Unknown')}
- Market Cap: ${int(data.get('MarketCapitalization', 0)):,}
- Description: {description}"""
    except Exception as e:
        print(f"Alpha Vantage overview fetch failed: {e}")
    
    # æ–¹æ³•4: ç½‘é¡µæœç´¢
    print(f"Falling back to web search for '{ticker}' company info")
    return search(f"{ticker} company profile stock information")

# ============================================
# æ–°é—»è·å–
# ============================================

MARKET_INDICES = {
    "^GSPC": "S&P 500 index",
    "^IXIC": "Nasdaq Composite index", 
    "^DJI": "Dow Jones Industrial Average",
    "^RUT": "Russell 2000 index",
    "^VIX": "VIX volatility index",
    "^NYA": "NYSE Composite index",
    "^FTSE": "FTSE 100 index",
    "^N225": "Nikkei 225 index",
    "^HSI": "Hang Seng index"
}

def _is_market_index(ticker: str) -> bool:
    """åˆ¤æ–­tickeræ˜¯å¦ä¸ºå¸‚åœºæŒ‡æ•°"""
    # æ–¹æ³•1: æ£€æŸ¥æ˜¯å¦åœ¨å·²çŸ¥æŒ‡æ•°åˆ—è¡¨ä¸­
    if ticker in MARKET_INDICES:
        return True
    
    # æ–¹æ³•2: æ£€æŸ¥å¸¸è§æŒ‡æ•°å‘½åæ¨¡å¼
    index_patterns = [
        r'^\^',      # ä»¥ ^ å¼€å¤´ï¼ˆYahoo FinanceæŒ‡æ•°æ ‡è®°ï¼‰
        r'SPX$',     # S&P 500 çš„å¦ä¸€ç§å†™æ³•
        r'NDX$',     # Nasdaq 100
        r'DJI$',     # Dow Jones
    ]
    
    for pattern in index_patterns:
        if re.match(pattern, ticker):
            return True
    
    return False

def _get_index_news(ticker: str) -> str:
    """
    ä¸“é—¨ä¸ºå¸‚åœºæŒ‡æ•°è·å–æ–°é—»çš„æ–¹æ³•ã€‚
    ç­–ç•¥ï¼šé€šè¿‡æœç´¢è·å–å®è§‚å¸‚åœºæ–°é—»å’ŒæŒ‡æ•°åˆ†æã€‚
    """
    friendly_name = MARKET_INDICES.get(ticker, ticker.replace('^', ''))
    
    print(f"  â†’ Detected market index: {friendly_name}")
    print(f"  â†’ Using specialized search strategy for index news...")
    
    # ç­–ç•¥1: æœç´¢æŒ‡æ•°æœ€è¿‘è¡¨ç°å’Œåˆ†æ
    current_date = datetime.now().strftime('%B %Y')
    search_queries = [
        f"{friendly_name} recent performance analysis {current_date}",
        f"{friendly_name} market news today",
        f"What's driving {friendly_name} this week"
    ]
    
    all_results = []
    for query in search_queries[:2]:  # åªç”¨å‰2ä¸ªæŸ¥è¯¢ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
        try:
            results = search(query)
            if results and "No search results" not in results:
                all_results.append(results)
            time.sleep(1)
        except Exception as e:
            print(f"  â†’ Search failed for '{query}': {e}")
            continue
    
    if not all_results:
        return f"Unable to fetch recent news for {friendly_name}. Please check financial news sites manually."
    
    # è§£æå¹¶æ ¼å¼åŒ–æœç´¢ç»“æœ
    combined_results = "\n\n".join(all_results)
    
    # å°è¯•ä»æœç´¢ç»“æœä¸­æå–æ–°é—»æ ‡é¢˜å’Œæ—¥æœŸ
    news_items = []
    lines = combined_results.split('\n')
    
    for i, line in enumerate(lines):
        # å¯»æ‰¾æ ‡é¢˜æ¨¡å¼ï¼ˆé€šå¸¸ä»¥æ•°å­—å¼€å¤´ï¼‰
        if re.match(r'^\d+\.', line.strip()):
            title = line.strip()
            # å°è¯•æ‰¾åˆ°æ—¥æœŸä¿¡æ¯
            date_match = re.search(r'(\d{1,2}\s+\w+\s+ago|\d{4}-\d{2}-\d{2}|\w+\s+\d{1,2},?\s+\d{4})', 
                                  ' '.join(lines[i:i+3]), re.IGNORECASE)
            date_str = date_match.group(1) if date_match else 'Recent'
            news_items.append(f"[{date_str}] {title}")
            
            if len(news_items) >= 5:
                break
    
    if news_items:
        return f"Latest Market News & Analysis ({friendly_name}):\n" + "\n".join(news_items)
    else:
        # å¦‚æœæ— æ³•æå–ç»“æ„åŒ–æ–°é—»ï¼Œè¿”å›åŸå§‹æœç´¢æ‘˜è¦
        preview = combined_results[:800] + "..." if len(combined_results) > 800 else combined_results
        return f"Recent Market Context ({friendly_name}):\n{preview}"

def get_company_news(ticker: str) -> str:
    """
    æ™ºèƒ½è·å–æ–°é—»ï¼šè‡ªåŠ¨è¯†åˆ«æ˜¯å…¬å¸è‚¡ç¥¨è¿˜æ˜¯å¸‚åœºæŒ‡æ•°ã€‚
    - å…¬å¸è‚¡ç¥¨ï¼šä½¿ç”¨ API (yfinance, Finnhub, Alpha Vantage)
    - å¸‚åœºæŒ‡æ•°ï¼šä½¿ç”¨æœç´¢ç­–ç•¥è·å–å®è§‚å¸‚åœºæ–°é—»
    """
    # ğŸ” å…³é”®åˆ¤æ–­ï¼šè¿™æ˜¯æŒ‡æ•°è¿˜æ˜¯å…¬å¸è‚¡ç¥¨ï¼Ÿ
    if _is_market_index(ticker):
        return _get_index_news(ticker)
    
    # --- ä»¥ä¸‹æ˜¯åŸæœ‰çš„å…¬å¸æ–°é—»è·å–é€»è¾‘ ---
    
    # æ–¹æ³•1: yfinance
    try:
        stock = yf.Ticker(ticker)
        news = stock.news
        if news:
            news_list = []
            for i, article in enumerate(news[:5], 1):
                title = article.get('title', 'No title')
                publisher = article.get('publisher', 'Unknown source')
                pub_time = article.get('providerPublishTime', 0)
                date_str = datetime.fromtimestamp(pub_time).strftime('%Y-%m-%d') if pub_time else 'Unknown date'
                news_list.append(f"{i}. [{date_str}] {title} ({publisher})")
            return f"Latest News ({ticker}):\n" + "\n".join(news_list)
    except Exception as e:
        print(f"yfinance news error for {ticker}: {e}")

    # æ–¹æ³•2: Finnhub
    if finnhub_client:
        try:
            print(f"Trying Finnhub news for {ticker}")
            to_date = date.today().strftime("%Y-%m-%d")
            from_date = (date.today() - timedelta(days=7)).strftime("%Y-%m-%d")
            news = finnhub_client.company_news(ticker, _from=from_date, to=to_date)
            if news:
                news_list = []
                for i, article in enumerate(news[:5], 1):
                    title = article.get('headline', 'No title')
                    source = article.get('source', 'Unknown')
                    pub_time = article.get('datetime', 0)
                    date_str = datetime.fromtimestamp(pub_time).strftime('%Y-%m-%d') if pub_time else 'Unknown'
                    news_list.append(f"{i}. [{date_str}] {title} ({source})")
                return f"Latest News ({ticker}):\n" + "\n".join(news_list)
        except Exception as e:
            print(f"Finnhub news fetch failed: {e}")

    # æ–¹æ³•3: Alpha Vantage
    try:
        print(f"Trying Alpha Vantage news for {ticker}")
        url = "https://www.alphavantage.co/query"
        params = {'function': 'NEWS_SENTIMENT', 'tickers': ticker, 'limit': 5, 'apikey': ALPHA_VANTAGE_API_KEY}
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        if 'feed' in data and data['feed']:
            news_list = []
            for i, article in enumerate(data['feed'][:5], 1):
                title = article.get('title', 'No title')
                source = article.get('source', 'Unknown')
                date_str = article.get('time_published', '')[:8]
                if date_str:
                    date_str = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                news_list.append(f"{i}. [{date_str}] {title} ({source})")
            return f"Latest News ({ticker}):\n" + "\n".join(news_list)
    except Exception as e:
        print(f"Alpha Vantage news fetch failed: {e}")
    
    # æ–¹æ³•4: å›é€€åˆ°å…¬å¸ç‰¹å®šæœç´¢
    print(f"Falling back to search for {ticker} news")
    return search(f"{ticker} company latest news stock")

# ============================================
# å…¶ä»–å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜æˆ–ç¨ä½œä¿®æ”¹ï¼‰
# ============================================

def get_market_sentiment() -> str:
    """
    è·å–å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ - CNN Fear & Greed Index
    ä½¿ç”¨æ›´å®Œæ•´çš„è¯·æ±‚å¤´æ¥æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œæé«˜æˆåŠŸç‡ã€‚
    """
    try:
        # ä¸»è¦APIåœ°å€
        url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
        
        # ä¼ªè£…æˆä¸€ä¸ªä»CNNå®˜ç½‘é¡µé¢å‘å‡ºè¯·æ±‚çš„çœŸå®æµè§ˆå™¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            # 'Referer' æ˜¯æœ€å…³é”®çš„å¤´ä¿¡æ¯ï¼Œå‘Šè¯‰æœåŠ¡å™¨è¯·æ±‚çš„æ¥æºé¡µé¢
            'Referer': 'https://www.cnn.com/markets/fear-and-greed',
            'Origin': 'https://www.cnn.com',
        }
        
        print("Attempting to fetch from CNN API with full headers...")
        response = requests.get(url, headers=headers, timeout=10)
        
        # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™ä¼šå¼•å‘ HTTPError å¼‚å¸¸
        response.raise_for_status() 
        
        data = response.json()
        score = float(data['fear_and_greed']['score'])
        rating = data['fear_and_greed']['rating']
        
        print("CNN API fetch successful!")
        return f"CNN Fear & Greed Index: {score:.1f} ({rating})"
    
    except requests.exceptions.HTTPError as http_err:
        print(f"CNN API failed with HTTP error: {http_err}. Trying fallback search...")
    except Exception as e:
        # æ•è·å…¶ä»–æ‰€æœ‰å¯èƒ½çš„å¼‚å¸¸ï¼Œä¾‹å¦‚ç½‘ç»œé—®é¢˜ã€JSONè§£æé”™è¯¯ç­‰
        print(f"CNN API failed with other error: {e}. Trying fallback search...")
    # --- å¦‚æœä¸Šé¢çš„ try ä»£ç å—å‡ºç°ä»»ä½•å¼‚å¸¸ï¼Œåˆ™æ‰§è¡Œä¸‹é¢çš„å›é€€é€»è¾‘ ---
    try:
        search_result = search("CNN Fear and Greed Index current value today")
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æœç´¢ç»“æœä¸­æå–æ•°å€¼å’Œè¯„çº§
        match = re.search(r'(?:Index|Score)[:\s]*(\d+\.?\d*)\s*\((\w+\s?\w*)\)', search_result, re.IGNORECASE)
        if match:
            score = float(match.group(1))
            rating = match.group(2)
            print("Fallback search successful!")
            return f"CNN Fear & Greed Index (via search): {score:.1f} ({rating})"
    except Exception as search_e:
        print(f"Search fallback also failed: {search_e}")
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªé€šç”¨é”™è¯¯ä¿¡æ¯
    return "Fear & Greed Index: Unable to fetch. Please check manually."
def get_economic_events() -> str:
    """æœç´¢å½“å‰æœˆä»½çš„ä¸»è¦ç¾å›½ç»æµäº‹ä»¶"""
    now = datetime.now()
    query = f"major upcoming US economic events {now.strftime('%B %Y')} (FOMC, CPI, jobs report)"
    return search(query)

def get_performance_comparison(tickers: dict) -> str:
    """æ¯”è¾ƒå­—å…¸ä¸­è‚¡ç¥¨ä»£ç çš„å¹´åˆè‡³ä»Šå’Œ1å¹´æœŸè¡¨ç°"""
    data = {}
    for name, ticker in tickers.items():
        time.sleep(1) # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="2y")
            if hist.empty:
                print(f"Warning: No historical data for {ticker}")
                continue
            
            end_price = hist['Close'].iloc[-1]
            
            # YTD Performance
            start_of_year = datetime(datetime.now().year, 1, 1)
            ytd_hist = hist[hist.index.tz_localize(None) >= start_of_year]
            if ytd_hist.empty:
                perf_ytd = float('nan')
            else:
                start_price_ytd = ytd_hist['Close'].iloc[0]
                perf_ytd = ((end_price - start_price_ytd) / start_price_ytd) * 100
            
            # 1-Year Performance
            one_year_ago = datetime.now() - timedelta(days=365)
            one_year_hist = hist[hist.index.tz_localize(None) >= one_year_ago]
            if one_year_hist.empty:
                 perf_1y = float('nan')
            else:
                start_price_1y = one_year_hist['Close'].iloc[0]
                perf_1y = ((end_price - start_price_1y) / start_price_1y) * 100

            data[name] = {
                "Current": f"{end_price:,.2f}", 
                "YTD": f"{perf_ytd:+.2f}%" if not pd.isna(perf_ytd) else "N/A", 
                "1-Year": f"{perf_1y:+.2f}%" if not pd.isna(perf_1y) else "N/A"
            }
        except Exception as e:
            print(f"Error processing performance for '{ticker}': {e}")
            data[name] = {"Current": "N/A", "YTD": "N/A", "1-Year": "N/A"}
    
    if not data:
        return "Unable to fetch performance data for any ticker."
            
    header = f"{'Ticker':<25} {'Current Price':<15} {'YTD %':<12} {'1-Year %':<12}\n" + "-" * 67 + "\n"
    rows = [f"{name:<25} {metrics['Current']:<15} {metrics['YTD']:<12} {metrics['1-Year']:<12}" for name, metrics in data.items()]
    return "Performance Comparison:\n\n" + header + "\n".join(rows)

def analyze_historical_drawdowns(ticker: str = "^IXIC") -> str:
    """è®¡ç®—å¹¶æŠ¥å‘Šè¿‡å»20å¹´çš„å‰3å¤§å†å²å›æ’¤ï¼ˆå·²ä¿®å¤æ—¶åŒºé—®é¢˜ï¼‰"""
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="20y") # å»¶é•¿è‡³20å¹´ä»¥æ•è·æ›´å¤šäº‹ä»¶
        if hist.empty:
            return f"No historical data available for {ticker}."
        
        # --- å…³é”®ä¿®å¤ï¼šç§»é™¤ç´¢å¼•çš„æ—¶åŒºä¿¡æ¯ ---
        hist.index = hist.index.tz_localize(None)
            
        hist['peak'] = hist['Close'].cummax()
        hist['drawdown'] = (hist['Close'] - hist['peak']) / hist['peak']
        
        # æ‰¾åˆ°æ‰€æœ‰å›æ’¤çš„è°·åº•
        # ä½¿ç”¨ä¸€ä¸ªæŠ€å·§æ¥åˆ†ç»„è¿ç»­çš„å›æ’¤æœŸ
        drawdown_groups = hist[hist['drawdown'] < 0]
        if drawdown_groups.empty:
            return f"No significant drawdowns found for {ticker} in the last 20 years."
        # æ‰¾åˆ°æ¯ä¸ªå›æ’¤æœŸå†…çš„æœ€ä½ç‚¹
        troughs = drawdown_groups.loc[drawdown_groups.groupby((drawdown_groups['drawdown'] == 0).cumsum())['drawdown'].idxmin()]
        top_3 = troughs.nsmallest(3, 'drawdown')
        if top_3.empty:
            return f"No significant drawdowns found for {ticker}."
        result = [f"Top 3 Historical Drawdowns for {ticker} (last 20y):\n"]
        for _, row in top_3.iterrows():
            trough_date = row.name
            # æ‰¾åˆ°è¿™ä¸ªè°·åº•å¯¹åº”çš„å³°å€¼æ—¥æœŸ
            peak_price = row['peak']
            
            # æ‰¾åˆ°å›æ’¤å¼€å§‹çš„æ—¥æœŸï¼ˆå³ç¬¬ä¸€æ¬¡è¾¾åˆ°å³°å€¼çš„æ—¥æœŸï¼‰
            peak_date = hist[(hist.index <= trough_date) & (hist['Close'] == peak_price)].index.max()
            
            # æŸ¥æ‰¾æ¢å¤æ—¥æœŸï¼ˆå³è°·åº•ä¹‹åç¬¬ä¸€æ¬¡å›åˆ°å³°å€¼ä»·æ ¼çš„æ—¥æœŸï¼‰
            recovery_df = hist[hist.index > trough_date]
            recovery_date_series = recovery_df[recovery_df['Close'] >= peak_price].index
            recovery_date = recovery_date_series[0] if not recovery_date_series.empty else None
            
            duration = (trough_date - peak_date).days
            recovery_days = (recovery_date - trough_date).days if recovery_date else "Ongoing"
            result.append(
                f"- Drawdown: {row['drawdown']:.2%} (from {peak_date.strftime('%Y-%m-%d')} to {trough_date.strftime('%Y-%m-%d')})\n"
                f"  Duration to trough: {duration} days. Recovery time: {recovery_days} days."
            )
        return "\n".join(result)
    except Exception as e:
        return f"Historical analysis error: {e}."
def get_current_datetime() -> str:
    """è¿”å›å½“å‰æ—¥æœŸå’Œæ—¶é—´"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

