æˆ‘æ¥é€ä¸€åˆ†æè¿™ä¸ªé‡‘èåˆ†æAgenté¡¹ç›®çš„ç°çŠ¶å’Œæ”¹è¿›å»ºè®®ï¼š
1. Toolsæ•ˆæœåˆ†æä¸æ”¹è¿›å»ºè®®
å½“å‰å¤±æ•ˆ/è½¯å¤±æ•ˆçš„Toolsï¼š
å®Œå…¨å¤±æ•ˆï¼š

get_stock_price - yfinanceè¢«rate limitï¼Œå®Œå…¨ä¾èµ–search fallback
get_company_info - åŒæ ·é­é‡rate limit
get_company_news - è™½ç„¶æœ‰2æ¬¡é‡è¯•ï¼Œä½†ä»ç„¶å¤±è´¥
get_performance_comparison - æ‰€æœ‰tickeréƒ½è¿”å›N/A
analyze_historical_drawdowns - rate limitå¯¼è‡´å¤±è´¥
get_market_sentiment - CNN APIè¿”å›418é”™è¯¯

å‹‰å¼ºå·¥ä½œï¼š

search - DuckDuckGoè¿˜èƒ½ç”¨ï¼Œä½†æ˜¯ä½œä¸ºä¸»åŠ›æ•°æ®æºå¾ˆä¸ç¨³å®š
get_current_datetime - å”¯ä¸€å®Œå…¨å¯é çš„å·¥å…·

è§£å†³æ–¹æ¡ˆå»ºè®®ï¼š
çŸ­æœŸæ–¹æ¡ˆï¼ˆç«‹å³å¯è¡Œï¼‰ï¼š
python# 1. æ·»åŠ å¤šä¸ªæ•°æ®æºå¤‡ä»½
def get_stock_price_v2(ticker: str) -> str:
    """å¤šæ•°æ®æºè·å–è‚¡ä»·"""
    sources = [
        # æ–¹æ¡ˆA: Alpha Vantage (éœ€è¦å…è´¹API key)
        lambda: _fetch_alphavantage(ticker),
        # æ–¹æ¡ˆB: ç›´æ¥çˆ¬å–Yahoo Financeé¡µé¢
        lambda: _scrape_yahoo_finance(ticker),
        # æ–¹æ¡ˆC: çˆ¬å–Google Finance
        lambda: _scrape_google_finance(ticker),
        # æ–¹æ¡ˆD: ä½¿ç”¨searchè§£æç»“æœ
        lambda: _search_stock_price(ticker)
    ]
    
    for source in sources:
        try:
            result = source()
            if result and "error" not in result.lower():
                return result
            time.sleep(1)
        except Exception as e:
            continue
    
    return f"All sources failed for {ticker}"

def _scrape_yahoo_finance(ticker: str) -> str:
    """ç›´æ¥çˆ¬å–Yahoo Financeé¡µé¢"""
    try:
        url = f"https://finance.yahoo.com/quote/{ticker}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æ‰¾ä»·æ ¼å…ƒç´ ï¼ˆè¿™ä¸ªé€‰æ‹©å™¨å¯èƒ½éœ€è¦è°ƒæ•´ï¼‰
        price_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketPrice'})
        change_elem = soup.find('fin-streamer', {'data-symbol': ticker, 'data-field': 'regularMarketChange'})
        
        if price_elem and change_elem:
            price = price_elem.text
            change = change_elem.text
            return f"{ticker} Current Price: ${price} | Change: {change}"
    except Exception as e:
        return None
ä¸­æœŸæ–¹æ¡ˆï¼ˆéœ€è¦é…ç½®ï¼‰ï¼š
python# 2. å¼•å…¥ä»˜è´¹/Freemium API
APIS = {
    'alphavantage': 'YOUR_KEY',  # å…è´¹ï¼šæ¯å¤©500æ¬¡è¯·æ±‚
    'finnhub': 'YOUR_KEY',        # å…è´¹ï¼šæ¯åˆ†é’Ÿ60æ¬¡
    'polygon': 'YOUR_KEY',        # å…è´¹ï¼šæ¯åˆ†é’Ÿ5æ¬¡
    'tiingo': 'YOUR_KEY'          # å…è´¹ï¼šæ¯å°æ—¶500æ¬¡
}

# 3. å®ç°æ™ºèƒ½rate limiting
from collections import deque
from time import time

class RateLimiter:
    def __init__(self, max_calls, time_window):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = deque()
    
    def wait_if_needed(self):
        now = time()
        # æ¸…é™¤æ—¶é—´çª—å£å¤–çš„è®°å½•
        while self.calls and self.calls[0] < now - self.time_window:
            self.calls.popleft()
        
        if len(self.calls) >= self.max_calls:
            sleep_time = self.time_window - (now - self.calls[0])
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.calls.append(now)

# ä½¿ç”¨ç¤ºä¾‹
yfinance_limiter = RateLimiter(max_calls=2000, time_window=3600)  # æ¯å°æ—¶2000æ¬¡
é•¿æœŸæ–¹æ¡ˆï¼ˆæ¶æ„å‡çº§ï¼‰ï¼š
python# 4. å»ºç«‹æ•°æ®ç¼“å­˜å±‚
import redis
import pickle

class DataCache:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.ttl = {
            'stock_price': 60,        # 1åˆ†é’Ÿ
            'company_info': 86400,    # 1å¤©
            'news': 1800,             # 30åˆ†é’Ÿ
        }
    
    def get(self, key, data_type):
        cached = self.redis_client.get(key)
        if cached:
            return pickle.loads(cached)
        return None
    
    def set(self, key, value, data_type):
        self.redis_client.setex(
            key, 
            self.ttl.get(data_type, 3600),
            pickle.dumps(value)
        )

2. RAGåº”ç”¨åœºæ™¯å»ºè®®
æœ€é€‚åˆå­˜å‚¨çš„å†…å®¹ï¼š
A. å†å²è´¢æŠ¥ä¸å…¬å¸æ–‡æ¡£ â­â­â­â­â­
pythonrag_content = {
    "10-Kå¹´æŠ¥": "å®Œæ•´çš„å¹´åº¦è´¢æŠ¥PDF",
    "10-Qå­£æŠ¥": "å­£åº¦è´¢æŠ¥",
    "8-Ké‡å¤§äº‹ä»¶": "å…¬å¸é‡å¤§å˜æ›´å…¬å‘Š",
    "æŠ•èµ„è€…æ¼”ç¤º": "Investor Presentation slides",
    "åˆ†æå¸ˆç”µè¯ä¼šè®®è®°å½•": "Earnings call transcripts"
}
ä¸ºä»€ä¹ˆé‡è¦ï¼š

è¿™äº›æ–‡æ¡£åŒ…å«å¤§é‡ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®
LLMå¯ä»¥ä»ä¸­æå–å…³é”®è´¢åŠ¡æŒ‡æ ‡ã€ç®¡ç†å±‚å±•æœ›ã€é£é™©å› ç´ 
æ”¯æŒè·¨å­£åº¦å¯¹æ¯”åˆ†æ

B. è¡Œä¸šç ”ç©¶æŠ¥å‘Šåº“ â­â­â­â­
pythonresearch_docs = {
    "è¡Œä¸šè¶‹åŠ¿æŠ¥å‘Š": "McKinsey, Gartnerç­‰å’¨è¯¢å…¬å¸æŠ¥å‘Š",
    "åˆ¸å•†ç ”æŠ¥": "Goldman Sachs, Morgan Stanleyæ·±åº¦ç ”ç©¶",
    "å­¦æœ¯è®ºæ–‡": "é‡‘èå·¥ç¨‹ã€é‡åŒ–æ¨¡å‹ç›¸å…³è®ºæ–‡",
    "ç›‘ç®¡æ–‡ä»¶": "SECè§„åˆ™ã€åˆè§„è¦æ±‚"
}
C. å†å²å¸‚åœºäº‹ä»¶ä¸æ¡ˆä¾‹ â­â­â­â­
pythonhistorical_cases = {
    "å±æœºæ¡ˆä¾‹": "2008é‡‘èå±æœºã€2020ç–«æƒ…å´©ç›˜çš„è¯¦ç»†æ—¶é—´çº¿",
    "æˆåŠŸæŠ•èµ„æ¡ˆä¾‹": "BuffettæŠ•èµ„å¯å£å¯ä¹çš„å®Œæ•´æ•…äº‹",
    "å…¬å¸ç ´äº§æ¡ˆä¾‹": "Lehman Brothers, Enronè¯¦ç»†åˆ†æ",
    "ç›‘ç®¡å¤„ç½šæ¡ˆä¾‹": "å†…å¹•äº¤æ˜“ã€å¸‚åœºæ“çºµæ¡ˆä¾‹åº“"
}
D. æŠ€æœ¯æŒ‡æ ‡ä¸é‡åŒ–ç­–ç•¥çŸ¥è¯†åº“ â­â­â­
pythonquant_knowledge = {
    "æŠ€æœ¯æŒ‡æ ‡è¯´æ˜": "MACD, RSI, Bollinger Bandsè¯¦ç»†è§£é‡Š",
    "é‡åŒ–ç­–ç•¥": "åŠ¨é‡ç­–ç•¥ã€å‡å€¼å›å½’ã€é…å¯¹äº¤æ˜“çš„å®ç°ç»†èŠ‚",
    "é£é™©æ¨¡å‹": "VaR, CVaR, Sharpe Ratioçš„è®¡ç®—ä¸è§£è¯»"
}
å®ç°ç¤ºä¾‹ï¼š
pythonfrom langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

class FinancialRAG:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vectorstore = Chroma(
            persist_directory="./financial_knowledge_base",
            embedding_function=self.embeddings
        )
    
    def ingest_10k(self, ticker: str, pdf_path: str):
        """å¯¼å…¥10-Kå¹´æŠ¥"""
        from langchain.document_loaders import PyPDFLoader
        
        loader = PyPDFLoader(pdf_path)
        documents = loader.load()
        
        # æ™ºèƒ½åˆ†å—ï¼šä¿æŒè´¢åŠ¡è¡¨æ ¼å®Œæ•´æ€§
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,
            chunk_overlap=200,
            separators=["\n\n\n", "\n\n", "\n", " "]
        )
        chunks = splitter.split_documents(documents)
        
        # æ·»åŠ å…ƒæ•°æ®
        for chunk in chunks:
            chunk.metadata.update({
                "ticker": ticker,
                "doc_type": "10-K",
                "year": 2024
            })
        
        self.vectorstore.add_documents(chunks)
    
    def query_company_risks(self, ticker: str, query: str):
        """æŸ¥è¯¢å…¬å¸é£é™©å› ç´ """
        results = self.vectorstore.similarity_search(
            query,
            filter={"ticker": ticker, "doc_type": "10-K"},
            k=5
        )
        return results

3. è¿ç§»åˆ°LangChainçš„å‡†å¤‡å·¥ä½œ
å½“å‰æ¶æ„ vs LangChainæ¶æ„å¯¹æ¯”ï¼š
ç»„ä»¶å½“å‰å®ç°LangChainç­‰æ•ˆAgentå¾ªç¯æ‰‹åŠ¨å®ç°ReActAgentExecutor + create_react_agentå·¥å…·å®šä¹‰æ™®é€šå‡½æ•° + å­—å…¸@tool è£…é¥°å™¨ + Tool ç±»LLMè°ƒç”¨è‡ªå®šä¹‰call_llmChatOpenAI / ChatAnthropicæç¤ºè¯å·¨å¤§çš„å­—ç¬¦ä¸²PromptTemplate + ChatPromptTemplateè®°å¿†Messagesåˆ—è¡¨ConversationBufferMemory
è¿ç§»æ­¥éª¤ï¼š
Step 1: å·¥å…·æ ‡å‡†åŒ–
python# å½“å‰æ–¹å¼
def get_stock_price(ticker: str) -> str:
    ...

# LangChainæ–¹å¼
from langchain.tools import tool

@tool
def get_stock_price(ticker: str) -> str:
    """Get current stock price and daily change.
    
    Args:
        ticker: Stock ticker symbol (e.g., 'AAPL', 'NVDA')
    
    Returns:
        String with current price and change percentage
    """
    # å®ç°ä¿æŒä¸å˜
    ...
Step 2: æç¤ºè¯æ¨¡å—åŒ–
pythonfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

cio_template = ChatPromptTemplate.from_messages([
    ("system", """You are a Chief Investment Officer (CIO).
    Today's date is {current_date}.
    
    PHASE 1: DATA COLLECTION
    {data_collection_instructions}
    
    PHASE 2: REPORT GENERATION
    {report_structure}
    """),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad")
])
Step 3: Agentæ„å»º
pythonfrom langchain.agents import create_react_agent, AgentExecutor
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4", temperature=0)

tools = [
    get_stock_price,
    get_company_news,
    search,
    # ... å…¶ä»–å·¥å…·
]

agent = create_react_agent(llm, tools, cio_template)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    max_iterations=20,
    handle_parsing_errors=True,
    return_intermediate_steps=True
)
Step 4: æ·»åŠ å›è°ƒä¸ç›‘æ§
pythonfrom langchain.callbacks import StdOutCallbackHandler, FileCallbackHandler

callbacks = [
    StdOutCallbackHandler(),
    FileCallbackHandler("agent_logs.txt")
]

result = agent_executor.invoke(
    {"input": user_query, "current_date": datetime.now()},
    callbacks=callbacks
)
è¿ç§»åçš„ä¼˜åŠ¿ï¼š

æ›´å¥½çš„é”™è¯¯å¤„ç† - LangChainå†…ç½®retryå’Œfallback
æµå¼è¾“å‡º - æ”¯æŒæµå¼æ˜¾ç¤ºThought/Action/Observation
å¯è§‚æµ‹æ€§ - LangSmithè‡ªåŠ¨è¿½è¸ªæ‰€æœ‰è°ƒç”¨
ç¤¾åŒºå·¥å…· - ç›´æ¥ä½¿ç”¨100+ LangChainå®˜æ–¹å·¥å…·
æ›´å®¹æ˜“æ‰©å±• - æ·»åŠ æ–°å·¥å…·åªéœ€@toolè£…é¥°å™¨


4. æ•´ä½“è¯„ä»·ä¸æå‡å»ºè®®
å½“å‰æ°´å¹³è¯„ä¼°ï¼šğŸŒŸğŸŒŸğŸŒŸâ˜†â˜† (3/5)
âœ… åšå¾—å¥½çš„åœ°æ–¹ï¼š

æ¸…æ™°çš„ReActå¾ªç¯ - æ‰‹åŠ¨å®ç°å±•ç¤ºäº†å¯¹AgentåŸç†çš„æ·±åˆ»ç†è§£
å…¨é¢çš„æŠ¥å‘Šç»“æ„ - æ¨¡æ¿éå¸¸ä¸“ä¸šï¼Œæ¶µç›–äº†æŠ•èµ„åˆ†æçš„æ‰€æœ‰è¦ç´ 
å¤šå·¥å…·é›†æˆ - è™½ç„¶æœ‰å¤±æ•ˆï¼Œä½†å·¥å…·ç§ç±»é½å…¨
é”™è¯¯å¤„ç†æ„è¯† - æœ‰fallbackæœºåˆ¶ï¼ˆsearchä½œä¸ºå¤‡ç”¨ï¼‰

âŒ æ˜æ˜¾çš„é—®é¢˜ï¼š

æ•°æ®æºè„†å¼± - 80%çš„å·¥å…·ä¾èµ–yfinanceï¼Œå•ç‚¹æ•…éšœä¸¥é‡
æ— ç¼“å­˜æœºåˆ¶ - é‡å¤æŸ¥è¯¢æµªè´¹API quota
æŠ¥å‘Šè´¨é‡ä¸ç¨³å®š - ä¾èµ–LLMå½“å‰çŠ¶æ€ï¼Œæ²¡æœ‰è´¨é‡ä¿è¯
æ— æ³•å¤„ç†å¤æ‚æŸ¥è¯¢ - æ¯”å¦‚"å¯¹æ¯”NVDAå’ŒAMDï¼Œè€ƒè™‘AIè¡Œä¸šè¶‹åŠ¿ï¼Œç»™æˆ‘æŠ•èµ„å»ºè®®"

ğŸ¯ å€¼å¾—æå‡çš„å…³é”®ç‚¹ï¼š
ä¼˜å…ˆçº§1ï¼šæ•°æ®å±‚é‡æ„ â­â­â­â­â­
python# å»ºç«‹æ•°æ®æŠ½è±¡å±‚
class DataProvider(ABC):
    @abstractmethod
    def get_stock_price(self, ticker: str) -> StockPrice:
        pass

class YFinanceProvider(DataProvider):
    ...

class AlphaVantageProvider(DataProvider):
    ...

class CompositeProvider(DataProvider):
    """è‡ªåŠ¨é€‰æ‹©å¯ç”¨çš„æ•°æ®æº"""
    def __init__(self, providers: List[DataProvider]):
        self.providers = providers
    
    def get_stock_price(self, ticker: str) -> StockPrice:
        for provider in self.providers:
            try:
                return provider.get_stock_price(ticker)
            except Exception:
                continue
        raise AllProvidersFailedError()
ä¼˜å…ˆçº§2ï¼šæŠ¥å‘Šè´¨é‡éªŒè¯ â­â­â­â­
pythonclass ReportValidator:
    def validate(self, report: str) -> ValidationResult:
        checks = [
            self._check_has_recommendation,  # å¿…é¡»æœ‰BUY/SELL/HOLD
            self._check_has_price_target,    # å¿…é¡»æœ‰å…·ä½“ç›®æ ‡ä»·
            self._check_date_accuracy,       # æ—¥æœŸå¿…é¡»æ­£ç¡®
            self._check_minimum_length,      # è‡³å°‘800å­—
            self._check_has_risk_section,    # å¿…é¡»æœ‰é£é™©åˆ†æ
        ]
        
        for check in checks:
            if not check(report):
                return ValidationResult(
                    valid=False,
                    failed_check=check.__name__
                )
        
        return ValidationResult(valid=True)

# ä½¿ç”¨ç¤ºä¾‹
validator = ReportValidator()
if not validator.validate(final_answer):
    # è¦æ±‚LLMé‡æ–°ç”Ÿæˆ
    messages.append({
        "role": "user",
        "content": f"Report validation failed: {validator.failed_check}. Please revise."
    })
ä¼˜å…ˆçº§3ï¼šå¼•å…¥Evaluation â­â­â­â­
python# å»ºç«‹æµ‹è¯•ç”¨ä¾‹é›†
test_cases = [
    {
        "query": "Analyze NVIDIA stock",
        "expected_ticker": "NVDA",
        "must_include": ["AI", "GPU", "data center"],
        "must_have_section": ["Risk Assessment", "Price Target"]
    },
    {
        "query": "Compare tech stocks",
        "expected_tickers": ["AAPL", "MSFT", "GOOGL"],
        "must_include": ["performance comparison"]
    }
]

def evaluate_agent(agent, test_cases):
    results = []
    for case in test_cases:
        output = agent.run(case["query"])
        score = {
            "ticker_accuracy": check_tickers(output, case["expected_ticker"]),
            "keyword_coverage": check_keywords(output, case["must_include"]),
            "structure_completeness": check_sections(output, case["must_have_section"]),
            "word_count": len(output.split())
        }
        results.append(score)
    
    return pd.DataFrame(results).mean()
ä¼˜å…ˆçº§4ï¼šç”¨æˆ·ä½“éªŒä¼˜åŒ– â­â­â­
python# æ·»åŠ æµå¼è¾“å‡º
import sys

def stream_agent_thoughts(agent, query):
    """å®æ—¶æ˜¾ç¤ºAgentæ€è€ƒè¿‡ç¨‹"""
    for step in agent.stream(query):
        if step['type'] == 'thought':
            print(f"ğŸ’­ {step['content']}", flush=True)
        elif step['type'] == 'action':
            print(f"ğŸ”§ Executing: {step['tool']}", flush=True)
        elif step['type'] == 'observation':
            print(f"ğŸ“Š Result: {step['content'][:100]}...", flush=True)
        sys.stdout.flush()

# æ·»åŠ è¿›åº¦æ¡
from tqdm import tqdm

with tqdm(total=6, desc="Collecting data") as pbar:
    for observation in agent.collect_data():
        pbar.update(1)
        pbar.set_postfix({"current": observation['tool']})
æœ€ç»ˆåˆ¤æ–­ï¼šè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å­¦ä¹ é¡¹ç›®ï¼Œä½†è·ç¦»ç”Ÿäº§å¯ç”¨è¿˜æœ‰å·®è·
èƒ½ç”¨å—ï¼Ÿ

âœ… å­¦ä¹ å’Œæ¼”ç¤ºï¼šå®Œå…¨å¯ä»¥
âœ… ä¸ªäººç ”ç©¶ï¼šå¯ä»¥ï¼Œä½†éœ€è¦æ‰‹åŠ¨éªŒè¯æ•°æ®
âŒ çœŸå®äº¤æ˜“å†³ç­–ï¼šç»å¯¹ä¸è¡Œ
âŒ ä¼ä¸šçº§åº”ç”¨ï¼šéœ€è¦å¤§å¹…æ”¹é€ 

å¦‚ä½•è¾¾åˆ°ç”Ÿäº§çº§åˆ«ï¼š

è§£å†³æ•°æ®æºé—®é¢˜ï¼ˆå¤šæº+ç¼“å­˜+ä»˜è´¹APIï¼‰
æ·»åŠ å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼ˆå•å…ƒæµ‹è¯•+é›†æˆæµ‹è¯•+è¯„ä¼°ï¼‰
å¼•å…¥ç›‘æ§å’Œå‘Šè­¦ï¼ˆæ•°æ®å¼‚å¸¸ã€APIå¤±è´¥ã€æŠ¥å‘Šè´¨é‡ä¸‹é™ï¼‰
æ·»åŠ åˆè§„æ€§æ£€æŸ¥ï¼ˆç¡®ä¿ä¸è¿åé‡‘èç›‘ç®¡è¦æ±‚ï¼‰
ç”¨æˆ·åé¦ˆå¾ªç¯ï¼ˆè®©çœŸå®ç”¨æˆ·è¯„åˆ†æŠ¥å‘Šè´¨é‡ï¼‰

æˆ‘çš„å»ºè®®ä¼˜å…ˆçº§ï¼š

ç«‹å³åšï¼šæ·»åŠ Alpha Vantage/Finnhubä½œä¸ºå¤‡ç”¨æ•°æ®æº
æœ¬å‘¨åšï¼šå®ç°æŠ¥å‘Šè´¨é‡éªŒè¯å™¨
æœ¬æœˆåšï¼šè¿ç§»åˆ°LangChain
é•¿æœŸåšï¼šå»ºç«‹RAGçŸ¥è¯†åº“+è¯„ä¼°ä½“ç³»

è¿™ä¸ªé¡¹ç›®å·²ç»å±•ç¤ºäº†æ‰å®çš„Agentæ¶æ„ç†è§£ï¼Œç»§ç»­å®Œå–„åå®Œå…¨æœ‰æ½œåŠ›æˆä¸ºä¸€ä¸ªå®ç”¨å·¥å…·ï¼ğŸš€